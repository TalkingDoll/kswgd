{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 1: Import All Required Packages ==============\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import subprocess\n",
    "import random\n",
    "import threading\n",
    "import psutil\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Add project directory to sys.path\n",
    "project_dir = \"/workspace/kswgd\"\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "# Scientific computing\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eig\n",
    "from scipy import linalg\n",
    "\n",
    "# PyTorch related\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "# Diffusers\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Real-ESRGAN and GFPGAN\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "from gfpgan import GFPGANer\n",
    "\n",
    "# FID evaluation\n",
    "try:\n",
    "    from pytorch_fid import fid_score\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pytorch-fid\", \"-q\"])\n",
    "    from pytorch_fid import fid_score\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "\n",
    "# LPIPS\n",
    "try:\n",
    "    import lpips\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lpips\", \"-q\"])\n",
    "    import lpips\n",
    "\n",
    "# Custom kernel functions\n",
    "from grad_ker1 import grad_ker1\n",
    "from K_tar_eval import K_tar_eval\n",
    "\n",
    "# Try GPU version\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from grad_ker1_gpu import grad_ker1 as grad_ker1_gpu\n",
    "    from K_tar_eval_gpu import K_tar_eval as K_tar_eval_gpu\n",
    "    GPU_KSWGD = True\n",
    "    print(\"‚úì GPU KSWGD backend available (CuPy)\")\n",
    "except Exception as e:\n",
    "    cp = None\n",
    "    grad_ker1_gpu = None\n",
    "    K_tar_eval_gpu = None\n",
    "    GPU_KSWGD = False\n",
    "    print(f\"‚úó GPU KSWGD backend not available: {e}\")\n",
    "\n",
    "# ==================== GPU Selection: Use the least utilized GPU ====================\n",
    "def get_gpu_utilization():\n",
    "    \"\"\"Get GPU utilization for all available GPUs using nvidia-smi\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=index,utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            return None\n",
    "        \n",
    "        gpu_info = []\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            parts = [p.strip() for p in line.split(',')]\n",
    "            if len(parts) >= 4:\n",
    "                gpu_id = int(parts[0])\n",
    "                util_percent = float(parts[1])\n",
    "                mem_used = float(parts[2])\n",
    "                mem_total = float(parts[3])\n",
    "                mem_percent = (mem_used / mem_total) * 100 if mem_total > 0 else 0\n",
    "                gpu_info.append({\n",
    "                    'id': gpu_id,\n",
    "                    'util_percent': util_percent,\n",
    "                    'mem_used_mb': mem_used,\n",
    "                    'mem_total_mb': mem_total,\n",
    "                    'mem_percent': mem_percent\n",
    "                })\n",
    "        return gpu_info\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not get GPU utilization: {e}\")\n",
    "        return None\n",
    "\n",
    "def select_best_gpu():\n",
    "    \"\"\"Select the GPU with lowest utilization\"\"\"\n",
    "    gpu_info = get_gpu_utilization()\n",
    "    \n",
    "    if gpu_info is None or len(gpu_info) == 0:\n",
    "        print(\"  ‚ö†Ô∏è Cannot detect GPU utilization, defaulting to GPU 0\")\n",
    "        return 0\n",
    "    \n",
    "    print(\"\\nüîç GPU Utilization Check:\")\n",
    "    print(f\"  {'GPU':<6} {'Util %':<10} {'Mem Used':<12} {'Mem Total':<12} {'Mem %':<10}\")\n",
    "    print(\"  \" + \"-\" * 50)\n",
    "    \n",
    "    for info in gpu_info:\n",
    "        print(f\"  GPU {info['id']:<3} {info['util_percent']:<10.1f} {info['mem_used_mb']:<12.0f} {info['mem_total_mb']:<12.0f} {info['mem_percent']:<10.1f}\")\n",
    "    \n",
    "    # Select GPU with lowest combined score (weighted: 60% utilization, 40% memory)\n",
    "    best_gpu = min(gpu_info, key=lambda x: 0.6 * x['util_percent'] + 0.4 * x['mem_percent'])\n",
    "    \n",
    "    print(f\"\\n  ‚úì Selected GPU {best_gpu['id']} (Util: {best_gpu['util_percent']:.1f}%, Mem: {best_gpu['mem_percent']:.1f}%)\")\n",
    "    return best_gpu['id']\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Auto-select best GPU based on utilization\n",
    "SELECTED_GPU = select_best_gpu()\n",
    "torch.cuda.set_device(SELECTED_GPU)\n",
    "device = torch.device(f\"cuda:{SELECTED_GPU}\")\n",
    "print(f\"\\nüéØ Global device set to: {device}\")\n",
    "print(\"   All subsequent cells will use this GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af498cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 2: All Function Definitions ==============\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# ==================== Data Processing ====================\n",
    "DATA_DIR = \"/workspace/kswgd/data\"\n",
    "CELEBAHQ_CACHE = os.path.join(DATA_DIR, \"CelebA-HQ\")\n",
    "CACHE_DIR = \"/workspace/kswgd/cache\"\n",
    "os.makedirs(CELEBAHQ_CACHE, exist_ok=True)\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs('/workspace/kswgd/figures_test', exist_ok=True)\n",
    "\n",
    "# VAE helper functions\n",
    "def _to_vae_range(x):\n",
    "    \"\"\"[0,1] ‚Üí [-1,1]\"\"\"\n",
    "    return (x * 2.0) - 1.0\n",
    "\n",
    "def _from_vae_range(x):\n",
    "    \"\"\"[-1,1] ‚Üí [0,1]\"\"\"\n",
    "    return torch.clamp((x + 1.0) * 0.5, 0.0, 1.0)\n",
    "\n",
    "# Image preprocessing transform\n",
    "transform_celebahq = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# ==================== MLP Latent AutoEncoder ====================\n",
    "MLP_ARCHITECTURE_VERSION = \"v3_configurable_depth\"\n",
    "\n",
    "class LatentAutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim=1024, latent_dim=64, hidden_dim=512, num_layers=5, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.architecture_version = MLP_ARCHITECTURE_VERSION\n",
    "        \n",
    "        encoder_layers = []\n",
    "        encoder_layers.extend([\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(dropout_rate),\n",
    "        ])\n",
    "        for i in range(num_layers - 2):\n",
    "            encoder_layers.extend([\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.LayerNorm(hidden_dim),\n",
    "                torch.nn.GELU(),\n",
    "            ])\n",
    "            if i % 2 == 0:\n",
    "                encoder_layers.append(torch.nn.Dropout(dropout_rate))\n",
    "        encoder_layers.append(torch.nn.Linear(hidden_dim, latent_dim))\n",
    "        self.encoder = torch.nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        decoder_layers = []\n",
    "        decoder_layers.extend([\n",
    "            torch.nn.Linear(latent_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "        ])\n",
    "        for i in range(num_layers - 2):\n",
    "            decoder_layers.extend([\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.LayerNorm(hidden_dim),\n",
    "                torch.nn.GELU(),\n",
    "            ])\n",
    "            if i % 2 == 0:\n",
    "                decoder_layers.append(torch.nn.Dropout(dropout_rate))\n",
    "        decoder_layers.append(torch.nn.Linear(hidden_dim, input_dim))\n",
    "        self.decoder = torch.nn.Sequential(*decoder_layers)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "def get_mlp_cache_path(config):\n",
    "    num_layers = config.get('mlp_num_layers', 5)\n",
    "    lpips_weight = config.get('lpips_weight', 0.7)\n",
    "    return os.path.join(\n",
    "        CACHE_DIR, \n",
    "        f\"vae_n{config['max_samples']}_mlp{config['reduced_dim']}_h{config['mlp_hidden_dim']}_L{num_layers}_lpips{lpips_weight}_e{config['mlp_epochs']}_{MLP_ARCHITECTURE_VERSION}.pkl\"\n",
    "    )\n",
    "\n",
    "def validate_cached_model(cache_data, config):\n",
    "    latent_ae = cache_data.get('latent_ae', None)\n",
    "    if latent_ae is None: return True\n",
    "    cached_version = cache_data.get('architecture_version', 'unknown')\n",
    "    if cached_version != MLP_ARCHITECTURE_VERSION: return False\n",
    "    if latent_ae.latent_dim != config['reduced_dim']: return False\n",
    "    if latent_ae.hidden_dim != config['mlp_hidden_dim']: return False\n",
    "    cached_layers = getattr(latent_ae, 'num_layers', 5)\n",
    "    if cached_layers != config.get('mlp_num_layers', 5): return False\n",
    "    return True\n",
    "\n",
    "def train_latent_autoencoder(Z_flat, latent_dim=64, hidden_dim=512, num_layers=5, epochs=100, batch_size=512, lr=1e-3, use_perceptual_loss=True, lpips_weight=0.7):\n",
    "    print(f\"\\n=== Training Latent AutoEncoder ({Z_flat.shape[1]} -> {latent_dim}) ===\")\n",
    "    model = LatentAutoEncoder(input_dim=Z_flat.shape[1], latent_dim=latent_dim, hidden_dim=hidden_dim, num_layers=num_layers).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    lpips_loss_fn = None\n",
    "    if use_perceptual_loss and lpips_weight > 0:\n",
    "        try:\n",
    "            lpips_loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "            lpips_loss_fn.eval()\n",
    "        except: use_perceptual_loss = False\n",
    "    \n",
    "    Z_tensor = torch.from_numpy(Z_flat).float().to(device)\n",
    "    dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(Z_tensor), batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for (batch,) in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            recon, z = model(batch)\n",
    "            mse_loss = torch.nn.functional.mse_loss(recon, batch)\n",
    "            if use_perceptual_loss and lpips_loss_fn is not None:\n",
    "                batch_3ch = batch.view(-1, 4, 16, 16)[:, :3, :, :]\n",
    "                recon_3ch = recon.view(-1, 4, 16, 16)[:, :3, :, :]\n",
    "                batch_norm = 2.0 * (batch_3ch - batch_3ch.min()) / (batch_3ch.max() - batch_3ch.min() + 1e-8) - 1.0\n",
    "                recon_norm = 2.0 * (recon_3ch - recon_3ch.min()) / (recon_3ch.max() - recon_3ch.min() + 1e-8) - 1.0\n",
    "                loss = mse_loss + lpips_weight * lpips_loss_fn(batch_norm, recon_norm).mean()\n",
    "            else: loss = mse_loss\n",
    "            loss.backward(); optimizer.step(); total_loss += loss.item() * batch.size(0)\n",
    "        scheduler.step()\n",
    "        if (epoch + 1) % 50 == 0: print(f\"  Epoch {epoch+1:3d}/{epochs}: Loss = {total_loss/len(Z_tensor):.6f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): Z_reduced = model.encode(Z_tensor).cpu().numpy()\n",
    "    return model, Z_reduced, MLP_ARCHITECTURE_VERSION\n",
    "\n",
    "# ==================== Real-ESRGAN + GFPGAN ====================\n",
    "model_path = '/workspace/kswgd/weights/RealESRGAN_x4plus.pth'\n",
    "gfpgan_path = '/workspace/kswgd/weights/GFPGANv1.3.pth'\n",
    "\n",
    "def create_upscaler(gpu_id):\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "    upsampler = RealESRGANer(scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=True, gpu_id=gpu_id)\n",
    "    face_enhancer = GFPGANer(model_path=gfpgan_path, upscale=4, arch='clean', channel_multiplier=2, bg_upsampler=upsampler)\n",
    "    return upsampler, face_enhancer\n",
    "\n",
    "def process_single_image(args):\n",
    "    img, gpu_id, use_face_enhance, face_enhancers, upsamplers = args\n",
    "    face_enhancer = face_enhancers[gpu_id]\n",
    "    upsampler = upsamplers[gpu_id]\n",
    "    if isinstance(img, Image.Image): img_np = np.array(img)\n",
    "    else:\n",
    "        img_np = np.transpose(img, (1, 2, 0)) if img.ndim == 3 and img.shape[0] == 3 else img\n",
    "        if img_np.max() <= 1.0: img_np = (img_np * 255).astype(np.uint8)\n",
    "    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    if use_face_enhance: _, _, output_bgr = face_enhancer.enhance(img_bgr, has_aligned=False, only_center_face=False, paste_back=True)\n",
    "    else: output_bgr, _ = upsampler.enhance(img_bgr, outscale=4)\n",
    "    return cv2.cvtColor(output_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def upscale_images(images_list, face_enhancers, upsamplers, use_face_enhance=True, desc=\"Upscaling\"):\n",
    "    return [process_single_image((img, 0, use_face_enhance, face_enhancers, upsamplers)) for img in tqdm(images_list, desc=desc)]\n",
    "\n",
    "# ==================== Decode Latents to Images ====================\n",
    "def decode_latents_to_images(flat_latents_std, Z_std, Z_mean, latent_ae, vae, full_latent_shape, vae_scaling, target_device):\n",
    "    \"\"\"Decode standardized latent codes back to images.\"\"\"\n",
    "    # Unstandardize\n",
    "    flat_latents = flat_latents_std * Z_std + Z_mean\n",
    "    \n",
    "    # Decode through MLP if available\n",
    "    if latent_ae is not None:\n",
    "        latent_ae.eval()\n",
    "        latent_ae = latent_ae.to(target_device)\n",
    "        with torch.no_grad():\n",
    "            flat_tensor = torch.from_numpy(flat_latents).float().to(target_device)\n",
    "            latents_recovered = latent_ae.decode(flat_tensor).cpu().numpy()\n",
    "    else:\n",
    "        latents_recovered = flat_latents\n",
    "    \n",
    "    # Reshape and decode through VAE\n",
    "    latents_tensor = torch.from_numpy(latents_recovered).float().view(-1, *full_latent_shape).to(target_device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        decoded = vae.decode(latents_tensor / vae_scaling).sample\n",
    "        decoded_rgb = _from_vae_range(decoded)\n",
    "    return decoded_rgb.cpu()\n",
    "\n",
    "# ==================== Eigendecomposition ====================\n",
    "def compute_eigendecomposition(rw_kernel, k_eig):\n",
    "    n_samples = rw_kernel.shape[0]\n",
    "    if k_eig < n_samples:\n",
    "        rw_kernel_torch = torch.from_numpy(rw_kernel).float().to(device)\n",
    "        X0 = torch.randn(n_samples, k_eig, device=device)\n",
    "        eigenvalues, eigenvectors = torch.lobpcg(rw_kernel_torch, k=k_eig, X=X0, largest=True)\n",
    "        lambda_ns, phi = eigenvalues.cpu().numpy(), eigenvectors.cpu().numpy()\n",
    "    else:\n",
    "        lambda_ns_raw, phi_raw = np.linalg.eigh(rw_kernel)\n",
    "        lambda_ns, phi = lambda_ns_raw[::-1], phi_raw[:, ::-1]\n",
    "    return lambda_ns, phi\n",
    "\n",
    "# ==================== GPU Accelerated Functions ====================\n",
    "def pairwise_distances_gpu(X, metric=\"euclidean\", batch_size=5000):\n",
    "    n = X.shape[0]\n",
    "    X_torch = torch.from_numpy(X).float().to(device)\n",
    "    if n <= batch_size:\n",
    "        dists = torch.cdist(X_torch, X_torch, p=2)\n",
    "        if metric == \"sqeuclidean\": dists = dists ** 2\n",
    "        return dists.cpu().numpy()\n",
    "    dist_matrix = np.zeros((n, n), dtype=np.float32)\n",
    "    for i in range(0, n, batch_size):\n",
    "        end_i = min(i + batch_size, n)\n",
    "        for j in range(0, n, batch_size):\n",
    "            end_j = min(j + batch_size, n)\n",
    "            dists_batch = torch.cdist(X_torch[i:end_i], X_torch[j:end_j], p=2)\n",
    "            if metric == \"sqeuclidean\": dists_batch = dists_batch ** 2\n",
    "            dist_matrix[i:end_i, j:end_j] = dists_batch.cpu().numpy()\n",
    "    return dist_matrix\n",
    "\n",
    "def compute_kernel_matrix_gpu(X_tar, batch_size=5000):\n",
    "    print(\"  üöÄ GPU Kernel Matrix...\")\n",
    "    dists = pairwise_distances_gpu(X_tar, metric=\"euclidean\", batch_size=batch_size)\n",
    "    eps_kswgd = float(max(np.median(dists**2) / (2.0 * np.log(X_tar.shape[0] + 1)), 1e-6))\n",
    "    dists_torch = torch.from_numpy(dists).float().to(device)\n",
    "    data_kernel = torch.exp(-dists_torch**2 / (2.0 * eps_kswgd))\n",
    "    p_x = torch.sqrt(torch.sum(data_kernel, dim=1))\n",
    "    data_kernel_norm = data_kernel / (p_x[:, None] * p_x[None, :] + 1e-12)\n",
    "    D_y = torch.sum(data_kernel_norm, dim=0)\n",
    "    rw_kernel = 0.5 * (data_kernel_norm / (D_y + 1e-12) + data_kernel_norm / (D_y[:, None] + 1e-12))\n",
    "    p_tar = torch.sum(data_kernel, dim=0)\n",
    "    sqrt_p = torch.sqrt(p_tar + 1e-12)\n",
    "    D_vec = torch.sum(data_kernel / sqrt_p[:, None] / sqrt_p[None, :], dim=1)\n",
    "    return eps_kswgd, rw_kernel.cpu().numpy(), p_tar.cpu().numpy(), D_vec.cpu().numpy()\n",
    "\n",
    "def compute_edmd_gpu(X_tar, dt_edmd, n_dict_components, batch_size=5000):\n",
    "    print(\"  üöÄ GPU EDMD...\")\n",
    "    dist2_edmd = pairwise_distances_gpu(X_tar, metric=\"sqeuclidean\", batch_size=batch_size)\n",
    "    h_edmd = np.sqrt(np.median(dist2_edmd) + 1e-12)\n",
    "    dist2_torch = torch.from_numpy(dist2_edmd).float().to(device)\n",
    "    W_edmd = torch.exp(-dist2_torch / (2.0 * h_edmd ** 2))\n",
    "    X_tar_torch = torch.from_numpy(X_tar).float().to(device)\n",
    "    score_edmd = (W_edmd @ X_tar_torch / (torch.sum(W_edmd, dim=1, keepdim=True) + 1e-12) - X_tar_torch) / (h_edmd ** 2)\n",
    "    X_tar_next = X_tar_torch + dt_edmd * score_edmd + torch.randn_like(X_tar_torch) * np.sqrt(2.0 * dt_edmd)\n",
    "    X_tar_next_np = X_tar_next.cpu().numpy()\n",
    "    \n",
    "    dict_model = MiniBatchDictionaryLearning(n_components=n_dict_components, alpha=1e-3, batch_size=256, max_iter=500, random_state=42)\n",
    "    dict_model.fit(X_tar)\n",
    "    Phi_X = np.hstack([np.ones((X_tar.shape[0], 1)), dict_model.transform(X_tar)])\n",
    "    Phi_Y = np.hstack([np.ones((X_tar_next_np.shape[0], 1)), dict_model.transform(X_tar_next_np)])\n",
    "    G_edmd = (Phi_X.T @ Phi_X) / Phi_X.shape[0] + 1e-3 * np.eye(Phi_X.shape[1])\n",
    "    A_edmd = (Phi_X.T @ Phi_Y) / Phi_X.shape[0]\n",
    "    eigvals_edmd, eigvecs_edmd = eig(A_edmd, G_edmd)\n",
    "    idx = np.argsort(-eigvals_edmd.real)\n",
    "    efuns_edmd = Phi_X @ eigvecs_edmd[:, idx]\n",
    "    lambda_ns_edmd = eigvals_edmd.real[idx]\n",
    "    lambda_gen_inv = np.zeros_like(lambda_ns_edmd)\n",
    "    valid = lambda_ns_edmd[1:] > 1e-6\n",
    "    lambda_gen_inv[1:][valid] = dt_edmd / (lambda_ns_edmd[1:][valid] - 1.0)\n",
    "    return np.real(efuns_edmd[:, 1:][:, valid]), lambda_gen_inv[1:][valid], np.sum(valid)\n",
    "\n",
    "# ==================== KSWGD Sampler ====================\n",
    "def compute_repulsive_force_gpu(particles, h=None):\n",
    "    use_gpu = GPU_KSWGD and torch.cuda.is_available()\n",
    "    xp = cp if use_gpu else np\n",
    "    n = particles.shape[0]\n",
    "    if n <= 1: return xp.zeros_like(particles)\n",
    "    p_sq = xp.sum(particles**2, axis=1, keepdims=True)\n",
    "    dist_sq = xp.maximum(p_sq + p_sq.T - 2 * xp.dot(particles, particles.T), 0)\n",
    "    if h is None: h = xp.sqrt(0.5 * xp.median(dist_sq) / xp.log(n + 1) + 1e-8)\n",
    "    kernel_matrix = xp.exp(-dist_sq / (2 * h**2 + 1e-8))\n",
    "    repulsion = xp.zeros_like(particles)\n",
    "    for i in range(n):\n",
    "        grad_k = -kernel_matrix[i, :, None] * (particles[i:i+1] - particles) / (h**2 + 1e-8)\n",
    "        repulsion[i] = xp.sum(grad_k, axis=0)\n",
    "    return repulsion / n\n",
    "\n",
    "def run_particle_sampler(X_tar, p_tar, sq_tar, D_vec, eps_kswgd, phi_use, lambda_use, num_particles=16, num_iters=200, step_size=0.05, alpha=0.1, rng_seed=42, method=\"kswgd\"):\n",
    "    use_gpu = GPU_KSWGD and torch.cuda.is_available()\n",
    "    xp = cp if use_gpu else np\n",
    "    grad_fn = grad_ker1_gpu if use_gpu else grad_ker1\n",
    "    K_eval_fn = K_tar_eval_gpu if use_gpu else K_tar_eval\n",
    "    print(f\"Method: {method.upper()}, Alpha: {alpha}\")\n",
    "    x_hist = xp.zeros((num_particles, X_tar.shape[1], num_iters))\n",
    "    x_hist[:, :, 0] = xp.asarray(np.random.default_rng(rng_seed).normal(0, 1, (num_particles, X_tar.shape[1])))\n",
    "    X_tar_d, p_tar_d, sq_tar_d, D_vec_d = xp.asarray(X_tar), xp.asarray(p_tar), xp.asarray(sq_tar), xp.asarray(D_vec)\n",
    "    phi_d, lambda_d = xp.asarray(phi_use), xp.asarray(lambda_use)\n",
    "    for t in trange(num_iters - 1, desc=\"Transport\"):\n",
    "        curr = x_hist[:, :, t]\n",
    "        grad_m = grad_fn(curr, X_tar_d, p_tar_d, sq_tar_d, D_vec_d, eps_kswgd)\n",
    "        cross_m = K_eval_fn(X_tar_d, curr, p_tar_d, sq_tar_d, D_vec_d, eps_kswgd)\n",
    "        push = phi_d @ ((phi_d.T @ cross_m) * lambda_d[:, None])\n",
    "        attr = xp.zeros_like(curr)\n",
    "        for d in range(X_tar.shape[1]): attr[:, d] = xp.sum(grad_m[:, :, d] @ push, axis=1) / num_particles\n",
    "        rep = compute_repulsive_force_gpu(curr) if alpha > 0 else 0\n",
    "        x_hist[:, :, t+1] = curr - step_size * (attr - alpha * rep)\n",
    "    return np.asarray(xp.asnumpy(x_hist[:, :, -1]) if use_gpu else x_hist[:, :, -1])\n",
    "\n",
    "# ==================== Main Experiment Function ====================\n",
    "def run_full_experiment(config, experiment_id=1):\n",
    "    print(f\"\\n{'='*60}\\nEXPERIMENT {experiment_id}\\n{'='*60}\")\n",
    "    for k, v in config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    \n",
    "    exp_dir = f\"/workspace/kswgd/figures_test/test{experiment_id}\"\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    print(f\"Output: {exp_dir}\")\n",
    "    \n",
    "    # Step 1: Load Dataset\n",
    "    print(\"\\n[1/9] Loading CelebA-HQ...\")\n",
    "    celebahq_dataset = load_dataset(\"mattymchen/celeba-hq\", split=\"train\", cache_dir=CELEBAHQ_CACHE, trust_remote_code=True)\n",
    "    \n",
    "    # Step 2: Load LDM\n",
    "    print(\"[2/9] Loading LDM...\")\n",
    "    ldm_pipe = DiffusionPipeline.from_pretrained(\"CompVis/ldm-celebahq-256\").to(device)\n",
    "    ldm_pipe.vqvae.config.scaling_factor = 1.0\n",
    "    vae = ldm_pipe.vqvae\n",
    "    vae_scaling = 1.0\n",
    "    \n",
    "    # Get latent shape\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.zeros(1, 3, 256, 256, device=device)\n",
    "        dummy_latent = vae.encode(_to_vae_range(dummy))\n",
    "        full_latent_shape = (dummy_latent.latents if hasattr(dummy_latent, 'latents') else dummy_latent[0]).shape[1:]\n",
    "    print(f\"  Latent shape: {full_latent_shape}\")\n",
    "    \n",
    "    # Step 3: Encode or Load from Cache\n",
    "    print(f\"[3/9] Encoding {config['max_samples']} images...\")\n",
    "    cache_path = get_mlp_cache_path(config)\n",
    "    \n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"  Loading from cache: {cache_path}\")\n",
    "        with open(cache_path, 'rb') as f: \n",
    "            data = pickle.load(f)\n",
    "        Z_all, latent_ae = data['Z_all'], data.get('latent_ae', None)\n",
    "        if latent_ae is not None:\n",
    "            latent_ae = latent_ae.to(device)\n",
    "    else:\n",
    "        print(f\"  Encoding images...\")\n",
    "        all_l = []\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(min(config['max_samples'], len(celebahq_dataset))), desc=\"Encoding\"):\n",
    "                img = transform_celebahq(celebahq_dataset[i][\"image\"]).unsqueeze(0).to(device)\n",
    "                latent = vae.encode(_to_vae_range(img))\n",
    "                latent_code = latent.latents if hasattr(latent, 'latents') else latent[0]\n",
    "                all_l.append((latent_code * vae_scaling).view(1, -1).cpu().numpy())\n",
    "        Z_flat = np.concatenate(all_l, axis=0)\n",
    "        \n",
    "        latent_ae, Z_all, _ = train_latent_autoencoder(\n",
    "            Z_flat, config['reduced_dim'], config['mlp_hidden_dim'], \n",
    "            config.get('mlp_num_layers', 5), config['mlp_epochs'],\n",
    "            lpips_weight=config.get('lpips_weight', 0.7)\n",
    "        )\n",
    "        with open(cache_path, 'wb') as f: \n",
    "            pickle.dump({'Z_all': Z_all, 'latent_ae': latent_ae, 'architecture_version': MLP_ARCHITECTURE_VERSION}, f)\n",
    "    \n",
    "    print(f\"  Z_all shape: {Z_all.shape}\")\n",
    "    \n",
    "    # Step 4-5: Kernel & EDMD\n",
    "    print(\"[4/9] Building kernel matrix...\")\n",
    "    Z_mean = np.mean(Z_all, axis=0, keepdims=True)\n",
    "    Z_std = np.std(Z_all, axis=0, keepdims=True) + 1e-8\n",
    "    X_tar = ((Z_all - Z_mean) / Z_std).astype(np.float64)\n",
    "    sq_tar = np.sum(X_tar ** 2, axis=1)\n",
    "    \n",
    "    eps, rw, p_tar, D_vec = compute_kernel_matrix_gpu(X_tar)\n",
    "    print(f\"  eps_kswgd: {eps:.6f}, kernel shape: {rw.shape}\")\n",
    "    \n",
    "    print(f\"[5/9] Eigendecomposition (k={config['k_eig']})...\")\n",
    "    l_ns, phi = compute_eigendecomposition(rw, config['k_eig'])\n",
    "    print(f\"  Top eigenvalues: {l_ns[:5]}\")\n",
    "    \n",
    "    print(f\"[6/9] EDMD (dt={config['dt_edmd']})...\")\n",
    "    phi_edmd, l_edmd, n_modes = compute_edmd_gpu(X_tar, config['dt_edmd'], config['n_dict_components'])\n",
    "    print(f\"  Koopman modes: {n_modes}\")\n",
    "    \n",
    "    # Step 6: KSWGD\n",
    "    print(f\"[7/9] KSWGD (particles={config['kswgd_num_particles']}, iters={config['kswgd_num_iters']})...\")\n",
    "    Z_kswgd = run_particle_sampler(\n",
    "        X_tar, p_tar, sq_tar, D_vec, eps, phi_edmd, l_edmd, \n",
    "        config['kswgd_num_particles'], config['kswgd_num_iters'], \n",
    "        config['kswgd_step_size'], config.get('repulsive_alpha', 0.1)\n",
    "    )\n",
    "    \n",
    "    # Step 7: Decode\n",
    "    print(\"[8/9] Decoding images...\")\n",
    "    imgs = decode_latents_to_images(Z_kswgd, Z_std.flatten(), Z_mean.flatten(), latent_ae, vae, full_latent_shape, vae_scaling, device)\n",
    "    \n",
    "    # Step 8: Upscale\n",
    "    print(\"[9/9] Upscaling with GFPGAN...\")\n",
    "    gpu_id = device.index if device.index is not None else 0\n",
    "    u, f = create_upscaler(gpu_id)\n",
    "    imgs_np = [np.clip(np.transpose(imgs[i].numpy(), (1, 2, 0)), 0, 1) for i in range(imgs.shape[0])]\n",
    "    upscaled = upscale_images(imgs_np, [f], [u])\n",
    "    \n",
    "    # Save\n",
    "    n_grid = min(16, len(upscaled))\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n_grid: ax.imshow(upscaled[i])\n",
    "        ax.axis('off')\n",
    "    title_text = str(config.get('figure_title', \"\")).strip()\n",
    "    if title_text:\n",
    "        fig.suptitle(title_text, fontsize=16, y=0.96)\n",
    "        fig.tight_layout(rect=[0.02, 0.02, 0.98, 0.93])\n",
    "    else:\n",
    "        fig.tight_layout(rect=[0.02, 0.02, 0.98, 0.98])\n",
    "    plt.savefig(os.path.join(exp_dir, \"kswgd_grid.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    \n",
    "    # Save config snapshot\n",
    "    config_txt_path = os.path.join(exp_dir, \"config.txt\")\n",
    "    with open(config_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Experiment {experiment_id} configuration\\n\")\n",
    "        for k in sorted(config.keys()):\n",
    "            f.write(f\"{k}: {config[k]}\\n\")\n",
    "    print(f\"‚úì Saved hyperparameters to {config_txt_path}\")\n",
    "    \n",
    "    print(f\"‚úì Saved to {exp_dir}/kswgd_grid.png\")\n",
    "    \n",
    "    # Clean up\n",
    "    del ldm_pipe, vae, imgs, upscaled\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {'config': config, 'experiment_id': experiment_id, 'output_dir': exp_dir}\n",
    "\n",
    "print(\"‚úì All functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 3: Timing Instrumentation for Steps 4-6 ==============\n",
    "import time\n",
    "\n",
    "if 'STEP_TIMINGS' not in globals():\n",
    "    STEP_TIMINGS = {}\n",
    "else:\n",
    "    STEP_TIMINGS = {}\n",
    "\n",
    "if 'compute_kernel_matrix_gpu_original' not in globals():\n",
    "    compute_kernel_matrix_gpu_original = compute_kernel_matrix_gpu\n",
    "\n",
    "def compute_kernel_matrix_gpu(*args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = compute_kernel_matrix_gpu_original(*args, **kwargs)\n",
    "    duration = time.perf_counter() - start\n",
    "    STEP_TIMINGS['kernel_matrix_seconds'] = duration\n",
    "    print(f\"  ‚è± Step 4 duration: {duration:.2f}s\")\n",
    "    return result\n",
    "\n",
    "if 'compute_eigendecomposition_original' not in globals():\n",
    "    compute_eigendecomposition_original = compute_eigendecomposition\n",
    "\n",
    "def compute_eigendecomposition(*args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = compute_eigendecomposition_original(*args, **kwargs)\n",
    "    duration = time.perf_counter() - start\n",
    "    STEP_TIMINGS['eigendecomposition_seconds'] = duration\n",
    "    print(f\"  ‚è± Step 5 duration: {duration:.2f}s\")\n",
    "    return result\n",
    "\n",
    "if 'compute_edmd_gpu_original' not in globals():\n",
    "    compute_edmd_gpu_original = compute_edmd_gpu\n",
    "\n",
    "def compute_edmd_gpu(*args, **kwargs):\n",
    "    start = time.perf_counter()\n",
    "    result = compute_edmd_gpu_original(*args, **kwargs)\n",
    "    duration = time.perf_counter() - start\n",
    "    STEP_TIMINGS['edmd_seconds'] = duration\n",
    "    print(f\"  ‚è± Step 6 duration: {duration:.2f}s\")\n",
    "    return result\n",
    "\n",
    "if 'run_full_experiment_original' not in globals():\n",
    "    run_full_experiment_original = run_full_experiment\n",
    "\n",
    "def run_full_experiment(config, experiment_id=1):\n",
    "    global STEP_TIMINGS\n",
    "    STEP_TIMINGS = {}\n",
    "    experiment_start = time.perf_counter()\n",
    "    result = run_full_experiment_original(config, experiment_id)\n",
    "    total_seconds = time.perf_counter() - experiment_start\n",
    "    STEP_TIMINGS['total_seconds'] = total_seconds\n",
    "    print(f\"‚è± Total experiment runtime: {total_seconds/60:.2f} min ({total_seconds:.1f}s)\")\n",
    "    if isinstance(result, dict):\n",
    "        result = result.copy()\n",
    "        result['timings'] = STEP_TIMINGS.copy()\n",
    "    return result\n",
    "\n",
    "print(\"‚úì Timing instrumentation active (Steps 4-6 + total runtime)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe30fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 4: Parameter Grid and Iteration Loop ==============\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Verify we're using the GPU selected in Cell 1\n",
    "print(f\"üéØ Using device from Cell 1: {device}\")\n",
    "print(f\"   SELECTED_GPU = {SELECTED_GPU}\")\n",
    "\n",
    "# ==================== Define Parameter Grid ====================\n",
    "DEBUG_MODE = False\n",
    "print(\"‚úì PRODUCTION MODE - Using full parameters\")\n",
    "\n",
    "DEBUG_MAX_SAMPLES = 28000\n",
    "DEBUG_NUM_PARTICLES = 16\n",
    "DEBUG_MLP_EPOCHS = 300\n",
    "\n",
    "# ==================== Extended Experiment Design ====================\n",
    "dt_edmd_values = [0.05, 0.1]\n",
    "kswgd_step_size_values = [0.01, 0.05, 0.1]\n",
    "k_eig_values = [100, 300, 1000]\n",
    "n_dict_values = [100, 300]\n",
    "kswgd_iters_values = [500]\n",
    "mlp_hidden_dim_values = [512]\n",
    "mlp_num_layers_values = [6, 7]\n",
    "lpips_weight_values = [0.0, 1.0]\n",
    "repulsive_alpha_values = [0.0, 0.5] # Added repulsive force alpha\n",
    "\n",
    "configs_to_run = []\n",
    "for dt in dt_edmd_values:\n",
    "    for step_size in kswgd_step_size_values:\n",
    "        for k_eig in k_eig_values:\n",
    "            for n_dict in n_dict_values:\n",
    "                for kswgd_iters in kswgd_iters_values:\n",
    "                    for hidden_dim in mlp_hidden_dim_values:\n",
    "                        for num_layers in mlp_num_layers_values:\n",
    "                            for lpips_w in lpips_weight_values:\n",
    "                                for alpha in repulsive_alpha_values:\n",
    "                                    configs_to_run.append({\n",
    "                                        'dt_edmd': dt,\n",
    "                                        'mlp_epochs': DEBUG_MLP_EPOCHS,\n",
    "                                        'mlp_hidden_dim': hidden_dim,\n",
    "                                        'mlp_num_layers': num_layers,\n",
    "                                        'lpips_weight': lpips_w,\n",
    "                                        'reduced_dim': 8,\n",
    "                                        'k_eig': k_eig,\n",
    "                                        'n_dict_components': n_dict,\n",
    "                                        'kswgd_num_particles': DEBUG_NUM_PARTICLES,\n",
    "                                        'kswgd_num_iters': kswgd_iters,\n",
    "                                        'kswgd_step_size': step_size,\n",
    "                                        'max_samples': DEBUG_MAX_SAMPLES,\n",
    "                                        'repulsive_alpha': alpha,\n",
    "                                    })\n",
    "\n",
    "print(f\"üìã SELECTED CONFIGS: {len(configs_to_run)} experiments\")\n",
    "print(f\"\\nüîß Fixed parameters:\")\n",
    "print(f\"  max_samples: {DEBUG_MAX_SAMPLES}, num_particles: {DEBUG_NUM_PARTICLES}, mlp_epochs: {DEBUG_MLP_EPOCHS}\")\n",
    "print(f\"\\nüìä Variable parameters:\")\n",
    "print(f\"  dt_edmd: {dt_edmd_values}, step_size: {kswgd_step_size_values}, k_eig: {k_eig_values}\")\n",
    "print(f\"  n_dict: {n_dict_values}, hidden: {mlp_hidden_dim_values}, layers: {mlp_num_layers_values}\")\n",
    "print(f\"  lpips: {lpips_weight_values}, alpha: {repulsive_alpha_values}\")\n",
    "\n",
    "# ==================== Run Experiments ====================\n",
    "all_results = []\n",
    "results_save_path = f\"/workspace/kswgd/cache/iteration_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "\n",
    "for i, config in enumerate(configs_to_run):\n",
    "    print(f\"\\n{'#'*80}\\n# EXPERIMENT {i+1}/{len(configs_to_run)} on GPU {SELECTED_GPU}\\n# alpha={config['repulsive_alpha']}, dt={config['dt_edmd']}, step={config['kswgd_step_size']}\\n{'#'*80}\")\n",
    "    try:\n",
    "        result = run_full_experiment(config, experiment_id=i+1)\n",
    "        all_results.append(result)\n",
    "        with open(results_save_path, 'wb') as f: pickle.dump(all_results, f)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Experiment failed: {e}\")\n",
    "        import traceback; traceback.print_exc()\n",
    "        all_results.append({'config': config, 'error': str(e)})\n",
    "    gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# ==================== Summary ====================\n",
    "print(\"\\n\" + \"=\" * 150)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 150)\n",
    "print(f\"{'#':<4} {'alpha':<6} {'dt':<6} {'step':<8} {'k_eig':<7} {'n_dict':<7} {'hidden':<7} {'layers':<7} {'lpips':<6}\")\n",
    "print(\"-\" * 150)\n",
    "for r in all_results:\n",
    "    if 'error' in r: print(f\"{r.get('experiment_id','?'):<4} ERROR: {r['error'][:50]}\")\n",
    "    else:\n",
    "        c = r['config']\n",
    "        print(f\"{r['experiment_id']:<4} {c['repulsive_alpha']:<6.2f} {c['dt_edmd']:<6.3f} {c['kswgd_step_size']:<8.4f} {c['k_eig']:<7} {c['n_dict_components']:<7} {c['mlp_hidden_dim']:<7} {c['mlp_num_layers']:<7} {c['lpips_weight']:<6.2f}\")\n",
    "print(f\"\\nResults saved to: {results_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kswgd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
