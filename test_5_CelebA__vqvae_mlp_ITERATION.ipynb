{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b4687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 1: Import All Required Packages ==============\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import subprocess\n",
    "import random\n",
    "import threading\n",
    "import psutil\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Add project directory to sys.path\n",
    "project_dir = \"/workspace/kswgd\"\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.append(project_dir)\n",
    "\n",
    "# Scientific computing\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eig\n",
    "from scipy import linalg\n",
    "\n",
    "# PyTorch related\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "# Diffusers\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Real-ESRGAN and GFPGAN\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from realesrgan import RealESRGANer\n",
    "from gfpgan import GFPGANer\n",
    "\n",
    "# FID evaluation\n",
    "try:\n",
    "    from pytorch_fid import fid_score\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pytorch-fid\", \"-q\"])\n",
    "    from pytorch_fid import fid_score\n",
    "    from pytorch_fid.inception import InceptionV3\n",
    "\n",
    "# LPIPS\n",
    "try:\n",
    "    import lpips\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"lpips\", \"-q\"])\n",
    "    import lpips\n",
    "\n",
    "# Custom kernel functions\n",
    "from grad_ker1 import grad_ker1\n",
    "from K_tar_eval import K_tar_eval\n",
    "\n",
    "# Try GPU version\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from grad_ker1_gpu import grad_ker1 as grad_ker1_gpu\n",
    "    from K_tar_eval_gpu import K_tar_eval as K_tar_eval_gpu\n",
    "    GPU_KSWGD = True\n",
    "    print(\"‚úì GPU KSWGD backend available (CuPy)\")\n",
    "except Exception as e:\n",
    "    cp = None\n",
    "    grad_ker1_gpu = None\n",
    "    K_tar_eval_gpu = None\n",
    "    GPU_KSWGD = False\n",
    "    print(f\"‚úó GPU KSWGD backend not available: {e}\")\n",
    "\n",
    "# ==================== GPU Selection: Use the least utilized GPU ====================\n",
    "def get_gpu_utilization():\n",
    "    \"\"\"Get GPU utilization for all available GPUs using nvidia-smi\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=index,utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'],\n",
    "            capture_output=True, text=True, timeout=10\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            return None\n",
    "        \n",
    "        gpu_info = []\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            parts = [p.strip() for p in line.split(',')]\n",
    "            if len(parts) >= 4:\n",
    "                gpu_id = int(parts[0])\n",
    "                util_percent = float(parts[1])\n",
    "                mem_used = float(parts[2])\n",
    "                mem_total = float(parts[3])\n",
    "                mem_percent = (mem_used / mem_total) * 100 if mem_total > 0 else 0\n",
    "                gpu_info.append({\n",
    "                    'id': gpu_id,\n",
    "                    'util_percent': util_percent,\n",
    "                    'mem_used_mb': mem_used,\n",
    "                    'mem_total_mb': mem_total,\n",
    "                    'mem_percent': mem_percent\n",
    "                })\n",
    "        return gpu_info\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Could not get GPU utilization: {e}\")\n",
    "        return None\n",
    "\n",
    "def select_best_gpu():\n",
    "    \"\"\"Select the GPU with lowest utilization\"\"\"\n",
    "    gpu_info = get_gpu_utilization()\n",
    "    \n",
    "    if gpu_info is None or len(gpu_info) == 0:\n",
    "        print(\"  ‚ö†Ô∏è Cannot detect GPU utilization, defaulting to GPU 0\")\n",
    "        return 0\n",
    "    \n",
    "    print(\"\\nüîç GPU Utilization Check:\")\n",
    "    print(f\"  {'GPU':<6} {'Util %':<10} {'Mem Used':<12} {'Mem Total':<12} {'Mem %':<10}\")\n",
    "    print(\"  \" + \"-\" * 50)\n",
    "    \n",
    "    for info in gpu_info:\n",
    "        print(f\"  GPU {info['id']:<3} {info['util_percent']:<10.1f} {info['mem_used_mb']:<12.0f} {info['mem_total_mb']:<12.0f} {info['mem_percent']:<10.1f}\")\n",
    "    \n",
    "    # Select GPU with lowest combined score (weighted: 60% utilization, 40% memory)\n",
    "    best_gpu = min(gpu_info, key=lambda x: 0.6 * x['util_percent'] + 0.4 * x['mem_percent'])\n",
    "    \n",
    "    print(f\"\\n  ‚úì Selected GPU {best_gpu['id']} (Util: {best_gpu['util_percent']:.1f}%, Mem: {best_gpu['mem_percent']:.1f}%)\")\n",
    "    return best_gpu['id']\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Auto-select best GPU based on utilization\n",
    "SELECTED_GPU = select_best_gpu()\n",
    "torch.cuda.set_device(SELECTED_GPU)\n",
    "device = torch.device(f\"cuda:{SELECTED_GPU}\")\n",
    "print(f\"\\nüéØ Global device set to: {device}\")\n",
    "print(\"   All subsequent cells will use this GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af498cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 2: All Function Definitions ==============\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# ==================== Data Processing ====================\n",
    "DATA_DIR = \"/workspace/kswgd/data\"\n",
    "CELEBAHQ_CACHE = os.path.join(DATA_DIR, \"CelebA-HQ\")\n",
    "CACHE_DIR = \"/workspace/kswgd/cache\"\n",
    "os.makedirs(CELEBAHQ_CACHE, exist_ok=True)\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs('/workspace/kswgd/figures', exist_ok=True)\n",
    "\n",
    "# VAE helper functions\n",
    "def _to_vae_range(x):\n",
    "    \"\"\"[0,1] ‚Üí [-1,1]\"\"\"\n",
    "    return (x * 2.0) - 1.0\n",
    "\n",
    "def _from_vae_range(x):\n",
    "    \"\"\"[-1,1] ‚Üí [0,1]\"\"\"\n",
    "    return torch.clamp((x + 1.0) * 0.5, 0.0, 1.0)\n",
    "\n",
    "# Image preprocessing transform\n",
    "transform_celebahq = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "# ==================== MLP Latent AutoEncoder ====================\n",
    "class LatentAutoEncoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim=1024, latent_dim=64, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.LayerNorm(hidden_dim // 2),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim // 2, latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, hidden_dim // 2),\n",
    "            torch.nn.LayerNorm(hidden_dim // 2),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.LayerNorm(hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim, input_dim),\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        return self.decode(z), z\n",
    "\n",
    "\n",
    "def train_latent_autoencoder(Z_flat, latent_dim=64, hidden_dim=512, epochs=100, batch_size=512, lr=1e-3, use_perceptual_loss=True):\n",
    "    \"\"\"Train the MLP AutoEncoder on VAE latent codes\"\"\"\n",
    "    print(f\"\\n=== Training Latent AutoEncoder ({Z_flat.shape[1]} -> {latent_dim}) ===\")\n",
    "    print(f\"  Hidden dim: {hidden_dim}, Epochs: {epochs}\")\n",
    "    \n",
    "    model = LatentAutoEncoder(input_dim=Z_flat.shape[1], latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    lpips_loss_fn = None\n",
    "    if use_perceptual_loss:\n",
    "        try:\n",
    "            lpips_loss_fn = lpips.LPIPS(net='vgg').to(device)\n",
    "            lpips_loss_fn.eval()\n",
    "            for param in lpips_loss_fn.parameters():\n",
    "                param.requires_grad = False\n",
    "        except:\n",
    "            use_perceptual_loss = False\n",
    "    \n",
    "    Z_tensor = torch.from_numpy(Z_flat).float().to(device)\n",
    "    dataset = torch.utils.data.TensorDataset(Z_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for (batch,) in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            recon, z = model(batch)\n",
    "            mse_loss = torch.nn.functional.mse_loss(recon, batch)\n",
    "            \n",
    "            if use_perceptual_loss and lpips_loss_fn is not None:\n",
    "                batch_spatial = batch.view(-1, 4, 16, 16)\n",
    "                recon_spatial = recon.view(-1, 4, 16, 16)\n",
    "                batch_3ch = batch_spatial[:, :3, :, :]\n",
    "                recon_3ch = recon_spatial[:, :3, :, :]\n",
    "                batch_norm = 2.0 * (batch_3ch - batch_3ch.min()) / (batch_3ch.max() - batch_3ch.min() + 1e-8) - 1.0\n",
    "                recon_norm = 2.0 * (recon_3ch - recon_3ch.min()) / (recon_3ch.max() - recon_3ch.min() + 1e-8) - 1.0\n",
    "                lpips_loss = lpips_loss_fn(batch_norm, recon_norm).mean()\n",
    "                loss = mse_loss + 0.7 * lpips_loss\n",
    "            else:\n",
    "                loss = mse_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * batch.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(Z_tensor)\n",
    "        scheduler.step()\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "        if (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "            print(f\"  Epoch {epoch+1:3d}/{epochs}: Loss = {avg_loss:.6f}\")\n",
    "    \n",
    "    print(f\"‚úì Training complete! Best loss: {best_loss:.6f}\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Z_reduced = model.encode(Z_tensor).cpu().numpy()\n",
    "    return model, Z_reduced\n",
    "\n",
    "\n",
    "# ==================== Real-ESRGAN + GFPGAN ====================\n",
    "model_path = '/workspace/kswgd/weights/RealESRGAN_x4plus.pth'\n",
    "gfpgan_path = '/workspace/kswgd/weights/GFPGANv1.3.pth'\n",
    "\n",
    "def create_upscaler(gpu_id):\n",
    "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)\n",
    "    upsampler = RealESRGANer(scale=4, model_path=model_path, model=model, tile=0, tile_pad=10, pre_pad=0, half=True, gpu_id=gpu_id)\n",
    "    face_enhancer = GFPGANer(model_path=gfpgan_path, upscale=4, arch='clean', channel_multiplier=2, bg_upsampler=upsampler)\n",
    "    return upsampler, face_enhancer\n",
    "\n",
    "def preprocess_image(img_bgr):\n",
    "    processed = img_bgr.copy().astype(np.float32)\n",
    "    processed = cv2.GaussianBlur(processed, (3, 3), sigmaX=0.5)\n",
    "    processed = cv2.bilateralFilter(processed.astype(np.uint8), d=5, sigmaColor=30, sigmaSpace=30).astype(np.float32)\n",
    "    mean_b, mean_g, mean_r = np.mean(processed[:, :, 0]), np.mean(processed[:, :, 1]), np.mean(processed[:, :, 2])\n",
    "    target_mean, alpha = 127.5, 0.3\n",
    "    processed[:, :, 0] += alpha * (target_mean - mean_b)\n",
    "    processed[:, :, 1] += alpha * (target_mean - mean_g)\n",
    "    processed[:, :, 2] += alpha * (target_mean - mean_r)\n",
    "    return np.clip(processed, 0, 255).astype(np.uint8)\n",
    "\n",
    "def process_single_image(args):\n",
    "    img, gpu_id, use_face_enhance, use_preprocess, face_enhancers, upsamplers = args\n",
    "    face_enhancer = face_enhancers[gpu_id]\n",
    "    upsampler = upsamplers[gpu_id]\n",
    "    \n",
    "    if isinstance(img, Image.Image):\n",
    "        img_np = np.array(img)\n",
    "    else:\n",
    "        if img.ndim == 3 and img.shape[0] == 3:\n",
    "            img_np = np.transpose(img, (1, 2, 0))\n",
    "        else:\n",
    "            img_np = img\n",
    "        if img_np.max() <= 1.0:\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "    \n",
    "    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)\n",
    "    if use_preprocess:\n",
    "        img_bgr = preprocess_image(img_bgr)\n",
    "    \n",
    "    if use_face_enhance:\n",
    "        _, _, output_bgr = face_enhancer.enhance(img_bgr, has_aligned=False, only_center_face=False, paste_back=True)\n",
    "    else:\n",
    "        output_bgr, _ = upsampler.enhance(img_bgr, outscale=4)\n",
    "    return cv2.cvtColor(output_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def upscale_images(images_list, face_enhancers, upsamplers, use_face_enhance=True, use_preprocess=True, desc=\"Upscaling\"):\n",
    "    return [process_single_image((img, 0, use_face_enhance, use_preprocess, face_enhancers, upsamplers)) for img in tqdm(images_list, desc=desc)]\n",
    "\n",
    "\n",
    "# ==================== Eigendecomposition ====================\n",
    "def compute_eigendecomposition(rw_kernel, k_eig, USE_GPU_EIGSH=True):\n",
    "    start_time = time.time()\n",
    "    n_samples = rw_kernel.shape[0]\n",
    "    use_truncated = k_eig < n_samples\n",
    "    _eig_result = {}\n",
    "    \n",
    "    if use_truncated:\n",
    "        print(f\"  Using TRUNCATED eigendecomposition (top {k_eig} of {n_samples})...\")\n",
    "        if USE_GPU_EIGSH and torch.cuda.is_available():\n",
    "            try:\n",
    "                rw_kernel_torch = torch.from_numpy(rw_kernel).float().to(device)\n",
    "                X0 = torch.randn(n_samples, k_eig, device=device, dtype=torch.float32)\n",
    "                eigenvalues, eigenvectors = torch.lobpcg(rw_kernel_torch, k=k_eig, X=X0, largest=True, niter=100)\n",
    "                _eig_result['lambda'] = eigenvalues.cpu().numpy()\n",
    "                _eig_result['phi'] = eigenvectors.cpu().numpy()\n",
    "                del rw_kernel_torch, X0\n",
    "                torch.cuda.empty_cache()\n",
    "            except:\n",
    "                lambda_ns_partial, phi_partial = eigsh(rw_kernel, k=k_eig, which='LM')\n",
    "                _eig_result['lambda'] = lambda_ns_partial\n",
    "                _eig_result['phi'] = phi_partial\n",
    "        else:\n",
    "            lambda_ns_partial, phi_partial = eigsh(rw_kernel, k=k_eig, which='LM')\n",
    "            _eig_result['lambda'] = lambda_ns_partial\n",
    "            _eig_result['phi'] = phi_partial\n",
    "        \n",
    "        sort_idx = np.argsort(_eig_result['lambda'])[::-1]\n",
    "        lambda_ns = _eig_result['lambda'][sort_idx]\n",
    "        phi = _eig_result['phi'][:, sort_idx]\n",
    "    else:\n",
    "        print(f\"  Using FULL eigendecomposition ({n_samples} x {n_samples})...\")\n",
    "        if torch.cuda.is_available():\n",
    "            rw_kernel_torch = torch.from_numpy(rw_kernel).to(device)\n",
    "            lambda_ns_torch, phi_torch = torch.linalg.eigh(rw_kernel_torch)\n",
    "            lambda_ns = lambda_ns_torch.cpu().numpy()[::-1].copy()\n",
    "            phi = phi_torch.cpu().numpy()[:, ::-1].copy()\n",
    "            del rw_kernel_torch\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            lambda_ns_raw, phi_raw = np.linalg.eigh(rw_kernel)\n",
    "            lambda_ns = lambda_ns_raw[::-1]\n",
    "            phi = phi_raw[:, ::-1]\n",
    "    \n",
    "    print(f\"‚úì Eigendecomposition complete! Time: {time.time() - start_time:.1f}s\")\n",
    "    return lambda_ns, phi\n",
    "\n",
    "\n",
    "# ==================== KSWGD Sampler ====================\n",
    "def run_particle_sampler(X_tar, p_tar, sq_tar, D_vec, eps_kswgd, phi_use, lambda_use, \n",
    "                        num_particles=16, num_iters=200, step_size=0.05, rng_seed=42, method=\"kswgd\"):\n",
    "    latent_dim = X_tar.shape[1]\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    use_gpu = GPU_KSWGD and torch.cuda.is_available()\n",
    "    xp = cp if use_gpu else np\n",
    "    grad_fn = grad_ker1_gpu if use_gpu else grad_ker1\n",
    "    K_eval_fn = K_tar_eval_gpu if use_gpu else K_tar_eval\n",
    "    \n",
    "    print(f\"Method: {method.upper()}, Backend: {'GPU' if use_gpu else 'CPU'}\")\n",
    "    \n",
    "    x_hist = xp.zeros((num_particles, latent_dim, num_iters), dtype=xp.float64)\n",
    "    x_hist[:, :, 0] = xp.asarray(rng.normal(0.0, 1.0, size=(num_particles, latent_dim)))\n",
    "    \n",
    "    if use_gpu:\n",
    "        X_tar_dev, p_tar_dev, sq_tar_dev, D_vec_dev = cp.asarray(X_tar), cp.asarray(p_tar), cp.asarray(sq_tar), cp.asarray(D_vec)\n",
    "        phi_dev, lambda_dev = cp.asarray(phi_use), cp.asarray(lambda_use)\n",
    "    else:\n",
    "        X_tar_dev, p_tar_dev, sq_tar_dev, D_vec_dev = X_tar, p_tar, sq_tar, D_vec\n",
    "        phi_dev, lambda_dev = phi_use, lambda_use\n",
    "    \n",
    "    for t in trange(num_iters - 1, desc=f\"{method.upper()} Transport\"):\n",
    "        current = x_hist[:, :, t]\n",
    "        grad_matrix = grad_fn(current, X_tar_dev, p_tar_dev, sq_tar_dev, D_vec_dev, eps_kswgd)\n",
    "        cross_matrix = K_eval_fn(X_tar_dev, current, p_tar_dev, sq_tar_dev, D_vec_dev, eps_kswgd)\n",
    "        tmp = (phi_dev.T @ cross_matrix) * lambda_dev[:, None]\n",
    "        push = phi_dev @ tmp\n",
    "        for dim in range(latent_dim):\n",
    "            sum_term = grad_matrix[:, :, dim] @ push\n",
    "            x_hist[:, dim, t + 1] = x_hist[:, dim, t] - (step_size / num_particles) * xp.sum(sum_term, axis=1)\n",
    "    \n",
    "    return np.asarray(xp.asnumpy(x_hist[:, :, -1]) if use_gpu else x_hist[:, :, -1], dtype=np.float64)\n",
    "\n",
    "\n",
    "def decode_latents_to_images(flat_latents_std, Z_std, Z_mean, latent_ae, vae, full_latent_shape, vae_scaling, target_device):\n",
    "    flat_latents = flat_latents_std * Z_std + Z_mean\n",
    "    \n",
    "    # Â¶ÇÊûú latent_ae ÊòØ NoneÔºåËØ¥Êòé‰∏ç‰ΩøÁî®MLPÔºåÁõ¥Êé•Áî®ÂéüÂßãlatent\n",
    "    if latent_ae is None:\n",
    "        latents_recovered = flat_latents\n",
    "    else:\n",
    "        latent_ae.eval()\n",
    "        with torch.no_grad():\n",
    "            flat_tensor = torch.from_numpy(flat_latents).float().to(target_device)\n",
    "            latents_recovered = latent_ae.decode(flat_tensor).cpu().numpy()\n",
    "    \n",
    "    latents_tensor = torch.from_numpy(latents_recovered).float().view(-1, *full_latent_shape).to(target_device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        decoded = vae.decode(latents_tensor / vae_scaling).sample\n",
    "        decoded_rgb = _from_vae_range(decoded)\n",
    "    return decoded_rgb.cpu()\n",
    "\n",
    "\n",
    "# ==================== FID Evaluation ====================\n",
    "def get_inception_features_single_gpu(images, gpu_id, batch_size=256, desc=\"Features\"):\n",
    "    device_local = torch.device(f\"cuda:{gpu_id}\")\n",
    "    block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[2048]\n",
    "    inception = InceptionV3([block_idx]).to(device_local)\n",
    "    inception.eval()\n",
    "    preprocess = T.Compose([T.Resize((299, 299)), T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    features_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(images), batch_size), desc=f\"{desc} (GPU {gpu_id})\"):\n",
    "            batch_samples = images[i:i+batch_size]\n",
    "            tensors = []\n",
    "            for img in batch_samples:\n",
    "                if isinstance(img, Image.Image):\n",
    "                    t = T.ToTensor()(img)\n",
    "                elif isinstance(img, np.ndarray):\n",
    "                    t = torch.from_numpy(img).float()\n",
    "                    if t.ndim == 3 and t.shape[2] == 3 and t.shape[0] != 3:\n",
    "                        t = t.permute(2, 0, 1)\n",
    "                    if t.max() > 1.0:\n",
    "                        t /= 255.0\n",
    "                else:\n",
    "                    t = torch.as_tensor(img).float()\n",
    "                tensors.append(t)\n",
    "            batch = torch.stack(tensors).to(device_local)\n",
    "            batch = preprocess(batch)\n",
    "            feat = inception(batch)[0].squeeze(-1).squeeze(-1)\n",
    "            features_list.append(feat.cpu().numpy())\n",
    "    del inception\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.concatenate(features_list, axis=0)\n",
    "\n",
    "def get_inception_features(images, batch_size=256, desc=\"Features\"):\n",
    "    selected_gpu_id = device.index if device.index is not None else 0\n",
    "    return get_inception_features_single_gpu(images, selected_gpu_id, batch_size, desc)\n",
    "\n",
    "def calculate_fid(real_features, gen_features):\n",
    "    mu_real, mu_gen = np.mean(real_features, axis=0), np.mean(gen_features, axis=0)\n",
    "    sigma_real, sigma_gen = np.cov(real_features, rowvar=False), np.cov(gen_features, rowvar=False)\n",
    "    diff = mu_real - mu_gen\n",
    "    offset = np.eye(sigma_real.shape[0]) * 1e-6\n",
    "    covmean, _ = linalg.sqrtm((sigma_real + offset) @ (sigma_gen + offset), disp=False)\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    return float(diff @ diff + np.trace(sigma_real + sigma_gen - 2 * covmean))\n",
    "\n",
    "def load_real_images_for_fid(dataset, n_samples, size=256, desc=\"Loading\"):\n",
    "    real_images = []\n",
    "    for i in tqdm(range(n_samples), desc=desc):\n",
    "        img = dataset[i][\"image\"]\n",
    "        if size != 1024:\n",
    "            img = img.resize((size, size))\n",
    "        real_images.append(T.ToTensor()(img).numpy() if size == 1024 else np.array(img))\n",
    "    return real_images\n",
    "\n",
    "\n",
    "# ==================== Main Experiment Function ====================\n",
    "def run_full_experiment(config, experiment_id=1):\n",
    "    \"\"\"Run the full KSWGD vs LDM comparison experiment.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"RUNNING EXPERIMENT {experiment_id} WITH CONFIG:\")\n",
    "    for k, v in config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    exp_dir = f\"/workspace/kswgd/figures/test{experiment_id}\"\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    print(f\"Output directory: {exp_dir}\")\n",
    "    \n",
    "    results = {'config': config.copy(), 'experiment_id': experiment_id, 'output_dir': exp_dir}\n",
    "    \n",
    "    # Step 1: Load Dataset\n",
    "    print(\"\\n[1/12] Loading CelebA-HQ dataset...\")\n",
    "    celebahq_dataset = None\n",
    "    for source in [\"mattymchen/celeba-hq\", \"datasets-community/CelebA-HQ\", \"xinrongzhang2022/celeba-hq\"]:\n",
    "        try:\n",
    "            celebahq_dataset = load_dataset(source, split=\"train\", cache_dir=CELEBAHQ_CACHE, trust_remote_code=True)\n",
    "            print(f\"‚úì Loaded: {source}\")\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    if celebahq_dataset is None:\n",
    "        raise RuntimeError(\"Unable to load CelebA-HQ dataset\")\n",
    "    \n",
    "    # Step 2: Load LDM\n",
    "    print(\"\\n[2/12] Loading LDM model...\")\n",
    "    print(f\"  Using GPU: {device}\")\n",
    "    ldm_pipe = DiffusionPipeline.from_pretrained(\"CompVis/ldm-celebahq-256\")\n",
    "    ldm_pipe = ldm_pipe.to(device)\n",
    "    ldm_pipe.vqvae.config.scaling_factor = 1.0\n",
    "    vae = ldm_pipe.vqvae\n",
    "    vae_scaling = 1.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dummy = torch.zeros(1, 3, 256, 256, device=device)\n",
    "        dummy_latent = vae.encode(_to_vae_range(dummy))\n",
    "        full_latent_shape = (dummy_latent.latents if hasattr(dummy_latent, 'latents') else dummy_latent[0]).shape[1:]\n",
    "    print(f\"‚úì LDM loaded! Latent shape: {full_latent_shape}\")\n",
    "    \n",
    "    # Step 3: Initialize Upscalers\n",
    "    print(\"\\n[3/12] Initializing GFPGAN upscalers...\")\n",
    "    gpu_id = device.index if device.index is not None else 0\n",
    "    u, f = create_upscaler(gpu_id)\n",
    "    upsamplers, face_enhancers = [u], [f]\n",
    "    print(f\"‚úì Upscalers initialized on GPU {gpu_id}\")\n",
    "    \n",
    "    # Step 4: Encode Images\n",
    "    print(f\"\\n[4/12] Encoding {config['max_samples']} images...\")\n",
    "    use_mlp = config['reduced_dim'] < 1024\n",
    "    \n",
    "    if use_mlp:\n",
    "        cache_path = os.path.join(CACHE_DIR, f\"vae_n{config['max_samples']}_mlp{config['reduced_dim']}_h{config['mlp_hidden_dim']}_e{config['mlp_epochs']}.pkl\")\n",
    "    else:\n",
    "        cache_path = os.path.join(CACHE_DIR, f\"vae_n{config['max_samples']}_nomlp.pkl\")\n",
    "        print(\"  ‚ö†Ô∏è reduced_dim >= 1024, ‰∏ç‰ΩøÁî®MLPÂéãÁº©ÔºåÁõ¥Êé•Áî®VAE latent\")\n",
    "    \n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"  Loading from cache: {cache_path}\")\n",
    "        with open(cache_path, 'rb') as f_cache:\n",
    "            cache_data = pickle.load(f_cache)\n",
    "        Z_all = cache_data['Z_all']\n",
    "        latent_ae = cache_data.get('latent_ae', None)\n",
    "        full_latent_shape = cache_data.get('full_latent_shape', full_latent_shape)\n",
    "    else:\n",
    "        all_latents = []\n",
    "        vae.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(min(config['max_samples'], len(celebahq_dataset))), desc=\"Encoding\"):\n",
    "                img = celebahq_dataset[i][\"image\"]\n",
    "                img_tensor = transform_celebahq(img).unsqueeze(0).to(device)\n",
    "                latent = vae.encode(_to_vae_range(img_tensor))\n",
    "                latent_code = latent.latents if hasattr(latent, 'latents') else latent[0]\n",
    "                all_latents.append((latent_code * vae_scaling).view(1, -1).cpu().numpy())\n",
    "        Z_flat = np.concatenate(all_latents, axis=0)\n",
    "        \n",
    "        if use_mlp:\n",
    "            latent_ae, Z_all = train_latent_autoencoder(Z_flat, latent_dim=config['reduced_dim'], hidden_dim=config['mlp_hidden_dim'], epochs=config['mlp_epochs'])\n",
    "        else:\n",
    "            latent_ae = None\n",
    "            Z_all = Z_flat\n",
    "            print(f\"  ‚úì ‰ΩøÁî®ÂéüÂßãVAE latentÔºåÁª¥Â∫¶: {Z_all.shape[1]}\")\n",
    "        \n",
    "        with open(cache_path, 'wb') as f_cache:\n",
    "            pickle.dump({'Z_all': Z_all, 'latent_ae': latent_ae, 'full_latent_shape': full_latent_shape}, f_cache)\n",
    "    \n",
    "    print(f\"  ‚úì Z_all shape: {Z_all.shape}\")\n",
    "    \n",
    "    # Step 5: Build Kernel Matrix\n",
    "    print(\"\\n[5/12] Building kernel matrix...\")\n",
    "    Z_mean = np.mean(Z_all, axis=0, keepdims=True).astype(np.float64)\n",
    "    Z_std = (np.std(Z_all, axis=0, keepdims=True) + 1e-8).astype(np.float64)\n",
    "    X_tar = ((Z_all - Z_mean) / Z_std).astype(np.float64)\n",
    "    sq_tar = np.sum(X_tar ** 2, axis=1)\n",
    "    dists = pairwise_distances(X_tar, metric=\"euclidean\")\n",
    "    eps_kswgd = float(max(np.median(dists**2) / (2.0 * np.log(X_tar.shape[0] + 1)), 1e-6))\n",
    "    data_kernel = np.exp(-dists**2 / (2.0 * eps_kswgd))\n",
    "    p_x = np.sqrt(np.sum(data_kernel, axis=1))\n",
    "    data_kernel_norm = data_kernel / (p_x[:, None] * p_x[None, :] + 1e-12)\n",
    "    D_y = np.sum(data_kernel_norm, axis=0)\n",
    "    rw_kernel = 0.5 * (data_kernel_norm / (D_y + 1e-12) + data_kernel_norm / (D_y[:, None] + 1e-12))\n",
    "    rw_kernel = np.nan_to_num(rw_kernel)\n",
    "    p_tar = np.sum(data_kernel, axis=0)\n",
    "    sqrt_p = np.sqrt(p_tar + 1e-12)\n",
    "    D_vec = np.sum(data_kernel / sqrt_p[:, None] / sqrt_p[None, :], axis=1)\n",
    "    print(f\"‚úì Kernel matrix built: {rw_kernel.shape}\")\n",
    "    \n",
    "    # Step 6: Eigendecomposition\n",
    "    print(f\"\\n[6/12] Computing eigendecomposition (k={config['k_eig']})...\")\n",
    "    lambda_ns, phi = compute_eigendecomposition(rw_kernel, config['k_eig'])\n",
    "    tol, reg = 1e-6, 1e-3\n",
    "    above_tol = int(np.sum(lambda_ns >= tol))\n",
    "    lambda_ = lambda_ns - 1.0\n",
    "    inv_lambda = np.zeros_like(lambda_)\n",
    "    inv_lambda[1:][lambda_[1:] > tol] = 1.0 / (np.abs(lambda_[1:][lambda_[1:] > tol]) + reg)\n",
    "    inv_lambda *= eps_kswgd\n",
    "    lambda_ns_inv = np.zeros_like(lambda_ns)\n",
    "    lambda_ns_inv[lambda_ns >= tol] = eps_kswgd / (lambda_ns[lambda_ns >= tol] + reg)\n",
    "    phi_trunc = phi[:, :above_tol]\n",
    "    lambda_ns_s_ns = np.nan_to_num((lambda_ns_inv * inv_lambda * lambda_ns_inv)[:above_tol])\n",
    "    print(f\"‚úì {above_tol} modes retained\")\n",
    "    \n",
    "    # Step 7: EDMD\n",
    "    print(f\"\\n[7/12] Computing EDMD with dt={config['dt_edmd']}...\")\n",
    "    dist2_edmd = pairwise_distances(X_tar, metric=\"sqeuclidean\")\n",
    "    h_edmd = np.sqrt(np.median(dist2_edmd) + 1e-12)\n",
    "    W_edmd = np.exp(-dist2_edmd / (2.0 * h_edmd ** 2))\n",
    "    score_edmd = (W_edmd @ X_tar / (np.sum(W_edmd, axis=1, keepdims=True) + 1e-12) - X_tar) / (h_edmd ** 2)\n",
    "    X_tar_next = X_tar + config['dt_edmd'] * score_edmd + np.sqrt(2.0 * config['dt_edmd']) * np.random.normal(0, 1, X_tar.shape)\n",
    "    \n",
    "    dict_model = MiniBatchDictionaryLearning(n_components=config['n_dict_components'], alpha=1e-3, batch_size=256, max_iter=500, random_state=42, fit_algorithm=\"lars\")\n",
    "    dict_model.fit(X_tar)\n",
    "    Phi_X = np.hstack([np.ones((X_tar.shape[0], 1)), dict_model.transform(X_tar)])\n",
    "    Phi_Y = np.hstack([np.ones((X_tar_next.shape[0], 1)), dict_model.transform(X_tar_next)])\n",
    "    N_edmd, m_edmd = Phi_X.shape\n",
    "    G_edmd = (Phi_X.T @ Phi_X) / N_edmd + 1e-3 * np.eye(m_edmd)\n",
    "    A_edmd = (Phi_X.T @ Phi_Y) / N_edmd\n",
    "    eigvals_edmd, eigvecs_edmd = eig(A_edmd, G_edmd)\n",
    "    idx_edmd = np.argsort(-eigvals_edmd.real)\n",
    "    eigvals_edmd, eigvecs_edmd = eigvals_edmd[idx_edmd], eigvecs_edmd[:, idx_edmd]\n",
    "    efuns_edmd = Phi_X @ eigvecs_edmd\n",
    "    \n",
    "    lambda_ns_edmd = eigvals_edmd.real\n",
    "    lambda_gen_edmd = (lambda_ns_edmd - 1.0) / config['dt_edmd']\n",
    "    valid_idx = np.arange(1, lambda_ns_edmd.shape[0])[lambda_ns_edmd[1:] > 1e-6]\n",
    "    phi_trunc_edmd = np.real(efuns_edmd[:, valid_idx])\n",
    "    lambda_gen_inv = np.zeros_like(lambda_gen_edmd)\n",
    "    lambda_gen_inv[np.abs(lambda_gen_edmd) > 1e-6] = 1.0 / lambda_gen_edmd[np.abs(lambda_gen_edmd) > 1e-6]\n",
    "    lambda_ns_s_ns_edmd = lambda_gen_inv[valid_idx].real\n",
    "    print(f\"‚úì EDMD complete: {valid_idx.size} Koopman modes\")\n",
    "    \n",
    "    # Step 8: Run KSWGD\n",
    "    print(f\"\\n[8/12] Running KSWGD...\")\n",
    "    start_time = time.time()\n",
    "    Z_kswgd_std = run_particle_sampler(X_tar, p_tar, sq_tar, D_vec, eps_kswgd, phi_trunc_edmd, lambda_ns_s_ns_edmd,\n",
    "                                       num_particles=config['kswgd_num_particles'], num_iters=config['kswgd_num_iters'],\n",
    "                                       step_size=config['kswgd_step_size'], rng_seed=42, method=\"kswgd\")\n",
    "    kswgd_time = time.time() - start_time\n",
    "    results['kswgd_time'] = kswgd_time\n",
    "    print(f\"‚úì KSWGD complete! Time: {kswgd_time:.1f}s\")\n",
    "    \n",
    "    # Step 9: Decode KSWGD Images\n",
    "    print(\"\\n[9/12] Decoding KSWGD images...\")\n",
    "    vae = vae.to(device)\n",
    "    if latent_ae is not None:\n",
    "        latent_ae = latent_ae.to(device)\n",
    "    all_kswgd_images = []\n",
    "    for i in tqdm(range(0, Z_kswgd_std.shape[0], 128), desc=\"Decoding\"):\n",
    "        batch = decode_latents_to_images(Z_kswgd_std[i:i+128], Z_std, Z_mean, latent_ae, vae, full_latent_shape, vae_scaling, device)\n",
    "        all_kswgd_images.append(batch.numpy())\n",
    "    kswgd_images_np = np.concatenate(all_kswgd_images, axis=0)\n",
    "    \n",
    "    kswgd_for_upscale = [np.clip(np.transpose(kswgd_images_np[i], (1, 2, 0)), 0, 1) for i in range(kswgd_images_np.shape[0])]\n",
    "    kswgd_upscaled = upscale_images(kswgd_for_upscale, face_enhancers, upsamplers, desc=\"KSWGD GFPGAN\")\n",
    "    \n",
    "    n_grid = min(16, len(kswgd_upscaled))\n",
    "    print(f\"  Saving KSWGD grid ({n_grid} of {len(kswgd_upscaled)} images)...\")\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < n_grid:\n",
    "            ax.imshow(kswgd_upscaled[idx])\n",
    "            ax.set_title(f\"KSWGD #{idx+1}\")\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(f\"KSWGD Enhanced - Test {experiment_id}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(exp_dir, \"kswgd_grid.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Step 10: KSWGD FID (DISABLED FOR DEBUG)\n",
    "    # print(\"\\n[10/12] Computing KSWGD FID...\")\n",
    "    # n_real = min(10000, len(celebahq_dataset))\n",
    "    # real_256 = load_real_images_for_fid(celebahq_dataset, n_real, 256, \"Real (256)\")\n",
    "    # real_feat_256 = get_inception_features(real_256, desc=\"Real (256)\")\n",
    "    # kswgd_feat_256 = get_inception_features(kswgd_images_np, desc=\"KSWGD (256)\")\n",
    "    # fid_kswgd_raw = calculate_fid(real_feat_256, kswgd_feat_256)\n",
    "    # del real_256; gc.collect()\n",
    "    # \n",
    "    # real_1024 = load_real_images_for_fid(celebahq_dataset, n_real, 1024, \"Real (1024)\")\n",
    "    # real_feat_1024 = get_inception_features(real_1024, desc=\"Real (1024)\")\n",
    "    # kswgd_feat_1024 = get_inception_features(kswgd_upscaled, desc=\"KSWGD (1024)\")\n",
    "    # fid_kswgd_enhanced = calculate_fid(real_feat_1024, kswgd_feat_1024)\n",
    "    # results['fid_kswgd_raw'], results['fid_kswgd_enhanced'] = fid_kswgd_raw, fid_kswgd_enhanced\n",
    "    # print(f\"‚úì KSWGD FID: Raw={fid_kswgd_raw:.2f}, Enhanced={fid_kswgd_enhanced:.2f}\")\n",
    "    fid_kswgd_raw, fid_kswgd_enhanced = -1.0, -1.0  # Placeholder for debug mode\n",
    "    results['fid_kswgd_raw'], results['fid_kswgd_enhanced'] = fid_kswgd_raw, fid_kswgd_enhanced\n",
    "    print(\"[10/12] KSWGD FID calculation SKIPPED (debug mode)\")\n",
    "    \n",
    "    del kswgd_images_np, kswgd_upscaled; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "    # Step 11: Run LDM\n",
    "    print(f\"\\n[11/12] Running LDM...\")\n",
    "    ldm_pipe = DiffusionPipeline.from_pretrained(\"CompVis/ldm-celebahq-256\").to(device)\n",
    "    ldm_pipe.vqvae.config.scaling_factor = 1.0\n",
    "    ldm_pipe.set_progress_bar_config(disable=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ldm_images = []\n",
    "    for batch_idx in tqdm(range((config['kswgd_num_particles'] + 63) // 64), desc=\"LDM\"):\n",
    "        bs = min(64, config['kswgd_num_particles'] - batch_idx * 64)\n",
    "        ldm_images.extend(ldm_pipe(batch_size=bs, num_inference_steps=200).images)\n",
    "    ldm_time = time.time() - start_time\n",
    "    results['ldm_time'] = ldm_time\n",
    "    print(f\"‚úì LDM complete! Time: {ldm_time:.1f}s\")\n",
    "    \n",
    "    ldm_upscaled = upscale_images(ldm_images, face_enhancers, upsamplers, desc=\"LDM GFPGAN\")\n",
    "    \n",
    "    n_grid_ldm = min(16, len(ldm_upscaled))\n",
    "    print(f\"  Saving LDM grid ({n_grid_ldm} of {len(ldm_upscaled)} images)...\")\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        if idx < n_grid_ldm:\n",
    "            ax.imshow(ldm_upscaled[idx])\n",
    "            ax.set_title(f\"LDM #{idx+1}\")\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(f\"LDM Enhanced - Test {experiment_id}\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(exp_dir, \"ldm_grid.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Step 12: LDM FID (DISABLED FOR DEBUG)\n",
    "    # print(\"\\n[12/12] Computing LDM FID...\")\n",
    "    # real_256 = load_real_images_for_fid(celebahq_dataset, n_real, 256, \"Real (256)\")\n",
    "    # real_feat_256 = get_inception_features(real_256, desc=\"Real (256)\")\n",
    "    # ldm_feat_256 = get_inception_features(ldm_images, desc=\"LDM (256)\")\n",
    "    # fid_ldm_raw = calculate_fid(real_feat_256, ldm_feat_256)\n",
    "    # del real_256; gc.collect()\n",
    "    # \n",
    "    # real_1024 = load_real_images_for_fid(celebahq_dataset, n_real, 1024, \"Real (1024)\")\n",
    "    # real_feat_1024 = get_inception_features(real_1024, desc=\"Real (1024)\")\n",
    "    # ldm_feat_1024 = get_inception_features(ldm_upscaled, desc=\"LDM (1024)\")\n",
    "    # fid_ldm_enhanced = calculate_fid(real_feat_1024, ldm_feat_1024)\n",
    "    # results['fid_ldm_raw'], results['fid_ldm_enhanced'] = fid_ldm_raw, fid_ldm_enhanced\n",
    "    # print(f\"‚úì LDM FID: Raw={fid_ldm_raw:.2f}, Enhanced={fid_ldm_enhanced:.2f}\")\n",
    "    fid_ldm_raw, fid_ldm_enhanced = -1.0, -1.0  # Placeholder for debug mode\n",
    "    results['fid_ldm_raw'], results['fid_ldm_enhanced'] = fid_ldm_raw, fid_ldm_enhanced\n",
    "    print(\"[12/12] LDM FID calculation SKIPPED (debug mode)\")\n",
    "    \n",
    "    del ldm_images, ldm_upscaled; gc.collect(); torch.cuda.empty_cache()\n",
    "    \n",
    "    # Print & Save Results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EXPERIMENT RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Method':<25} {'Resolution':<15} {'FID':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'KSWGD':<25} {'256x256':<15} {fid_kswgd_raw:.2f}\")\n",
    "    print(f\"{'KSWGD + GFPGAN':<25} {'1024x1024':<15} {fid_kswgd_enhanced:.2f}\")\n",
    "    print(f\"{'LDM':<25} {'256x256':<15} {fid_ldm_raw:.2f}\")\n",
    "    print(f\"{'LDM + GFPGAN':<25} {'1024x1024':<15} {fid_ldm_enhanced:.2f}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    config_path = os.path.join(exp_dir, \"experiment_config.txt\")\n",
    "    with open(config_path, 'w') as f_out:\n",
    "        f_out.write(f\"{'='*60}\\nEXPERIMENT {experiment_id} CONFIG & RESULTS\\n{'='*60}\\n\")\n",
    "        f_out.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "        f_out.write(\"PARAMETERS:\\n\")\n",
    "        for k, v in config.items():\n",
    "            f_out.write(f\"  {k}: {v}\\n\")\n",
    "        f_out.write(f\"\\nRESULTS:\\n\")\n",
    "        f_out.write(f\"  KSWGD Raw FID: {fid_kswgd_raw:.4f}\\n\")\n",
    "        f_out.write(f\"  KSWGD Enhanced FID: {fid_kswgd_enhanced:.4f}\\n\")\n",
    "        f_out.write(f\"  LDM Raw FID: {fid_ldm_raw:.4f}\\n\")\n",
    "        f_out.write(f\"  LDM Enhanced FID: {fid_ldm_enhanced:.4f}\\n\")\n",
    "        f_out.write(f\"\\nTIMING:\\n\")\n",
    "        f_out.write(f\"  KSWGD: {kswgd_time:.1f}s\\n\")\n",
    "        f_out.write(f\"  LDM: {ldm_time:.1f}s\\n\")\n",
    "    print(f\"‚úì Config saved to: {config_path}\")\n",
    "    \n",
    "\n",
    "    return results\n",
    "    return resultsprint(\"‚úì All functions defined!\")\n",
    "\n",
    "\n",
    "print(\"‚úì All functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe30fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Cell 3: Parameter Grid and Iteration Loop ==============\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# Verify we're using the GPU selected in Cell 1\n",
    "print(f\"üéØ Using device from Cell 1: {device}\")\n",
    "print(f\"   SELECTED_GPU = {SELECTED_GPU}\")\n",
    "\n",
    "# ==================== Define Parameter Grid ====================\n",
    "# DEBUG MODE - Significantly reduced parameters for quick testing\n",
    "DEBUG_MODE = False\n",
    "print(\"‚úì PRODUCTION MODE - Using full parameters\")\n",
    "\n",
    "# Production parameters\n",
    "DEBUG_MAX_SAMPLES = 28000\n",
    "DEBUG_NUM_PARTICLES = 16\n",
    "DEBUG_MLP_EPOCHS = 300\n",
    "DEBUG_K_EIG = 1000\n",
    "DEBUG_N_DICT = 300\n",
    "DEBUG_KSWGD_ITERS = 300\n",
    "\n",
    "# ==================== Simplified Experiment Design ====================\n",
    "# - dt_edmd: [0.05, 0.1, 0.5] - 3 choices\n",
    "# - kswgd_step_size: [0.05, 0.1, 0.5] - 3 choices\n",
    "# - reduced_dim: fixed at 8\n",
    "# - mlp_hidden_dim: fixed at 512\n",
    "\n",
    "dt_edmd_values = [0.05, 0.1, 0.5]\n",
    "kswgd_step_size_values = [0.05, 0.1, 0.5]\n",
    "\n",
    "configs_to_run = []\n",
    "for dt in dt_edmd_values:\n",
    "    for step_size in kswgd_step_size_values:\n",
    "        configs_to_run.append({\n",
    "            'dt_edmd': dt,\n",
    "            'mlp_epochs': DEBUG_MLP_EPOCHS,\n",
    "            'mlp_hidden_dim': 512,\n",
    "            'reduced_dim': 8,\n",
    "            'k_eig': DEBUG_K_EIG,\n",
    "            'n_dict_components': DEBUG_N_DICT,\n",
    "            'kswgd_num_particles': DEBUG_NUM_PARTICLES,\n",
    "            'kswgd_num_iters': DEBUG_KSWGD_ITERS,\n",
    "            'kswgd_step_size': step_size,\n",
    "            'max_samples': DEBUG_MAX_SAMPLES,\n",
    "        })\n",
    "\n",
    "print(f\"üìã SELECTED CONFIGS: {len(configs_to_run)} experiments (3 x 3 = 9)\")\n",
    "print(f\"\\nüîß Parameter settings:\")\n",
    "print(f\"  max_samples: {DEBUG_MAX_SAMPLES}\")\n",
    "print(f\"  num_particles: {DEBUG_NUM_PARTICLES}\")\n",
    "print(f\"  mlp_epochs: {DEBUG_MLP_EPOCHS}\")\n",
    "print(f\"  k_eig: {DEBUG_K_EIG}\")\n",
    "print(f\"  n_dict_components: {DEBUG_N_DICT}\")\n",
    "print(f\"  kswgd_num_iters: {DEBUG_KSWGD_ITERS}\")\n",
    "print(f\"\\nüìä Experiment design:\")\n",
    "print(f\"  Fixed: reduced_dim=8, mlp_hidden_dim=512\")\n",
    "print(f\"  Variable: dt_edmd={dt_edmd_values}\")\n",
    "print(f\"  Variable: kswgd_step_size={kswgd_step_size_values}\")\n",
    "\n",
    "# ==================== Run Experiments ====================\n",
    "all_results = []\n",
    "results_save_path = f\"/workspace/kswgd/cache/iteration_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "\n",
    "# Sequential execution on the selected GPU\n",
    "for i, config in enumerate(configs_to_run):\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# EXPERIMENT {i+1}/{len(configs_to_run)} on GPU {SELECTED_GPU}\")\n",
    "    print(f\"#   dt_edmd={config['dt_edmd']}, reduced_dim={config['reduced_dim']}, mlp_hidden={config['mlp_hidden_dim']}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    try:\n",
    "        result = run_full_experiment(config, experiment_id=i+1)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Save intermediate results\n",
    "        with open(results_save_path, 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "        print(f\"\\n‚úì Results saved to {results_save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Experiment failed with error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        all_results.append({'config': config, 'error': str(e)})\n",
    "        \n",
    "        # Still save failed results\n",
    "        with open(results_save_path, 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "    \n",
    "    # Memory cleanup between experiments\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ==================== Summary ====================\n",
    "all_results_sorted = sorted(all_results, key=lambda x: x.get('experiment_id', 0))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 110)\n",
    "print(\"FINAL SUMMARY - ALL EXPERIMENTS\")\n",
    "print(\"=\" * 110)\n",
    "print(f\"{'#':<3} {'dt_edmd':<8} {'reduced':<8} {'hidden':<8} {'epochs':<8} {'KSWGD Raw':<12} {'KSWGD Enh':<12} {'LDM Raw':<12} {'LDM Enh':<12}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "for result in all_results_sorted:\n",
    "    exp_id = result.get('experiment_id', '?')\n",
    "    if 'error' in result:\n",
    "        print(f\"{exp_id:<3} ERROR: {result['error'][:60]}...\")\n",
    "    else:\n",
    "        cfg = result['config']\n",
    "        print(f\"{exp_id:<3} {cfg['dt_edmd']:<8.2f} {cfg['reduced_dim']:<8} {cfg['mlp_hidden_dim']:<8} {cfg['mlp_epochs']:<8} {result['fid_kswgd_raw']:<12.2f} {result['fid_kswgd_enhanced']:<12.2f} {result['fid_ldm_raw']:<12.2f} {result['fid_ldm_enhanced']:<12.2f}\")\n",
    "\n",
    "print(\"=\" * 110)\n",
    "print(f\"\\nResults saved to: {results_save_path}\")\n",
    "print(\"\\n‚ö†Ô∏è DEBUG MODE parameters are significantly reduced. Restore normal values after testing passes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kswgd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
