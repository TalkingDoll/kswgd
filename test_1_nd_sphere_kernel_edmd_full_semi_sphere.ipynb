{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1eb8ebc",
   "metadata": {},
   "source": [
    "# Kernel EDMD + LAWGD Implementation\n",
    "\n",
    "This notebook implements **Kernel Extended Dynamic Mode Decomposition (EDMD)** combined with **Langevin-Adjusted Wasserstein Gradient Descent (LAWGD)**.\n",
    "\n",
    "## Key Differences from Standard DMPS\n",
    "\n",
    "1. **Kernel-EDMD** learns the Koopman operator from time-evolved data pairs\n",
    "2. **X_tar_next** generated via manifold-constrained Langevin dynamics:\n",
    "   - KDE-based score estimation: ∇log π(x)\n",
    "   - Tangent space projection for manifold constraint\n",
    "   - Euler-Maruyama update with diffusion coefficient √2\n",
    "   - Renormalization to stay on the sphere\n",
    "   - Reflecting boundary (for semi-circle) to keep data in physical domain\n",
    "3. **Koopman operator**: K = K_xy @ (K_xx + γI)^{-1}\n",
    "4. Subsequent DMPS-style normalization and spectral decomposition\n",
    "5. **LAWGD particle transport**: NO artificial boundary (data-driven learning)\n",
    "\n",
    "## Boundary Conditions Philosophy\n",
    "\n",
    "### CRITICAL DISTINCTION:\n",
    "\n",
    "**1. DATA GENERATION (X_tar, X_tar_next):**\n",
    "- Represents the TRUE PHYSICAL SYSTEM\n",
    "- For semi-circle: Apply reflecting boundary (y < 0 → y > 0)\n",
    "- Reason: The real system HAS this boundary constraint\n",
    "- This is NOT artificial - it's the ground truth dynamics\n",
    "\n",
    "**2. LAWGD PARTICLE TRANSPORT (x_t iteration):**\n",
    "- DATA-DRIVEN LEARNING process\n",
    "- NO artificial boundary operations\n",
    "- Reason: We want the Koopman operator to LEARN the boundary behavior\n",
    "- If Koopman learns correctly, particles will naturally stay in domain\n",
    "- Adding artificial boundaries would defeat the purpose of learning\n",
    "\n",
    "**Philosophy**: The algorithm should learn FROM data (which has boundaries), not be artificially constrained DURING learning (which is cheating)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac495c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and GPU/CPU Backend Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd, eigh\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# --------------- Optional GPU backend (CuPy) ---------------\n",
    "USE_GPU = True  # set False to force CPU even if CuPy is available\n",
    "try:  # Attempt to import cupy\n",
    "    import cupy as cp  # type: ignore\n",
    "    GPU_AVAILABLE = True\n",
    "except Exception:\n",
    "    cp = None  # type: ignore\n",
    "    GPU_AVAILABLE = False\n",
    "USE_GPU = bool(USE_GPU and GPU_AVAILABLE)\n",
    "if USE_GPU:\n",
    "    from grad_ker1_gpu import grad_ker1  # xp-aware versions\n",
    "    from K_tar_eval_gpu import K_tar_eval\n",
    "else:\n",
    "    from grad_ker1 import grad_ker1      # CPU fallbacks\n",
    "    from K_tar_eval import K_tar_eval\n",
    "\n",
    "print(f\"[DEVICE] {'GPU' if USE_GPU else 'CPU'} mode active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725d245",
   "metadata": {},
   "source": [
    "## 2. Define Timing and Progress Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6248b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Timing / Progress Utilities ----------------\n",
    "def _fmt_secs(s: float) -> str:\n",
    "    s = max(0.0, float(s))\n",
    "    h = int(s // 3600)\n",
    "    m = int((s % 3600) // 60)\n",
    "    sec = int(s % 60)\n",
    "    if h > 0:\n",
    "        return f\"{h:02d}:{m:02d}:{sec:02d}\"\n",
    "    return f\"{m:02d}:{sec:02d}\"\n",
    "\n",
    "def _print_phase(name: str, t_start: float) -> float:\n",
    "    dt = time.time() - t_start\n",
    "    print(f\"[TIMER] {name}: {dt:.3f}s\")\n",
    "    return time.time()\n",
    "\n",
    "_LAST_PROGRESS_LEN = 0\n",
    "def _print_progress(curr: int, total: int, start_time: float, prefix: str = \"\") -> None:\n",
    "    global _LAST_PROGRESS_LEN\n",
    "    total = max(1, int(total))\n",
    "    curr = min(max(0, curr), total)\n",
    "    bar_len = 30\n",
    "    filled = int(bar_len * curr / total)\n",
    "    filled = min(filled, bar_len)\n",
    "    bar = (\"=\" * filled) + (\">\" if filled < bar_len else \"\") + (\".\" * max(0, bar_len - filled - (0 if filled == bar_len else 1)))\n",
    "    pct = 100.0 * curr / total\n",
    "    elapsed = time.time() - start_time\n",
    "    avg = elapsed / max(1, curr)\n",
    "    eta = avg * (total - curr)\n",
    "    msg = f\"{prefix}[{bar}] {pct:5.1f}% | iter {curr}/{total} | elapsed {_fmt_secs(elapsed)} | eta {_fmt_secs(eta)}\"\n",
    "    prev = _LAST_PROGRESS_LEN\n",
    "    clear = \"\\r\" + (\" \" * prev) + \"\\r\"\n",
    "    print(clear, end=\"\")\n",
    "    print(msg, end=\"\", flush=True)\n",
    "    _LAST_PROGRESS_LEN = len(msg)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "_t = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8e3729",
   "metadata": {},
   "source": [
    "## 3. Configuration Parameters\n",
    "\n",
    "- `USE_SEMICIRCLE`: True for semi-circle, False for full circle\n",
    "- `KERNEL_TYPE`: Kernel selection (1: RBF, 2: Spherical, 3: Matérn, 4: Rational Quadratic, 5: Polynomial)\n",
    "- `n`: Number of target sample points (500)\n",
    "- `d`: Dimensions (2D)\n",
    "- `lambda_`: Anisotropy parameter (1 means isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Configuration ----------------\n",
    "USE_SEMICIRCLE = False  # Set False for full circle, True for semi-circle (upper half)\n",
    "KERNEL_TYPE = 5  # 1: RBF, 2: Spherical, 3: Matérn, 4: Rational Quadratic, 5: Polynomial\n",
    "\n",
    "# Sample 500 points from a circle or semi-circle\n",
    "n = 500\n",
    "d = 2\n",
    "lambda_ = 1  # Anisotropy parameter (stretches along x-axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a3fe9",
   "metadata": {},
   "source": [
    "## 4. Generate Target Distribution Samples (X_tar)\n",
    "\n",
    "Using rejection sampling for semi-circle or Gaussian sampling for full circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a0e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SEMICIRCLE:\n",
    "    # Rejection Sampling for semi-circle\n",
    "    samples = []\n",
    "    while len(samples) < n:\n",
    "        batch_size = max(n - len(samples), int((n - len(samples)) * 2.5))\n",
    "        u = np.random.normal(0, 1, (batch_size, d))\n",
    "        u[:, 0] = lambda_ * u[:, 0]  # Apply anisotropy\n",
    "        u_norm = np.linalg.norm(u, axis=1, keepdims=True)\n",
    "        u_trans = u / (u_norm + 1e-12)\n",
    "        valid = u_trans[:, 1] >= 0  # Filter for y >= 0\n",
    "        samples.append(u_trans[valid, :])\n",
    "    u_trans = np.vstack(samples)[:n, :]\n",
    "    label = \"semi-circle\"\n",
    "else:\n",
    "    # Gaussian Sampling for full circle\n",
    "    u = np.random.normal(0, 1, (n, d))\n",
    "    u[:, 0] = lambda_ * u[:, 0]\n",
    "    u_norm = np.linalg.norm(u, axis=1, keepdims=True)\n",
    "    u_trans = u / (u_norm + 1e-12)\n",
    "    label = \"full circle\"\n",
    "\n",
    "# Radial distance: slightly randomized around radius 1\n",
    "r = np.sqrt(np.random.rand(n, 1)) * 1/100 + 99/100\n",
    "X_tar = r * u_trans\n",
    "n = X_tar.shape[0]\n",
    "print(f\"Generated {n} points on {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e14718",
   "metadata": {},
   "source": [
    "## 5. Kernel EDMD: Generate X_tar_next via Manifold Langevin Dynamics\n",
    "\n",
    "**Key Steps:**\n",
    "1. KDE-based score estimation (drift term): ∇log π(x)\n",
    "2. Project to tangent space (manifold constraint)\n",
    "3. Langevin update with manifold-projected noise\n",
    "4. Renormalize to stay on the sphere\n",
    "5. Apply reflecting boundary for semi-circle\n",
    "\n",
    "**Critical Fix**: Increased `dt_edmd` and `noise_multiplier` to ensure 15-30% particles cross boundary, teaching Koopman operator about boundary behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: KDE-based score estimation (drift term)\n",
    "dt_edmd = 5e-2  # Sampling time\n",
    "diffs_edmd = X_tar[:, None, :] - X_tar[None, :, :]\n",
    "dist2_edmd = np.sum(diffs_edmd ** 2, axis=2)\n",
    "h_edmd = np.sqrt(np.median(dist2_edmd) + 1e-12)\n",
    "W_edmd = np.exp(-dist2_edmd / (2.0 * (h_edmd ** 2)))\n",
    "sumW_edmd = np.sum(W_edmd, axis=1, keepdims=True) + 1e-12\n",
    "weighted_means_edmd = (W_edmd @ X_tar) / sumW_edmd\n",
    "score_eucl = (weighted_means_edmd - X_tar) / (h_edmd ** 2)\n",
    "\n",
    "# Step 2: Project to tangent space\n",
    "X_norm = X_tar / (np.linalg.norm(X_tar, axis=1, keepdims=True) + 1e-12)\n",
    "proj = np.eye(X_tar.shape[1])[None, :, :] - X_norm[:, :, None] * X_norm[:, None, :]\n",
    "score_tan = np.einsum('nij,ni->nj', proj, score_eucl)\n",
    "\n",
    "# Step 3: Langevin update with manifold-projected noise\n",
    "noise_multiplier = 3.0  # Amplify noise for better boundary exploration\n",
    "xi_edmd = np.random.normal(0.0, 1.0, size=X_tar.shape)\n",
    "xi_tan = xi_edmd - (np.sum(X_norm * xi_edmd, axis=1, keepdims=True)) * X_norm\n",
    "X_step = X_norm + dt_edmd * score_tan + noise_multiplier * np.sqrt(2.0 * dt_edmd) * xi_tan\n",
    "\n",
    "# Step 4: Renormalize to stay on the sphere\n",
    "X_tar_next = X_step / (np.linalg.norm(X_step, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "# Step 5: Apply reflecting boundary for semi-circle\n",
    "if USE_SEMICIRCLE:\n",
    "    crossed_boundary = X_tar_next[:, 1] < 0\n",
    "    num_crossed = np.sum(crossed_boundary)\n",
    "    \n",
    "    if num_crossed > 0:\n",
    "        X_tar_next[crossed_boundary, 1] = -X_tar_next[crossed_boundary, 1]\n",
    "        print(f\"[BOUNDARY FIX] Applied reflection to {num_crossed}/{n} points ({100*num_crossed/n:.1f}%)\")\n",
    "        print(f\"[BOUNDARY INFO] This teaches Koopman operator about boundary dynamics!\")\n",
    "    else:\n",
    "        print(f\"[BOUNDARY WARNING] No particles crossed boundary!\")\n",
    "        print(f\"[BOUNDARY HINT] Consider increasing dt_edmd or noise_multiplier\")\n",
    "\n",
    "# Verify X_tar_next is strictly on semi-circle\n",
    "if USE_SEMICIRCLE:\n",
    "    min_y = np.min(X_tar_next[:, 1])\n",
    "    if min_y < -1e-10:\n",
    "        print(f\"[WARNING] X_tar_next has points below y=0! min_y = {min_y:.6e}\")\n",
    "    else:\n",
    "        print(f\"[VERIFIED] X_tar_next strictly on semi-circle (min_y = {min_y:.6e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bac8f",
   "metadata": {},
   "source": [
    "## 6. Visualize Time Evolution Pair (X_tar vs X_tar_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_names = {1: \"RBF\", 2: \"Spherical\", 3: \"Matérn\", 4: \"Rational Quadratic\", 5: \"Polynomial\"}\n",
    "kernel_display = kernel_names.get(KERNEL_TYPE, \"Unknown\")\n",
    "\n",
    "if d == 2:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(X_tar[:, 0], X_tar[:, 1], s=10, c='C0', alpha=0.6, label='X_tar (current)')\n",
    "    plt.scatter(X_tar_next[:, 0], X_tar_next[:, 1], s=10, c='C1', alpha=0.6, label='X_tar_next (evolved)')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "    plt.title(f'Kernel-EDMD: Time Evolution Pair\\nKernel: {kernel_display}')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b591161c",
   "metadata": {},
   "source": [
    "## 7. Define Kernel Functions\n",
    "\n",
    "Five kernel options available:\n",
    "1. **RBF/Gaussian**: k(x,y) = exp(-||x-y||²/(2ε))\n",
    "2. **Spherical**: k(x,y) = exp(-d_geodesic²/(2θ²)) - Respects manifold geometry\n",
    "3. **Matérn**: k(x,y) = (1 + √3·d/ℓ)·exp(-√3·d/ℓ) - Controls smoothness\n",
    "4. **Rational Quadratic**: k(x,y) = (1 + ||x-y||²/(2α·ℓ²))^(-α) - Multi-scale features\n",
    "5. **Polynomial**: k(x,y) = (γ·⟨x,y⟩ + c₀)^d - Efficient, captures polynomial structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332bab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel1_rbf(X, Y, eps):\n",
    "    \"\"\"RBF/Gaussian Kernel\"\"\"\n",
    "    sq_x = np.sum(X ** 2, axis=1)\n",
    "    sq_y = np.sum(Y ** 2, axis=1)\n",
    "    D2 = sq_x[:, None] + sq_y[None, :] - 2 * (X @ Y.T)\n",
    "    return np.exp(-D2 / (2 * eps))\n",
    "\n",
    "def kernel2_spherical(X, Y, theta_scale=1.0):\n",
    "    \"\"\"Spherical/Geodesic Kernel\"\"\"\n",
    "    X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-12)\n",
    "    Y_norm = Y / (np.linalg.norm(Y, axis=1, keepdims=True) + 1e-12)\n",
    "    cos_sim = X_norm @ Y_norm.T\n",
    "    cos_sim = np.clip(cos_sim, -1.0, 1.0)\n",
    "    geodesic_dist = np.arccos(cos_sim)\n",
    "    return np.exp(-geodesic_dist**2 / (2 * theta_scale**2))\n",
    "\n",
    "def kernel3_matern(X, Y, length_scale=1.0, nu=1.5):\n",
    "    \"\"\"Matérn Kernel (ν=1.5)\"\"\"\n",
    "    sq_x = np.sum(X ** 2, axis=1)\n",
    "    sq_y = np.sum(Y ** 2, axis=1)\n",
    "    D2 = sq_x[:, None] + sq_y[None, :] - 2 * (X @ Y.T)\n",
    "    D = np.sqrt(np.maximum(D2, 0))\n",
    "    sqrt3_D = np.sqrt(3) * D / length_scale\n",
    "    return (1 + sqrt3_D) * np.exp(-sqrt3_D)\n",
    "\n",
    "def kernel4_rational_quadratic(X, Y, alpha=1.0, length_scale=1.0):\n",
    "    \"\"\"Rational Quadratic Kernel\"\"\"\n",
    "    sq_x = np.sum(X ** 2, axis=1)\n",
    "    sq_y = np.sum(Y ** 2, axis=1)\n",
    "    D2 = sq_x[:, None] + sq_y[None, :] - 2 * (X @ Y.T)\n",
    "    return (1 + D2 / (2 * alpha * length_scale**2)) ** (-alpha)\n",
    "\n",
    "def kernel5_polynomial(X, Y, degree=3, coef0=1.0, gamma=None):\n",
    "    \"\"\"Polynomial Kernel\"\"\"\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / X.shape[1]\n",
    "    inner_prod = X @ Y.T\n",
    "    return (gamma * inner_prod + coef0) ** degree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e4d90",
   "metadata": {},
   "source": [
    "## 8. Compute Kernel Matrices (K_xx and K_xy)\n",
    "\n",
    "**Critical**: K_xy is computed AFTER reflection boundary fix on X_tar_next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11843f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bandwidth parameter\n",
    "sq_tar = np.sum(X_tar ** 2, axis=1)\n",
    "H = sq_tar[:, None] + sq_tar[None, :] - 2 * (X_tar @ X_tar.T)\n",
    "epsilon = 0.5 * np.median(H) / (np.log(n + 1) + 1e-12)\n",
    "length_scale = np.sqrt(np.median(H))\n",
    "\n",
    "# Select and apply kernel\n",
    "if KERNEL_TYPE == 1:\n",
    "    kernel_name = \"RBF\"\n",
    "    K_xx = kernel1_rbf(X_tar, X_tar, epsilon)\n",
    "    K_xy = kernel1_rbf(X_tar, X_tar_next, epsilon)\n",
    "elif KERNEL_TYPE == 2:\n",
    "    kernel_name = \"Spherical\"\n",
    "    theta_scale = 0.3\n",
    "    K_xx = kernel2_spherical(X_tar, X_tar, theta_scale=theta_scale)\n",
    "    K_xy = kernel2_spherical(X_tar, X_tar_next, theta_scale=theta_scale)\n",
    "elif KERNEL_TYPE == 3:\n",
    "    kernel_name = \"Matérn\"\n",
    "    K_xx = kernel3_matern(X_tar, X_tar, length_scale=length_scale, nu=1.5)\n",
    "    K_xy = kernel3_matern(X_tar, X_tar_next, length_scale=length_scale, nu=1.5)\n",
    "elif KERNEL_TYPE == 4:\n",
    "    kernel_name = \"Rational Quadratic\"\n",
    "    alpha = 2.0\n",
    "    K_xx = kernel4_rational_quadratic(X_tar, X_tar, alpha=alpha, length_scale=length_scale)\n",
    "    K_xy = kernel4_rational_quadratic(X_tar, X_tar_next, alpha=alpha, length_scale=length_scale)\n",
    "elif KERNEL_TYPE == 5:\n",
    "    kernel_name = \"Polynomial\"\n",
    "    poly_degree = 10\n",
    "    poly_coef0 = 1.0\n",
    "    poly_gamma = 1.0 / d\n",
    "    K_xx = kernel5_polynomial(X_tar, X_tar, degree=poly_degree, coef0=poly_coef0, gamma=poly_gamma)\n",
    "    K_xy = kernel5_polynomial(X_tar, X_tar_next, degree=poly_degree, coef0=poly_coef0, gamma=poly_gamma)\n",
    "else:\n",
    "    raise ValueError(f\"Invalid KERNEL_TYPE: {KERNEL_TYPE}\")\n",
    "\n",
    "print(f\"[KERNEL] Using {kernel_name} kernel (Type {KERNEL_TYPE})\")\n",
    "_t = _print_phase(f\"Kernel-EDMD: Gram matrices K_xx and K_xy ({kernel_name})\", _t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47af20d",
   "metadata": {},
   "source": [
    "## 9. Compute Koopman Operator via Kernel EDMD\n",
    "\n",
    "**Formula**: K_koopman = K_xy @ (K_xx + γI)^{-1}\n",
    "\n",
    "This approximates the Koopman operator for the dynamics X_t → X_{t+dt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_ridge = 1e-6  # Tikhonov regularization\n",
    "\n",
    "# Use eigendecomposition for stable inversion\n",
    "evals_kxx, Q_kxx = eigh(K_xx)\n",
    "evals_kxx = np.clip(evals_kxx, 0.0, None)\n",
    "inv_evals = 1.0 / (evals_kxx + gamma_ridge)\n",
    "data_kernel = K_xy @ (Q_kxx @ (np.diag(inv_evals) @ Q_kxx.T))\n",
    "\n",
    "# Safety: ensure finite values\n",
    "data_kernel = np.nan_to_num(data_kernel, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "minK = float(np.min(data_kernel))\n",
    "if minK < 0.0:\n",
    "    data_kernel = data_kernel - minK + 1e-12\n",
    "_t = _print_phase(\"Kernel-EDMD: Koopman operator K_xy @ (K_xx + γI)^{-1}\", _t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873e1d2",
   "metadata": {},
   "source": [
    "## 10. DMPS-Style Normalization\n",
    "\n",
    "Apply density normalization and random-walk symmetric normalization to the Koopman operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90187c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_tar = np.sum(X_tar ** 2, axis=1)  # Keep for downstream gradient computations\n",
    "\n",
    "p_x = np.sqrt(np.sum(data_kernel, axis=1))\n",
    "p_y = p_x.copy()\n",
    "data_kernel_norm = data_kernel / p_x[:, None] / p_y[None, :]\n",
    "D_y = np.sum(data_kernel_norm, axis=0)\n",
    "\n",
    "rw_kernel = 0.5 * (data_kernel_norm / D_y + data_kernel_norm / D_y[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7d0af",
   "metadata": {},
   "source": [
    "## 11. Spectral Decomposition (Eigendecomposition)\n",
    "\n",
    "Using `eigh` for symmetric matrices (faster than SVD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigendecomposition (returns ascending order, need to reverse)\n",
    "evals_rw, evecs_rw = eigh(rw_kernel)\n",
    "phi = evecs_rw[:, ::-1]  # Reverse to descending order\n",
    "s = evals_rw[::-1]\n",
    "\n",
    "# Truncate eigenvalues below threshold\n",
    "tol_truncate = 1e-6\n",
    "s_original = s.copy()\n",
    "s = np.where(s < tol_truncate, 0.0, s)\n",
    "num_truncated = np.sum(s_original < tol_truncate)\n",
    "print(f\"[INFO] Truncated {num_truncated} eigenvalues < {tol_truncate:.0e} to zero\")\n",
    "_t = _print_phase(\"Eigendecomposition on rw_kernel\", _t)\n",
    "\n",
    "lambda_ns = s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3811b41",
   "metadata": {},
   "source": [
    "## 12. Eigenvalue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba82a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[EIGENVALUE ANALYSIS]\")\n",
    "print(f\"Total eigenvalues: {len(lambda_ns)}\")\n",
    "print(f\"Largest eigenvalue: {lambda_ns[0]:.6f}\")\n",
    "print(f\"Smallest eigenvalue (after clipping): {lambda_ns[-1]:.6e}\")\n",
    "\n",
    "count_gt_1 = np.sum(lambda_ns > 1.0)\n",
    "print(f\"Eigenvalues > 1.0: {count_gt_1}\")\n",
    "\n",
    "count_lt_0 = np.sum(lambda_ns < 0.0)\n",
    "print(f\"Eigenvalues < 0.0 (after clipping): {count_lt_0}\")\n",
    "\n",
    "tol_small = 1e-6\n",
    "count_near_0 = np.sum((lambda_ns >= 0.0) & (lambda_ns < tol_small))\n",
    "print(f\"Eigenvalues in [0, {tol_small:.0e}): {count_near_0}\")\n",
    "\n",
    "count_tiny_to_1 = np.sum((lambda_ns >= tol_small) & (lambda_ns <= 1.0))\n",
    "print(f\"Eigenvalues in [{tol_small:.0e}, 1.0]: {count_tiny_to_1}\")\n",
    "\n",
    "print(f\"\\nFirst 10 eigenvalues:\")\n",
    "for i in range(min(10, len(lambda_ns))):\n",
    "    print(f\"  λ[{i}] = {lambda_ns[i]:.8f}\")\n",
    "print(\"=\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea736d",
   "metadata": {},
   "source": [
    "## 13. Compute Inverse Weights for Gradient Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5cd59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ = -lambda_ns + 1\n",
    "inv_lambda = np.zeros_like(lambda_)\n",
    "inv_lambda[1:] = 1 / lambda_[1:]\n",
    "inv_lambda = inv_lambda * epsilon\n",
    "inv_K = phi @ np.diag(inv_lambda) @ phi.T\n",
    "\n",
    "tol = 1e-6\n",
    "lambda_ns_mod = np.copy(lambda_ns)\n",
    "lambda_ns_mod[lambda_ns_mod < tol] = 0\n",
    "below_tol = np.sum(lambda_ns < tol)\n",
    "above_tol = n - below_tol\n",
    "reg = 0.001\n",
    "lambda_ns_inv = np.zeros_like(lambda_ns)\n",
    "mask = lambda_ns >= tol\n",
    "lambda_ns_inv[mask] = epsilon / (lambda_ns[mask] + reg)\n",
    "inv_K_ns = phi @ np.diag(lambda_ns_inv) @ phi.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0b02d",
   "metadata": {},
   "source": [
    "## 14. Particle Initialization\n",
    "\n",
    "Initialize particles based on mode (full circle or semi-circle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1000\n",
    "h = 2\n",
    "m = 700\n",
    "u = np.random.normal(0, 1, (m, d))\n",
    "u_norm = np.linalg.norm(u, axis=1, keepdims=True)\n",
    "r = np.sqrt(np.random.rand(m, 1)) * 1/100 + 99/100\n",
    "u_trans = u / u_norm\n",
    "x_init = r * u_trans\n",
    "\n",
    "if USE_SEMICIRCLE:\n",
    "    x_init = x_init[x_init[:, 1] > 0.9, :]\n",
    "else:\n",
    "    x_init = x_init[x_init[:, 1] > 0.95, :]\n",
    "\n",
    "m = x_init.shape[0]\n",
    "print(f\"[INFO] Initialized {m} particles ({'semi-circle' if USE_SEMICIRCLE else 'full circle'} mode)\")\n",
    "x_t = np.zeros((m, d, iter), dtype=np.float64)\n",
    "x_t[:, :, 0] = x_init\n",
    "\n",
    "p_tar = np.sum(data_kernel, axis=0)\n",
    "D = np.sum(data_kernel / np.sqrt(p_tar) / np.sqrt(p_tar)[:, None], axis=1)\n",
    "\n",
    "inv_K_ns_s_ns = phi @ np.diag(lambda_ns_inv * inv_lambda * lambda_ns_inv) @ phi.T\n",
    "lambda_s_s_ns = inv_lambda * inv_lambda * lambda_ns_inv\n",
    "lambda_s_s_ns = lambda_s_s_ns[:above_tol]\n",
    "lambda_ns_s_ns = lambda_ns_inv * inv_lambda * lambda_ns_inv\n",
    "lambda_ns_s_ns = lambda_ns_s_ns[:above_tol]\n",
    "\n",
    "sum_x = np.zeros((m, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a916f",
   "metadata": {},
   "source": [
    "## 15. LAWGD Iteration Loop\n",
    "\n",
    "**Data-driven learning**: NO artificial boundary operations!\n",
    "\n",
    "The Koopman operator should have learned the boundary behavior from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748016a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = time.time()\n",
    "total_loop = iter - 1\n",
    "\n",
    "if USE_GPU:\n",
    "    # Stage constants on GPU\n",
    "    X_tar_gpu = cp.asarray(X_tar)\n",
    "    p_tar_gpu = cp.asarray(p_tar)\n",
    "    sq_tar_gpu = cp.asarray(sq_tar)\n",
    "    D_gpu = cp.asarray(D)\n",
    "    phi_gpu = cp.asarray(phi[:, :above_tol])\n",
    "    lambda_ns_s_ns_gpu = cp.asarray(lambda_ns_s_ns)\n",
    "    x_t_gpu = cp.asarray(x_t)\n",
    "    diag_lambda_gpu = cp.diag(lambda_ns_s_ns_gpu)\n",
    "    \n",
    "    # Iteration loop (GPU)\n",
    "    for t in range(iter - 1):\n",
    "        x_slice = x_t_gpu[:, :, t]\n",
    "        grad_matrix = grad_ker1(x_slice, X_tar_gpu, p_tar_gpu, sq_tar_gpu, D_gpu, epsilon)\n",
    "        cross_matrix = K_tar_eval(X_tar_gpu, x_slice, p_tar_gpu, sq_tar_gpu, D_gpu, epsilon)\n",
    "        \n",
    "        sum_x_gpu = cp.zeros((m, d))\n",
    "        for i in range(d):\n",
    "            sum_x_gpu[:, i] = cp.sum(\n",
    "                grad_matrix[:, :, i] @ phi_gpu @ diag_lambda_gpu @ phi_gpu.T @ cross_matrix,\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        x_proposed = x_slice - (h / m) * sum_x_gpu\n",
    "        x_norm_proposed = cp.sqrt(cp.sum(x_proposed ** 2, axis=1, keepdims=True))\n",
    "        x_t_gpu[:, :, t + 1] = x_proposed / (x_norm_proposed + 1e-12)\n",
    "        \n",
    "        done = t + 1\n",
    "        if done == total_loop or (done % max(1, total_loop // 100) == 0):\n",
    "            _print_progress(done, total_loop, loop_start, prefix=\"[Kernel-EDMD-GPU] \")\n",
    "    \n",
    "    x_t = cp.asnumpy(x_t_gpu)\n",
    "else:\n",
    "    # CPU iteration loop\n",
    "    for t in range(iter - 1):\n",
    "        grad_matrix = grad_ker1(x_t[:, :, t], X_tar, p_tar, sq_tar, D, epsilon)\n",
    "        cross_matrix = K_tar_eval(X_tar, x_t[:, :, t], p_tar, sq_tar, D, epsilon)\n",
    "        for i in range(d):\n",
    "            sum_x[:, i] = np.sum(\n",
    "                grad_matrix[:, :, i] @ phi[:, :above_tol] @ np.diag(lambda_ns_s_ns) @ phi[:, :above_tol].T @ cross_matrix,\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        x_proposed = x_t[:, :, t] - h / m * sum_x\n",
    "        x_norm_proposed = np.sqrt(np.sum(x_proposed ** 2, axis=1, keepdims=True))\n",
    "        x_t[:, :, t + 1] = x_proposed / (x_norm_proposed + 1e-12)\n",
    "        \n",
    "        done = t + 1\n",
    "        if done == total_loop or (done % max(1, total_loop // 100) == 0):\n",
    "            _print_progress(done, total_loop, loop_start, prefix=\"[Kernel-EDMD-CPU] \")\n",
    "\n",
    "print()\n",
    "_t = _print_phase(\"Iteration loop total\", loop_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28181402",
   "metadata": {},
   "source": [
    "## 16. Visualize Results (2D/3D)\n",
    "\n",
    "- **Blue dots**: Target distribution\n",
    "- **Red solid circles**: Initial particle positions\n",
    "- **Magenta hollow circles**: Final particle positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if d == 2:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(X_tar[:, 0], X_tar[:, 1], 'o', markersize=4, alpha=0.6, label='Target')\n",
    "    plt.plot(x_t[:, 0, 0], x_t[:, 1, 0], 'o', markersize=8, color='red', label='Init')\n",
    "    plt.plot(x_t[:, 0, -1], x_t[:, 1, -1], 'o', markersize=10, markerfacecolor='none', markeredgecolor='magenta', markeredgewidth=1.2, alpha=0.6, label='Final')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.title(f'2D Results - Kernel EDMD with {kernel_name}')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X_tar[:, 0], X_tar[:, 1], X_tar[:, 2], s=20, alpha=0.6, label='Target')\n",
    "    ax.scatter(x_t[:, 0, 0], x_t[:, 1, 0], x_t[:, 2, 0], s=50, marker='o', color='red', label='Init')\n",
    "    ax.scatter(x_t[:, 0, -1], x_t[:, 1, -1], x_t[:, 2, -1], s=100, marker='o', facecolors='none', edgecolors='green', linewidths=0.8, alpha=0.5, label='Final')\n",
    "    ax.legend(fontsize=12)\n",
    "    plt.title(f'3D Results - Kernel EDMD with {kernel_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plt.figure(figsize=(10, 8))\n",
    "    ax2 = fig2.add_subplot(111, projection='3d')\n",
    "    ax2.scatter(x_t[:, 0, 0], x_t[:, 1, 0], x_t[:, 2, 0], s=50, marker='o', color='red', label='Init')\n",
    "    ax2.scatter(x_t[:, 0, -1], x_t[:, 1, -1], x_t[:, 2, -1], s=100, marker='o', facecolors='none', edgecolors='green', linewidths=0.8, alpha=0.5, label='Final')\n",
    "    ax2.legend(fontsize=12)\n",
    "    plt.title(f'3D Final State - Kernel EDMD with {kernel_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79618cc4",
   "metadata": {},
   "source": [
    "## 17. Scatter Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff871b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(\n",
    "    pd.DataFrame(X_tar),\n",
    "    alpha=0.2,\n",
    "    figsize=(6, 6),\n",
    "    diagonal='hist',\n",
    "    hist_kwds={'edgecolor': 'black'}\n",
    ")\n",
    "plt.suptitle(f'Scatter Matrix of X_tar - {kernel_name} Kernel')\n",
    "plt.show()\n",
    "\n",
    "pd.plotting.scatter_matrix(\n",
    "    pd.DataFrame(x_t[:, :, -1]),\n",
    "    alpha=0.2,\n",
    "    figsize=(6, 6),\n",
    "    diagonal='hist',\n",
    "    hist_kwds={'edgecolor': 'black'}\n",
    ")\n",
    "plt.suptitle(f'Scatter Matrix of x_t (final) - {kernel_name} Kernel')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
