{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035e1915",
   "metadata": {},
   "source": [
    "## 1. 安装和导入依赖\n",
    "\n",
    "如果没有安装 diffusers，先运行：\n",
    "```\n",
    "pip install diffusers transformers accelerate\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# 检查 GPU\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547314e4",
   "metadata": {},
   "source": [
    "## 2. 加载预训练的 Stable Diffusion 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# 加载 SD 1.5 模型（约4GB，首次下载需要几分钟）\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,  # 半精度，节省显存\n",
    "    safety_checker=None,  # 关闭安全检查，加速\n",
    "    requires_safety_checker=False\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# 优化设置\n",
    "pipe.enable_attention_slicing()  # 节省显存\n",
    "\n",
    "print(\"模型加载完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff4bcc",
   "metadata": {},
   "source": [
    "## 3. 快速生成测试（单张图像）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 生成单张图像\n",
    "prompt = \"a cute cat sitting on grass, realistic photo\"\n",
    "\n",
    "start_time = time.time()\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    num_inference_steps=20,  # 20步足够7-8成效果\n",
    "    guidance_scale=7.5,\n",
    "    height=512,\n",
    "    width=512\n",
    ").images[0]\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"生成时间: {elapsed:.2f} 秒\")\n",
    "\n",
    "# 显示图像\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Prompt: {prompt}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d2a7b",
   "metadata": {},
   "source": [
    "## 4. 生成 CIFAR-10 类别的图像\n",
    "\n",
    "CIFAR-10 包含 10 个类别：airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6fd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 类别\n",
    "cifar10_classes = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "# 为每个类别生成一张图像\n",
    "generated_images = []\n",
    "\n",
    "for cls in cifar10_classes:\n",
    "    prompt = f\"a photo of a {cls}, high quality, realistic\"\n",
    "    print(f\"生成: {cls}...\", end=\" \")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    image = pipe(\n",
    "        prompt,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=7.5,\n",
    "        height=512,\n",
    "        width=512\n",
    "    ).images[0]\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    generated_images.append(image)\n",
    "    print(f\"完成 ({elapsed:.2f}s)\")\n",
    "\n",
    "print(\"\\n所有类别生成完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化所有生成的图像\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (img, cls) in enumerate(zip(generated_images, cifar10_classes)):\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(cls)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(\"Generated CIFAR-10 Categories (Stable Diffusion 1.5)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac5e0a",
   "metadata": {},
   "source": [
    "## 5. 批量生成（每个类别多张）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量生成：每个类别生成 n 张\n",
    "n_per_class = 5  # 每个类别生成5张\n",
    "batch_images = {cls: [] for cls in cifar10_classes}\n",
    "\n",
    "total = n_per_class * len(cifar10_classes)\n",
    "count = 0\n",
    "\n",
    "start_total = time.time()\n",
    "\n",
    "for cls in cifar10_classes:\n",
    "    for i in range(n_per_class):\n",
    "        prompt = f\"a photo of a {cls}, high quality, realistic\"\n",
    "        \n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=7.5,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "        \n",
    "        batch_images[cls].append(image)\n",
    "        count += 1\n",
    "        print(f\"\\r进度: {count}/{total}\", end=\"\")\n",
    "\n",
    "elapsed_total = time.time() - start_total\n",
    "print(f\"\\n\\n总计生成 {total} 张图像\")\n",
    "print(f\"总耗时: {elapsed_total:.1f} 秒\")\n",
    "print(f\"平均每张: {elapsed_total/total:.2f} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436cb82",
   "metadata": {},
   "source": [
    "## 6. 提取 Latent 表示（用于后续分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6d5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderKL\n",
    "from torchvision import transforms\n",
    "\n",
    "# 加载 VAE（可以单独使用，用于提取 latent）\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    subfolder=\"vae\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")\n",
    "\n",
    "print(\"VAE 加载完成！\")\n",
    "print(f\"Latent 空间维度: 4 x 64 x 64 (对于 512x512 图像)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba611df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # 归一化到 [-1, 1]\n",
    "])\n",
    "\n",
    "# 将生成的图像编码到 latent 空间\n",
    "def encode_to_latent(image, vae):\n",
    "    \"\"\"将 PIL 图像编码到 latent 空间\"\"\"\n",
    "    img_tensor = preprocess(image).unsqueeze(0).to(\"cuda\", dtype=torch.float16)\n",
    "    with torch.no_grad():\n",
    "        latent = vae.encode(img_tensor).latent_dist.sample()\n",
    "        latent = latent * 0.18215  # 缩放因子\n",
    "    return latent\n",
    "\n",
    "# 测试：编码第一张生成的图像\n",
    "test_latent = encode_to_latent(generated_images[0], vae)\n",
    "print(f\"Latent shape: {test_latent.shape}\")\n",
    "print(f\"Latent dtype: {test_latent.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df643a84",
   "metadata": {},
   "source": [
    "## 7. 加载本地 CIFAR-10 并编码到 Latent 空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516720b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载本地 CIFAR-10 数据\n",
    "def load_cifar10_batch(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data_dict = pickle.load(f, encoding='bytes')\n",
    "    images = data_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    labels = data_dict[b'labels']\n",
    "    return images, labels\n",
    "\n",
    "# 加载第一个 batch\n",
    "cifar_path = \"data/cifar-10-batches-py/data_batch_1\"\n",
    "images, labels = load_cifar10_batch(cifar_path)\n",
    "\n",
    "print(f\"CIFAR-10 图像形状: {images.shape}\")\n",
    "print(f\"标签数量: {len(labels)}\")\n",
    "\n",
    "# 显示几张 CIFAR-10 原图\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i])\n",
    "    axes[i].set_title(cifar10_classes[labels[i]])\n",
    "    axes[i].axis('off')\n",
    "plt.suptitle(\"Original CIFAR-10 Images (32x32)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd88d5",
   "metadata": {},
   "source": [
    "## 8. KSWGD 生成方法（替代 Stable Diffusion 的扩散过程）\n",
    "\n",
    "使用 KSWGD（Kernel Stein Wasserstein Gradient Descent）在 latent space 中进行粒子传输生成。\n",
    "\n",
    "**核心思想：**\n",
    "- 保留 VAE 的 encoder/decoder（预训练的 latent space）\n",
    "- 用 KSWGD 替代 UNet 去噪过程\n",
    "- 从随机噪声出发，通过核梯度流传输到目标分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf49e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 KSWGD 所需的库和自定义核函数\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm.auto import trange\n",
    "\n",
    "# 导入你的核函数\n",
    "from grad_ker1 import grad_ker1\n",
    "from K_tar_eval import K_tar_eval\n",
    "\n",
    "# 尝试导入 GPU 版本\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from grad_ker1_gpu import grad_ker1 as grad_ker1_gpu\n",
    "    from K_tar_eval_gpu import K_tar_eval as K_tar_eval_gpu\n",
    "    GPU_KSWGD = True\n",
    "    print(\"✓ GPU KSWGD backend available (CuPy)\")\n",
    "except Exception as e:\n",
    "    cp = None\n",
    "    grad_ker1_gpu = None\n",
    "    K_tar_eval_gpu = None\n",
    "    GPU_KSWGD = False\n",
    "    print(f\"✗ GPU KSWGD backend not available: {e}\")\n",
    "    print(\"  Using CPU backend instead\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568af7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新加载 VAE 用于 KSWGD 生成\n",
    "from diffusers import AutoencoderKL\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    \"stabilityai/sd-vae-ft-mse\",  # 使用优化过的 VAE\n",
    "    torch_dtype=torch.float32  # KSWGD 需要 float32 精度\n",
    ").to(device)\n",
    "\n",
    "vae_scaling = float(getattr(vae.config, \"scaling_factor\", 0.18215))\n",
    "print(f\"VAE scaling factor: {vae_scaling}\")\n",
    "\n",
    "# VAE 辅助函数\n",
    "def _to_vae_range(x):\n",
    "    \"\"\"[0,1] → [-1,1]\"\"\"\n",
    "    return (x * 2.0) - 1.0\n",
    "\n",
    "def _from_vae_range(x):\n",
    "    \"\"\"[-1,1] → [0,1]\"\"\"\n",
    "    return torch.clamp((x + 1.0) * 0.5, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3131fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 CIFAR-10 图像编码到 VAE latent space 作为 KSWGD 目标分布\n",
    "from torchvision import datasets, transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "transform_cifar = T.Compose([\n",
    "    T.Resize((256, 256)),  # VAE 需要较大尺寸输入\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform_cifar, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "print(f\"CIFAR-10 训练集大小: {len(train_dataset)}\")\n",
    "\n",
    "# 编码所有训练图像到 latent space\n",
    "max_samples = 2000  # 限制样本数量以加速（可调整）\n",
    "all_latents = []\n",
    "all_labels = []\n",
    "\n",
    "vae.eval()\n",
    "print(f\"正在编码 {max_samples} 张图像到 latent space...\")\n",
    "\n",
    "# 计算需要的 batch 数量\n",
    "n_batches_needed = (max_samples + 63) // 64\n",
    "\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    pbar = tqdm(train_loader, total=n_batches_needed, desc=\"编码进度\", unit=\"batch\")\n",
    "    \n",
    "    for batch_imgs, batch_labels in pbar:\n",
    "        if count >= max_samples:\n",
    "            break\n",
    "        \n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        # 编码到 latent\n",
    "        latents = vae.encode(_to_vae_range(batch_imgs)).latent_dist.mode()\n",
    "        latents = latents * vae_scaling\n",
    "        \n",
    "        # 展平 latent\n",
    "        latents_flat = latents.view(latents.size(0), -1).cpu().numpy()\n",
    "        all_latents.append(latents_flat)\n",
    "        all_labels.append(batch_labels.numpy())\n",
    "        \n",
    "        count += latents_flat.shape[0]\n",
    "        pbar.set_postfix({\"已编码\": f\"{min(count, max_samples)}/{max_samples}\"})\n",
    "    \n",
    "    pbar.close()\n",
    "\n",
    "Z_all = np.concatenate(all_latents, axis=0)[:max_samples]\n",
    "y_labels = np.concatenate(all_labels, axis=0)[:max_samples]\n",
    "\n",
    "print(f\"\\nLatent codes shape: {Z_all.shape}\")\n",
    "print(f\"Latent dim: {Z_all.shape[1]}\")\n",
    "\n",
    "# 记录 latent shape 用于后续解码\n",
    "with torch.no_grad():\n",
    "    dummy = torch.zeros(1, 3, 256, 256, device=device)\n",
    "    dummy_latent = vae.encode(_to_vae_range(dummy)).latent_dist.mode()\n",
    "    latent_shape = dummy_latent.shape[1:]  # (C, H, W)\n",
    "    \n",
    "print(f\"Latent shape (C, H, W): {latent_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化 latent codes 并构建 KSWGD 核算子\n",
    "# 标准化\n",
    "Z_mean = np.mean(Z_all, axis=0, keepdims=True)\n",
    "Z_std = np.std(Z_all, axis=0, keepdims=True) + 1e-8\n",
    "Z_std = Z_std.astype(np.float64)\n",
    "Z_mean = Z_mean.astype(np.float64)\n",
    "X_tar = ((Z_all - Z_mean) / Z_std).astype(np.float64)\n",
    "\n",
    "print(f\"标准化后: mean={X_tar.mean():.4f}, std={X_tar.std():.4f}\")\n",
    "\n",
    "# 计算目标样本的平方和（用于核函数）\n",
    "sq_tar = np.sum(X_tar ** 2, axis=1)\n",
    "\n",
    "# 计算成对距离和带宽 epsilon\n",
    "dists = pairwise_distances(X_tar, metric=\"euclidean\")\n",
    "eps_kswgd = np.median(dists**2) / (2.0 * np.log(X_tar.shape[0] + 1))\n",
    "eps_kswgd = float(max(eps_kswgd, 1e-6))\n",
    "\n",
    "print(f\"KSWGD epsilon: {eps_kswgd:.6f}\")\n",
    "print(f\"距离统计: min={dists[dists>0].min():.4f}, median={np.median(dists):.4f}, max={dists.max():.4f}\")\n",
    "\n",
    "# 构建数据核矩阵\n",
    "data_kernel = np.exp(-dists**2 / (2.0 * eps_kswgd))\n",
    "\n",
    "# 归一化\n",
    "p_x = np.sqrt(np.sum(data_kernel, axis=1))\n",
    "data_kernel_norm = data_kernel / (p_x[:, None] * p_x[None, :] + 1e-12)\n",
    "D_y = np.sum(data_kernel_norm, axis=0)\n",
    "rw_kernel = 0.5 * (data_kernel_norm / (D_y + 1e-12) + data_kernel_norm / (D_y[:, None] + 1e-12))\n",
    "rw_kernel = np.nan_to_num(rw_kernel)\n",
    "\n",
    "print(f\"核矩阵构建完成，shape: {rw_kernel.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20772169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算特征分解和 KSWGD 权重\n",
    "import time\n",
    "\n",
    "print(\"正在计算特征分解（可能需要 1-2 分钟）...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用 GPU 加速特征分解（如果可用）\n",
    "if torch.cuda.is_available():\n",
    "    print(\"  使用 GPU 加速...\")\n",
    "    rw_kernel_torch = torch.from_numpy(rw_kernel).to(device)\n",
    "    lambda_ns_torch, phi_torch = torch.linalg.eigh(rw_kernel_torch)\n",
    "    lambda_ns = lambda_ns_torch.cpu().numpy()[::-1].copy()\n",
    "    phi = phi_torch.cpu().numpy()[:, ::-1].copy()\n",
    "    del rw_kernel_torch, lambda_ns_torch, phi_torch\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"  使用 CPU...\")\n",
    "    lambda_ns, phi = np.linalg.eigh(rw_kernel)\n",
    "    phi = phi[:, ::-1]\n",
    "    lambda_ns = lambda_ns[::-1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"特征分解完成，耗时: {elapsed:.1f}s\")\n",
    "\n",
    "# 设置正则化参数\n",
    "tol = 1e-6\n",
    "reg = 1e-3\n",
    "latent_dim = X_tar.shape[1]\n",
    "\n",
    "# 计算逆特征值\n",
    "lambda_ = lambda_ns - 1.0\n",
    "inv_lambda = np.zeros_like(lambda_)\n",
    "inv_lambda[1:] = 1.0 / np.clip(lambda_[1:], 1e-12, None)\n",
    "inv_lambda *= eps_kswgd\n",
    "\n",
    "# 截断小特征值\n",
    "lambda_ns_inv = np.zeros_like(lambda_ns)\n",
    "mask = lambda_ns >= tol\n",
    "lambda_ns_inv[mask] = eps_kswgd / (lambda_ns[mask] + reg)\n",
    "above_tol = int(np.sum(mask))\n",
    "phi_trunc = phi[:, :above_tol]\n",
    "lambda_ns_s_ns = (lambda_ns_inv * inv_lambda * lambda_ns_inv)[:above_tol]\n",
    "\n",
    "# 目标分布权重\n",
    "p_tar = np.sum(data_kernel, axis=0)\n",
    "sqrt_p = np.sqrt(p_tar + 1e-12)\n",
    "D_vec = np.sum(data_kernel / sqrt_p[:, None] / sqrt_p[None, :], axis=1)\n",
    "\n",
    "print(f\"保留的特征向量数量: {above_tol}\")\n",
    "print(f\"前 10 个特征值: {lambda_ns[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21691815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 KSWGD 采样器\n",
    "def run_kswgd_sampler(num_particles=16, num_iters=200, step_size=0.05, rng_seed=42):\n",
    "    \"\"\"\n",
    "    KSWGD 粒子传输采样器\n",
    "    \n",
    "    从标准正态分布初始化粒子，通过核梯度流传输到目标分布\n",
    "    \n",
    "    Args:\n",
    "        num_particles: 生成的样本数量\n",
    "        num_iters: 迭代次数\n",
    "        step_size: 步长\n",
    "        rng_seed: 随机种子\n",
    "    \n",
    "    Returns:\n",
    "        生成的标准化 latent vectors\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    \n",
    "    # 选择后端\n",
    "    use_gpu = GPU_KSWGD and torch.cuda.is_available()\n",
    "    xp = cp if use_gpu else np\n",
    "    grad_fn = grad_ker1_gpu if use_gpu else grad_ker1\n",
    "    K_eval_fn = K_tar_eval_gpu if use_gpu else K_tar_eval\n",
    "    \n",
    "    print(f\"KSWGD 后端: {'GPU (CuPy)' if use_gpu else 'CPU (NumPy)'}\")\n",
    "    \n",
    "    # 初始化粒子轨迹\n",
    "    x_hist = xp.zeros((num_particles, latent_dim, num_iters), dtype=xp.float64)\n",
    "    init_particles = rng.normal(0.0, 1.0, size=(num_particles, latent_dim))\n",
    "    x_hist[:, :, 0] = xp.asarray(init_particles)\n",
    "    \n",
    "    # 准备目标数据\n",
    "    if use_gpu:\n",
    "        X_tar_dev = cp.asarray(X_tar)\n",
    "        p_tar_dev = cp.asarray(p_tar)\n",
    "        sq_tar_dev = cp.asarray(sq_tar)\n",
    "        D_vec_dev = cp.asarray(D_vec)\n",
    "        phi_trunc_dev = cp.asarray(phi_trunc)\n",
    "        lambda_weights = cp.asarray(lambda_ns_s_ns)\n",
    "    else:\n",
    "        X_tar_dev = X_tar\n",
    "        p_tar_dev = p_tar\n",
    "        sq_tar_dev = sq_tar\n",
    "        D_vec_dev = D_vec\n",
    "        phi_trunc_dev = phi_trunc\n",
    "        lambda_weights = lambda_ns_s_ns\n",
    "    \n",
    "    # KSWGD 迭代\n",
    "    iterator = trange(num_iters - 1, desc=\"KSWGD 传输\", unit=\"step\")\n",
    "    for t in iterator:\n",
    "        current = x_hist[:, :, t]\n",
    "        \n",
    "        # 计算核梯度\n",
    "        grad_matrix = grad_fn(current, X_tar_dev, p_tar_dev, sq_tar_dev, D_vec_dev, eps_kswgd)\n",
    "        cross_matrix = K_eval_fn(X_tar_dev, current, p_tar_dev, sq_tar_dev, D_vec_dev, eps_kswgd)\n",
    "        \n",
    "        # 谱分解加速\n",
    "        tmp = phi_trunc_dev.T @ cross_matrix\n",
    "        tmp = lambda_weights[:, None] * tmp\n",
    "        kswgd_push = phi_trunc_dev @ tmp\n",
    "        \n",
    "        # 更新粒子位置\n",
    "        for dim in range(latent_dim):\n",
    "            sum_term = grad_matrix[:, :, dim] @ kswgd_push\n",
    "            x_hist[:, dim, t + 1] = x_hist[:, dim, t] - (step_size / num_particles) * xp.sum(sum_term, axis=1)\n",
    "        \n",
    "        # 显示进度\n",
    "        if (t + 1) % 50 == 0:\n",
    "            step_norm = x_hist[:, :, t + 1] - x_hist[:, :, t]\n",
    "            mean_disp = float(xp.mean(xp.linalg.norm(step_norm, axis=1)))\n",
    "            iterator.set_postfix({\"mean_step\": f\"{mean_disp:.3e}\"})\n",
    "    \n",
    "    # 返回最终样本\n",
    "    samples_std = x_hist[:, :, -1]\n",
    "    if use_gpu:\n",
    "        samples_std = cp.asnumpy(samples_std)\n",
    "    \n",
    "    return np.asarray(samples_std, dtype=np.float64)\n",
    "\n",
    "\n",
    "def decode_latents_to_images(flat_latents_std):\n",
    "    \"\"\"\n",
    "    将标准化的 latent vectors 解码为图像\n",
    "    \n",
    "    Args:\n",
    "        flat_latents_std: 标准化的 latent vectors (N, latent_dim)\n",
    "    \n",
    "    Returns:\n",
    "        解码后的图像 tensor (N, 3, H, W)\n",
    "    \"\"\"\n",
    "    # 反标准化\n",
    "    flat_latents = flat_latents_std * Z_std + Z_mean\n",
    "    \n",
    "    # 重塑为 (N, C, H, W)\n",
    "    latents = flat_latents.reshape(-1, *latent_shape)\n",
    "    latents_tensor = torch.from_numpy(latents).float().to(device)\n",
    "    \n",
    "    # VAE 解码\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        decoded = vae.decode(latents_tensor / vae_scaling).sample\n",
    "        decoded_rgb = _from_vae_range(decoded)\n",
    "    \n",
    "    return decoded_rgb.cpu()\n",
    "\n",
    "print(\"KSWGD 采样器定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcef6e8",
   "metadata": {},
   "source": [
    "### 8.1 运行 KSWGD 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行 KSWGD 采样生成新的 latent vectors\n",
    "kswgd_config = {\n",
    "    \"num_particles\": 16,   # 生成 16 张图像\n",
    "    \"num_iters\": 300,      # 迭代次数\n",
    "    \"step_size\": 0.03,     # 步长（较小以保持稳定）\n",
    "    \"rng_seed\": 42\n",
    "}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"KSWGD 生成配置:\")\n",
    "for k, v in kswgd_config.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 运行 KSWGD\n",
    "start_time = time.time()\n",
    "Z_kswgd_std = run_kswgd_sampler(**kswgd_config)\n",
    "kswgd_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nKSWGD 完成！\")\n",
    "print(f\"生成样本 shape: {Z_kswgd_std.shape}\")\n",
    "print(f\"总耗时: {kswgd_time:.1f} 秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解码 KSWGD 生成的 latent vectors 为图像\n",
    "print(\"正在解码 latent vectors 为图像...\")\n",
    "\n",
    "kswgd_images = decode_latents_to_images(Z_kswgd_std)\n",
    "kswgd_images_np = kswgd_images.numpy()\n",
    "\n",
    "print(f\"生成图像 shape: {kswgd_images_np.shape}\")\n",
    "print(f\"像素值范围: [{kswgd_images_np.min():.3f}, {kswgd_images_np.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8c956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化 KSWGD 生成的图像\n",
    "n_show = min(16, kswgd_images_np.shape[0])\n",
    "n_cols = 4\n",
    "n_rows = (n_show + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(3 * n_cols, 3 * n_rows))\n",
    "axes = np.asarray(axes).reshape(-1)\n",
    "\n",
    "for idx in range(n_show):\n",
    "    img = np.transpose(kswgd_images_np[idx], (1, 2, 0))  # (C,H,W) → (H,W,C)\n",
    "    axes[idx].imshow(np.clip(img, 0.0, 1.0))\n",
    "    axes[idx].set_title(f\"KSWGD #{idx+1}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "# 隐藏多余的子图\n",
    "for idx in range(n_show, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(\"KSWGD 生成的 CIFAR-10 图像\\n(VAE Latent Space + 核梯度流)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n对比 Stable Diffusion:\")\n",
    "print(f\"  - SD: 随机噪声 → UNet 去噪 (20步) → VAE Decode\")\n",
    "print(f\"  - KSWGD: 随机噪声 → 核梯度流传输 ({kswgd_config['num_iters']}步) → VAE Decode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3d783",
   "metadata": {},
   "source": [
    "### 8.2 对比：原始 CIFAR-10 vs KSWGD 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 并排对比原始图像和 KSWGD 生成图像\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# 从训练集随机选几张原始图像\n",
    "n_compare = 8\n",
    "random_indices = np.random.choice(len(train_dataset), n_compare, replace=False)\n",
    "\n",
    "original_imgs = []\n",
    "for idx in random_indices:\n",
    "    img, _ = train_dataset[idx]\n",
    "    original_imgs.append(img)\n",
    "original_batch = torch.stack(original_imgs)\n",
    "\n",
    "# VAE 重建原始图像（作为参考）\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    original_latents = vae.encode(_to_vae_range(original_batch.to(device))).latent_dist.mode()\n",
    "    reconstructed = vae.decode(original_latents).sample\n",
    "    reconstructed_rgb = _from_vae_range(reconstructed).cpu()\n",
    "\n",
    "# KSWGD 生成图像\n",
    "kswgd_batch = torch.from_numpy(kswgd_images_np[:n_compare])\n",
    "\n",
    "# 创建对比图\n",
    "fig, axes = plt.subplots(3, n_compare, figsize=(2 * n_compare, 6))\n",
    "\n",
    "for i in range(n_compare):\n",
    "    # 原始 CIFAR-10\n",
    "    orig = original_batch[i].permute(1, 2, 0).numpy()\n",
    "    axes[0, i].imshow(np.clip(orig, 0, 1))\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel(\"Original\", fontsize=12)\n",
    "    \n",
    "    # VAE 重建\n",
    "    recon = reconstructed_rgb[i].permute(1, 2, 0).numpy()\n",
    "    axes[1, i].imshow(np.clip(recon, 0, 1))\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_ylabel(\"VAE Recon\", fontsize=12)\n",
    "    \n",
    "    # KSWGD 生成\n",
    "    kswgd_img = kswgd_batch[i].permute(1, 2, 0).numpy()\n",
    "    axes[2, i].imshow(np.clip(kswgd_img, 0, 1))\n",
    "    axes[2, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[2, i].set_ylabel(\"KSWGD Gen\", fontsize=12)\n",
    "\n",
    "# 设置行标签\n",
    "axes[0, 0].text(-0.3, 0.5, 'Original\\n(CIFAR-10)', transform=axes[0, 0].transAxes, \n",
    "                fontsize=10, va='center', ha='right')\n",
    "axes[1, 0].text(-0.3, 0.5, 'VAE\\nReconstruct', transform=axes[1, 0].transAxes,\n",
    "                fontsize=10, va='center', ha='right')\n",
    "axes[2, 0].text(-0.3, 0.5, 'KSWGD\\nGenerated', transform=axes[2, 0].transAxes,\n",
    "                fontsize=10, va='center', ha='right')\n",
    "\n",
    "plt.suptitle(\"CIFAR-10: Original vs VAE Reconstruction vs KSWGD Generation\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28e5a4",
   "metadata": {},
   "source": [
    "## 8. 清理 GPU 显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e827693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理显存\n",
    "import gc\n",
    "\n",
    "del pipe\n",
    "del vae\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"当前显存使用: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"显存缓存: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
