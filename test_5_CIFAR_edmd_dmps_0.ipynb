{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967f0030",
   "metadata": {},
   "source": [
    "# Diffusion Maps + KSWGD Generative Modelling on CIFAR-10\n",
    "\n",
    "This notebook implements an autoencoder + diffusion-maps latent analysis, then mirrors the KSWGD scheme from Tests 1 & 2 to sample new CIFAR-10 images directly in latent space.\n",
    "\n",
    "**Dataset: CIFAR-10**\n",
    "- 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- 32×32 RGB color images (3 channels)\n",
    "- 50,000 training / 10,000 test images\n",
    "\n",
    "**Pipeline:**\n",
    "\n",
    "1. Load CIFAR-10 and normalize images.\n",
    "2. Train an autoencoder (either MLP-based or CNN-based) to learn a low-dimensional latent space.\n",
    "3. Map training images to latent codes.\n",
    "4. Apply Diffusion Maps on latent codes to obtain diffusion coordinates for diagnostics.\n",
    "5. Build the KSWGD kernel operators on the latent samples (same normalization as Tests 1 & 2).\n",
    "6. Run KSWGD particle transport to draw new latent vectors.\n",
    "7. Decode KSWGD latent vectors back to images and visually inspect generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b8d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure core libraries, plotting defaults, and compute device\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.linalg import eig\n",
    "from tqdm.auto import trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from grad_ker1 import grad_ker1\n",
    "from K_tar_eval import K_tar_eval\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from grad_ker1_gpu import grad_ker1 as grad_ker1_gpu\n",
    "    from K_tar_eval_gpu import K_tar_eval as K_tar_eval_gpu\n",
    "    GPU_AVAILABLE = True\n",
    "except Exception:\n",
    "    cp = None\n",
    "    grad_ker1_gpu = None\n",
    "    K_tar_eval_gpu = None\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_gpu_kswgd = bool(GPU_AVAILABLE and torch.cuda.is_available())\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GPU Info\")\n",
    "print(\"=\" * 50)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {props.name}, Memory: {props.total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"No CUDA GPU available\")\n",
    "\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "print(f\"KSWGD GPU backend: {'enabled' if use_gpu_kswgd else 'disabled'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a060825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 datasets and build training/test data loaders\n",
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # [0, 1], shape: 3x32x32\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset  = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset), \"Test size:\", len(test_dataset))\n",
    "print(\"Number of classes:\", len(train_dataset.classes))\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Image shape: 3x32x32 (RGB color)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a837b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fully connected autoencoder blocks used for the MLP baseline\n",
    "# CIFAR-100: 32x32x3 = 3072 input dimensions\n",
    "latent_dim = 16  # increased for more complex color images\n",
    "\n",
    "class MLPEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class MLPDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 32 * 32 * 3),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_flat = self.net(z)\n",
    "        return x_flat.view(-1, 3, 32, 32)\n",
    "\n",
    "\n",
    "class MLPAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.encoder = MLPEncoder(latent_dim)\n",
    "        self.decoder = MLPDecoder(latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the convolutional autoencoder architecture for improved spatial modeling\n",
    "# CIFAR-100: 3x32x32 RGB images\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),    # 3x32x32 -> 64x32x32\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 64x32x32 -> 128x16x16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # 128x16x16 -> 256x8x8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1), # 256x8x8 -> 512x4x4\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        z = self.fc(h)\n",
    "        return z\n",
    "\n",
    "\n",
    "class CNNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512 * 4 * 4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),  # 512x4x4 -> 256x8x8\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 256x8x8 -> 128x16x16\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),   # 128x16x16 -> 64x32x32\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1),  # 64x32x32 -> 3x32x32\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.fc(z)\n",
    "        h = h.view(-1, 512, 4, 4)\n",
    "        x = self.deconv(h)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.encoder = CNNEncoder(latent_dim)\n",
    "        self.decoder = CNNDecoder(latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which autoencoder variant to train and move it to the target device\n",
    "# Option 1: MLP autoencoder\n",
    "# autoencoder = MLPAutoencoder(latent_dim=latent_dim).to(device)\n",
    "\n",
    "# Option 2: CNN autoencoder (default here)\n",
    "autoencoder = CNNAutoencoder(latent_dim=latent_dim).to(device)\n",
    "\n",
    "print(autoencoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the selected autoencoder on MNIST with Adam, validation, and per-class loss analysis\n",
    "num_epochs = 60\n",
    "learning_rate = 1e-3\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon, z = autoencoder(images)\n",
    "        loss = criterion(recon, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    autoencoder.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(device)\n",
    "            recon, _ = autoencoder(images)\n",
    "            val_loss += criterion(recon, images).item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "\n",
    "    # Track best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "    print(f\"Epoch [{epoch+1:2d}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nBest validation loss: {best_val_loss:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch of original vs reconstructed digits to sanity-check training\n",
    "autoencoder.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    recon, _ = autoencoder(images)\n",
    "\n",
    "images_cpu = images.cpu().numpy()\n",
    "recon_cpu = recon.cpu().numpy()\n",
    "\n",
    "n_show = 12\n",
    "fig, axes = plt.subplots(2, n_show, figsize=(2 * n_show, 4))\n",
    "fig.suptitle(\"Original(upper) vs Recon(lower)\", fontsize=30)\n",
    "for i in range(n_show):\n",
    "    axes[0, i].imshow(images_cpu[i, 0], cmap=\"gray\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "    # axes[0, i].set_title(\"Original (DM)\", fontsize=20)\n",
    "    axes[1, i].imshow(recon_cpu[i, 0], cmap=\"gray\")\n",
    "    axes[1, i].axis(\"off\")\n",
    "    # axes[1, i].set_title(\"Recon (DM)\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c66079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the full training set to collect latent vectors and labels for DM\n",
    "autoencoder.eval()\n",
    "\n",
    "all_latents = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        _, z = autoencoder(images)\n",
    "        all_latents.append(z.cpu().numpy())\n",
    "        all_labels.append(labels.numpy())\n",
    "\n",
    "Z = np.concatenate(all_latents, axis=0)   # shape (N, latent_dim)\n",
    "y_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "print(\"Latent codes shape:\", Z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc211ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the latent sample subset and kernel matrix required for diffusion maps\n",
    "# Subsample for Diffusion Maps (e.g., 5000 points) with stratified sampling to keep label balance\n",
    "max_dm_samples = 20000\n",
    "N_total = Z.shape[0]\n",
    "\n",
    "if N_total > max_dm_samples:\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, train_size=max_dm_samples, random_state=42)\n",
    "    idx_dm, _ = next(splitter.split(Z, y_labels))\n",
    "else:\n",
    "    idx_dm = np.arange(N_total)\n",
    "\n",
    "Z_dm_raw = Z[idx_dm]\n",
    "labels_dm = y_labels[idx_dm]\n",
    "\n",
    "# ========== STANDARDIZE latent codes for DM ==========\n",
    "# This ensures all dimensions have similar scale for proper kernel computation\n",
    "Z_dm_mean = np.mean(Z_dm_raw, axis=0, keepdims=True)\n",
    "Z_dm_std = np.std(Z_dm_raw, axis=0, keepdims=True) + 1e-8\n",
    "Z_dm = (Z_dm_raw - Z_dm_mean) / Z_dm_std  # Standardized latent codes\n",
    "print(f\"Standardized Z_dm: mean~{Z_dm.mean():.4f}, std~{Z_dm.std():.4f}\")\n",
    "# =====================================================\n",
    "\n",
    "unique_labels, label_counts = np.unique(labels_dm, return_counts=True)\n",
    "label_hist = {int(lbl): int(cnt) for lbl, cnt in zip(unique_labels, label_counts)}\n",
    "print(\"Latent points used for DM:\", Z_dm.shape)\n",
    "print(\"Label histogram in DM subset:\", label_hist)\n",
    "\n",
    "# Pairwise distances (now on standardized data)\n",
    "dists = pairwise_distances(Z_dm, metric=\"euclidean\")\n",
    "\n",
    "# Epsilon via median heuristic (can adjust multiplier for better separation)\n",
    "med_sq = np.median(dists**2)\n",
    "eps = med_sq / (2.0 * np.log(Z_dm.shape[0]))\n",
    "# Alternative: use a smaller epsilon for tighter clustering\n",
    "# eps = np.percentile(dists**2, 10)  # 10th percentile for local structure\n",
    "print(\"Chosen epsilon:\", eps)\n",
    "print(f\"Distance stats: min={dists[dists>0].min():.4f}, median={np.median(dists):.4f}, max={dists.max():.4f}\")\n",
    "\n",
    "# Gaussian kernel\n",
    "K = np.exp(-dists**2 / (2.0 * eps))\n",
    "\n",
    "# Row-normalize -> Markov matrix P\n",
    "row_sums = K.sum(axis=1, keepdims=True)\n",
    "P = K / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b22280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the leading diffusion-map eigenpairs to obtain coordinates and spectra\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "m = 15  # number of eigenvectors\n",
    "t_diffusion = 1  # diffusion time for scaling coordinates\n",
    "\n",
    "# Create progress bar widget\n",
    "progress_bar = widgets.FloatProgress(\n",
    "    value=0, min=0, max=100, \n",
    "    description='Computing:', \n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#00a0dc', 'description_width': '80px'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "status_label = widgets.HTML(value=\"<b>Starting eigenvalue decomposition...</b>\")\n",
    "time_label = widgets.HTML(value=\"\")\n",
    "display(widgets.VBox([progress_bar, status_label, time_label]))\n",
    "\n",
    "# Estimate computation based on matrix size\n",
    "n_samples = P.shape[0]\n",
    "print(f\"Matrix size: {n_samples} x {n_samples}, computing {m} eigenvectors...\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Update progress - phase 1: preparation\n",
    "progress_bar.value = 10\n",
    "status_label.value = \"<b>Phase 1/3:</b> Preparing matrix transpose...\"\n",
    "time.sleep(0.1)\n",
    "\n",
    "# Compute eigenvalues with progress updates\n",
    "progress_bar.value = 20\n",
    "status_label.value = \"<b>Phase 2/3:</b> Computing eigenvalue decomposition (this may take a while)...\"\n",
    "\n",
    "# The actual computation\n",
    "vals, vecs = eigs(P.T, k=m, which=\"LR\")\n",
    "\n",
    "# Update progress - phase 3: post-processing\n",
    "progress_bar.value = 80\n",
    "elapsed = time.time() - start_time\n",
    "status_label.value = \"<b>Phase 3/3:</b> Sorting and scaling eigenvectors...\"\n",
    "time_label.value = f\"<i>Eigenvalue computation took: {elapsed:.1f} seconds</i>\"\n",
    "\n",
    "idx_sort = np.argsort(-np.abs(vals))\n",
    "vals = vals[idx_sort]\n",
    "vecs = vecs[:, idx_sort]\n",
    "\n",
    "lam = np.real(vals)\n",
    "phi_raw = np.real(vecs)\n",
    "\n",
    "# Scale diffusion coordinates by eigenvalues^t (standard Diffusion Maps embedding)\n",
    "# This amplifies the coordinates to show structure at different scales\n",
    "phi = phi_raw * (lam[np.newaxis, :] ** t_diffusion)\n",
    "\n",
    "# Finalize progress\n",
    "progress_bar.value = 100\n",
    "progress_bar.bar_style = 'success'\n",
    "total_time = time.time() - start_time\n",
    "status_label.value = \"<b style='color: green;'>✓ Completed!</b>\"\n",
    "time_label.value = f\"<i>Total time: {total_time:.1f} seconds</i>\"\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Leading eigenvalues:\", lam)\n",
    "print(f\"Diffusion coords range: [{phi[:, 1:].min():.4f}, {phi[:, 1:].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several diffusion-coordinate pairs with GMM outlier filtering (keep ~90% of points)\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# GMM outlier filtering parameters\n",
    "n_gmm_components_2d = 10  # number of GMM components\n",
    "outlier_percentile = 15   # remove bottom 10% by GMM log-likelihood (keep 90%)\n",
    "\n",
    "pairs = [(1, 2), (1, 3), (2, 3)]\n",
    "for i, j in pairs:\n",
    "    dc_i = phi[:, i]\n",
    "    dc_j = phi[:, j]\n",
    "    coords_2d = np.column_stack([dc_i, dc_j])\n",
    "    \n",
    "    # Fit GMM and compute log-likelihood scores\n",
    "    gmm_2d = GaussianMixture(n_components=n_gmm_components_2d, covariance_type='full', random_state=42)\n",
    "    gmm_2d.fit(coords_2d)\n",
    "    log_probs_2d = gmm_2d.score_samples(coords_2d)\n",
    "    \n",
    "    # Keep top 90% by log-likelihood (filter out bottom 10% outliers)\n",
    "    threshold_2d = np.percentile(log_probs_2d, outlier_percentile)\n",
    "    inlier_mask_2d = log_probs_2d >= threshold_2d\n",
    "    \n",
    "    n_total = len(dc_i)\n",
    "    n_kept = np.sum(inlier_mask_2d)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    scatter = plt.scatter(dc_i[inlier_mask_2d], dc_j[inlier_mask_2d], \n",
    "                          c=labels_dm[inlier_mask_2d], s=5, alpha=0.6, cmap=\"tab10\")\n",
    "    plt.xlabel(f\"Diffusion Map coord {i}\")\n",
    "    plt.ylabel(f\"Diffusion Map coord {j}\")\n",
    "    plt.title(f\"DC{i} vs DC{j} (GMM filtered: {n_kept}/{n_total}, {100*n_kept/n_total:.1f}%)\")\n",
    "    plt.colorbar(scatter, label=\"Digit label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D diffusion-coordinate visualization with GMM outlier filtering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# ============== RESCALE PARAMETER ==============\n",
    "# Increase this value to spread clusters further apart\n",
    "# Typical values: 1.0 (no change), 2.0-5.0 (moderate spread), 5.0-10.0 (large spread)\n",
    "SPREAD_FACTOR = 1.0  # <-- Adjust this to control cluster separation\n",
    "# ===============================================\n",
    "\n",
    "# Use first 3 nontrivial diffusion coordinates for 3D plot\n",
    "# Scale by eigenvalues to get proper diffusion distances (standard practice)\n",
    "dc_1_raw = phi[:, 1] * lam[1]\n",
    "dc_2_raw = phi[:, 2] * lam[2]\n",
    "dc_3_raw = phi[:, 3] * lam[3]\n",
    "coords_3d_raw = np.column_stack([dc_1_raw, dc_2_raw, dc_3_raw])\n",
    "\n",
    "print(f\"Raw coordinate ranges (before filtering):\")\n",
    "print(f\"  DC1: [{dc_1_raw.min():.4f}, {dc_1_raw.max():.4f}]\")\n",
    "print(f\"  DC2: [{dc_2_raw.min():.4f}, {dc_2_raw.max():.4f}]\")\n",
    "print(f\"  DC3: [{dc_3_raw.min():.4f}, {dc_3_raw.max():.4f}]\")\n",
    "\n",
    "# Step 1: First pass - use IQR to remove extreme outliers before GMM\n",
    "def iqr_filter(data, factor=3.0):\n",
    "    \"\"\"Remove points outside factor*IQR from Q1/Q3\"\"\"\n",
    "    q1 = np.percentile(data, 25, axis=0)\n",
    "    q3 = np.percentile(data, 75, axis=0)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - factor * iqr\n",
    "    upper = q3 + factor * iqr\n",
    "    mask = np.all((data >= lower) & (data <= upper), axis=1)\n",
    "    return mask\n",
    "\n",
    "iqr_mask = iqr_filter(coords_3d_raw, factor=2.5)\n",
    "print(f\"\\nIQR pre-filter: removed {np.sum(~iqr_mask)} extreme points ({100*np.sum(~iqr_mask)/len(iqr_mask):.1f}%)\")\n",
    "\n",
    "# Step 2: Fit GMM on IQR-filtered data for finer outlier detection\n",
    "coords_filtered = coords_3d_raw[iqr_mask]\n",
    "n_gmm_components = 10\n",
    "gmm = GaussianMixture(n_components=n_gmm_components, covariance_type='full', random_state=42)\n",
    "gmm.fit(coords_filtered)\n",
    "\n",
    "# Score ALL points with the GMM trained on filtered data\n",
    "log_probs_all = gmm.score_samples(coords_3d_raw)\n",
    "# Use a more aggressive threshold: bottom 5% of GMM scores\n",
    "threshold = np.percentile(log_probs_all[iqr_mask], 10)\n",
    "gmm_mask = log_probs_all >= threshold\n",
    "\n",
    "# Combine both filters\n",
    "inlier_mask = iqr_mask & gmm_mask\n",
    "\n",
    "print(f\"GMM filter: removed additional {np.sum(iqr_mask & ~gmm_mask)} points\")\n",
    "print(f\"Total outliers removed: {np.sum(~inlier_mask)} ({100*np.sum(~inlier_mask)/len(inlier_mask):.1f}%)\")\n",
    "print(f\"Inliers kept: {np.sum(inlier_mask)}\")\n",
    "\n",
    "# Step 3: Standardize inliers, then apply SPREAD_FACTOR to increase separation\n",
    "scaler = RobustScaler()  # More robust to remaining outliers\n",
    "coords_inliers = coords_3d_raw[inlier_mask]\n",
    "coords_scaled = scaler.fit_transform(coords_inliers)\n",
    "\n",
    "# Apply spread factor: multiply by SPREAD_FACTOR to increase inter-cluster distances\n",
    "coords_spread = coords_scaled * SPREAD_FACTOR\n",
    "\n",
    "dc_1_plot, dc_2_plot, dc_3_plot = coords_spread[:, 0], coords_spread[:, 1], coords_spread[:, 2]\n",
    "\n",
    "print(f\"\\nFiltered & scaled coordinate ranges (SPREAD_FACTOR={SPREAD_FACTOR}):\")\n",
    "print(f\"  DC1: [{dc_1_plot.min():.3f}, {dc_1_plot.max():.3f}]\")\n",
    "print(f\"  DC2: [{dc_2_plot.min():.3f}, {dc_2_plot.max():.3f}]\")\n",
    "print(f\"  DC3: [{dc_3_plot.min():.3f}, {dc_3_plot.max():.3f}]\")\n",
    "\n",
    "# Plot 3D with inliers only (properly filtered and spread)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    dc_1_plot, dc_2_plot, dc_3_plot,\n",
    "    c=labels_dm[inlier_mask], s=8, alpha=0.6, cmap=\"tab10\"\n",
    ")\n",
    "ax.set_xlabel(\"DC 1 (scaled)\")\n",
    "ax.set_ylabel(\"DC 2 (scaled)\")\n",
    "ax.set_zlabel(\"DC 3 (scaled)\")\n",
    "ax.set_title(f\"3D Diffusion Map (spread={SPREAD_FACTOR}x, {np.sum(inlier_mask)}/{len(inlier_mask)} points)\")\n",
    "fig.colorbar(scatter, ax=ax, label=\"Digit label\", shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also show where outliers were (using same scaling)\n",
    "scaler_all = RobustScaler().fit(coords_3d_raw[inlier_mask])\n",
    "coords_all_scaled = scaler_all.transform(coords_3d_raw) * SPREAD_FACTOR\n",
    "dc_1_all, dc_2_all, dc_3_all = coords_all_scaled[:, 0], coords_all_scaled[:, 1], coords_all_scaled[:, 2]\n",
    "\n",
    "fig2 = plt.figure(figsize=(10, 8))\n",
    "ax2 = fig2.add_subplot(111, projection='3d')\n",
    "ax2.scatter(\n",
    "    dc_1_all[inlier_mask], dc_2_all[inlier_mask], dc_3_all[inlier_mask],\n",
    "    c=labels_dm[inlier_mask], s=8, alpha=0.5, cmap=\"tab10\", label=\"Inliers\"\n",
    ")\n",
    "ax2.scatter(\n",
    "    dc_1_all[~inlier_mask], dc_2_all[~inlier_mask], dc_3_all[~inlier_mask],\n",
    "    c='red', s=25, alpha=0.9, marker='x', label=f\"Outliers ({np.sum(~inlier_mask)})\"\n",
    ")\n",
    "ax2.set_xlabel(\"DC 1\")\n",
    "ax2.set_ylabel(\"DC 2\")\n",
    "ax2.set_zlabel(\"DC 3\")\n",
    "ax2.set_title(\"3D Diffusion Map (outliers shown in red)\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbdc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute diffusion-space mean and covariance for Gaussian diagnostics\n",
    "num_dc = 8  # number of nontrivial diffusion coords to use (<= m-1)\n",
    "Y_dm = phi[:, 1:1 + num_dc]\n",
    "print(\"Diffusion-space data shape:\", Y_dm.shape)\n",
    "\n",
    "mu_Y = np.mean(Y_dm, axis=0)\n",
    "cov_Y = np.cov(Y_dm.T)\n",
    "\n",
    "print(\"Mean in diffusion space:\", mu_Y)\n",
    "print(\"Covariance shape:\", cov_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ac4c0",
   "metadata": {},
   "source": [
    "## KSWGD-based latent generation\n",
    "Following the KSWGD workflow from Tests 1 & 2, we now treat the autoencoder latents as the target samples and run Wasserstein gradient dynamics directly in latent space. Diffusion maps remain available above for visualization, but the sampling path below no longer uses the Gaussian model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize DM latents and build the KSWGD kernel operators\n",
    "# NOTE: Z_dm is already standardized in Cell 11, so we use it directly\n",
    "X_tar = Z_dm.astype(np.float64)  # target samples for KSWGD (already standardized)\n",
    "sq_tar = np.sum(X_tar ** 2, axis=1)\n",
    "\n",
    "kswgd_dists = pairwise_distances(X_tar, metric=\"euclidean\")\n",
    "eps_kswgd = np.median(kswgd_dists**2) / (2.0 * np.log(X_tar.shape[0] + 1))\n",
    "eps_kswgd = float(max(eps_kswgd, 1e-6))\n",
    "data_kernel = np.exp(-kswgd_dists**2 / (2.0 * eps_kswgd))\n",
    "\n",
    "p_x = np.sqrt(np.sum(data_kernel, axis=1))\n",
    "data_kernel_norm = data_kernel / (p_x[:, None] * p_x[None, :] + 1e-12)\n",
    "D_y = np.sum(data_kernel_norm, axis=0)\n",
    "rw_kernel = 0.5 * (data_kernel_norm / (D_y + 1e-12) + data_kernel_norm / (D_y[:, None] + 1e-12))\n",
    "# rw_kernel = data_kernel_norm / (D_y[:, None] + 1e-12)\n",
    "rw_kernel = np.nan_to_num(rw_kernel)\n",
    "\n",
    "print(\"KSWGD target shape:\", X_tar.shape)\n",
    "print(\"KSWGD epsilon:\", eps_kswgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f941f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build spectral quantities and KSWGD weights\n",
    "lambda_ns, phi = np.linalg.eigh(rw_kernel)\n",
    "phi = np.real(phi[:, ::-1])\n",
    "lambda_ns = np.real(lambda_ns[::-1])\n",
    "\n",
    "tol = 1e-6\n",
    "reg = 1e-3\n",
    "# lambda_ = -lambda_ns + 1.0\n",
    "lambda_ = lambda_ns - 1.0\n",
    "inv_lambda = np.zeros_like(lambda_)\n",
    "inv_lambda[1:] = 1.0 / np.clip(lambda_[1:], 1e-12, None)\n",
    "inv_lambda *= eps_kswgd\n",
    "\n",
    "lambda_ns_inv = np.zeros_like(lambda_ns)\n",
    "mask = lambda_ns >= tol\n",
    "lambda_ns_inv[mask] = eps_kswgd / (lambda_ns[mask] + reg)\n",
    "above_tol = int(np.sum(mask))\n",
    "phi_trunc = phi[:, :above_tol]\n",
    "lambda_ns_s_ns = (lambda_ns_inv * inv_lambda * lambda_ns_inv)[:above_tol]\n",
    "\n",
    "p_tar = np.sum(data_kernel, axis=0)\n",
    "sqrt_p = np.sqrt(p_tar + 1e-12)\n",
    "D_vec = np.sum(data_kernel / sqrt_p[:, None] / sqrt_p[None, :], axis=1)\n",
    "\n",
    "print(\"Retained eigenvectors for KSWGD:\", above_tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7d619",
   "metadata": {},
   "source": [
    "## EDMD dictionary-learning pipeline\n",
    "We now replicate the TestÂ 2 EDMD workflow on the MNIST latents: learn a sparse dictionary on the standardized targets, build a stochastic DMD operator in the resulting feature space, and feed the Koopman spectrum into KSWGD for a third generative path. The next cells construct the KDE drift pairs that seed the dictionary stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc488d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE-based drift estimation and Langevin evolution to build EDMD pairs\n",
    "dt_edmd = 0.1  # time step for EDMD Langevin evolution\n",
    "dist2_edmd = pairwise_distances(X_tar, metric=\"sqeuclidean\")  # returns squared distances directly\n",
    "h_edmd = np.sqrt(np.median(dist2_edmd) + 1e-12)\n",
    "W_edmd = np.exp(-dist2_edmd / (2.0 * (h_edmd ** 2)))\n",
    "sumW_edmd = np.sum(W_edmd, axis=1, keepdims=True) + 1e-12\n",
    "weighted_means_edmd = W_edmd @ X_tar / sumW_edmd\n",
    "score_edmd = (weighted_means_edmd - X_tar) / (h_edmd ** 2)  # KDE score = drift term\n",
    "\n",
    "# Langevin step with unit diffusion so the stochastic term uses sqrt(2 dt)\n",
    "xi_edmd = np.random.normal(0.0, 1.0, size=X_tar.shape)\n",
    "X_tar_next = X_tar + dt_edmd * score_edmd + np.sqrt(2.0 * dt_edmd) * xi_edmd\n",
    "\n",
    "print(\"EDMD drift bandwidth h:\", h_edmd)\n",
    "print(\"X_tar_next stats -> mean {:.4f}, std {:.4f}\".format(X_tar_next.mean(), X_tar_next.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b842c",
   "metadata": {},
   "source": [
    "### Dictionary learning and Koopman operator\n",
    "With the EDMD drift pairs in place, we now learn a sparse dictionary on the standardized targets, construct the stochastic DMD operator in that feature space, and feed its spectrum back into KSWGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351674a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn a sparse dictionary on standardized KSWGD targets and encode Koopman pairs\n",
    "n_dict_components = 100\n",
    "dict_alpha = 1e-3\n",
    "dict_batch = 256\n",
    "dict_max_iter = 500\n",
    "dict_random_state = 42\n",
    "\n",
    "dict_model = MiniBatchDictionaryLearning(\n",
    "    n_components=n_dict_components,\n",
    "    alpha=dict_alpha,\n",
    "    batch_size=dict_batch,\n",
    "    max_iter=dict_max_iter,\n",
    "    random_state=dict_random_state,\n",
    "    verbose=0,\n",
    "    fit_algorithm=\"lars\"\n",
    ")\n",
    "dict_model.fit(X_tar)\n",
    "\n",
    "Phi_X = dict_model.transform(X_tar)\n",
    "Phi_Y = dict_model.transform(X_tar_next)\n",
    "Phi_X = np.hstack([np.ones((Phi_X.shape[0], 1)), Phi_X])\n",
    "Phi_Y = np.hstack([np.ones((Phi_Y.shape[0], 1)), Phi_Y])\n",
    "\n",
    "print(\"Dictionary atoms:\", dict_model.components_.shape)\n",
    "print(\"Dictionary codes (current):\", Phi_X.shape)\n",
    "print(\"Dictionary codes (next):\", Phi_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the EDMD operator in dictionary space and extract Koopman spectrum\n",
    "reg_edmd = 1e-3\n",
    "N_edmd, m_edmd = Phi_X.shape\n",
    "G_edmd = (Phi_X.T @ Phi_X) / N_edmd + reg_edmd * np.eye(m_edmd)\n",
    "A_edmd = (Phi_X.T @ Phi_Y) / N_edmd\n",
    "\n",
    "eigvals_edmd, eigvecs_edmd = eig(A_edmd, G_edmd)\n",
    "idx_edmd = np.argsort(-eigvals_edmd.real)\n",
    "eigvals_edmd = eigvals_edmd[idx_edmd]\n",
    "eigvecs_edmd = eigvecs_edmd[:, idx_edmd]\n",
    "\n",
    "efuns_edmd = Phi_X @ eigvecs_edmd\n",
    "\n",
    "print(\"EDMD eigenvalues (first 6):\", np.round(eigvals_edmd[:6].real, 4))\n",
    "print(\"EDMD dictionary modes shape:\", efuns_edmd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare EDMD-derived KSWGD weights (skip constant mode)\n",
    "lambda_ns_edmd = eigvals_edmd.real\n",
    "lambda_gen_edmd = (lambda_ns_edmd - 1.0) / dt_edmd\n",
    "# lambda_gen_edmd = (1.0 - lambda_ns_edmd) / dt_edmd\n",
    "\n",
    "mode_skip_edmd = 1\n",
    "eig_threshold_edmd = 1e-6  # keep more Koopman modes for generative transport\n",
    "valid_idx_edmd = np.arange(mode_skip_edmd, lambda_ns_edmd.shape[0])\n",
    "valid_mask_edmd = lambda_ns_edmd[mode_skip_edmd:] > eig_threshold_edmd\n",
    "valid_idx_edmd = valid_idx_edmd[valid_mask_edmd]\n",
    "\n",
    "if valid_idx_edmd.size == 0:\n",
    "    raise RuntimeError(\"No EDMD modes survived the threshold; adjust eig_threshold_edmd or dictionary size.\")\n",
    "\n",
    "phi_trunc_edmd = np.real(efuns_edmd[:, valid_idx_edmd])\n",
    "lambda_gen_inv_edmd = np.zeros_like(lambda_gen_edmd)\n",
    "mask_nonzero_edmd = np.abs(lambda_gen_edmd) > 1e-6\n",
    "lambda_gen_inv_edmd[mask_nonzero_edmd] = 1.0 / lambda_gen_edmd[mask_nonzero_edmd]\n",
    "lambda_ns_s_ns_edmd = lambda_gen_inv_edmd[valid_idx_edmd].real\n",
    "\n",
    "print(f\"EDMD kept {valid_idx_edmd.size} modes (threshold {eig_threshold_edmd})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ae3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare diffusion-map and EDMD spectra\n",
    "n_show_eigs = 15\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.semilogy(range(1, n_show_eigs + 1), lambda_ns[:n_show_eigs], marker=\"o\", label=\"Diffusion Maps\")\n",
    "plt.semilogy(\n",
    "    range(1, min(n_show_eigs, lambda_ns_edmd.size) + 1),\n",
    "    lambda_ns_edmd[:n_show_eigs],\n",
    "    marker=\"^\",\n",
    "    label=\"EDMD dictionary\",\n",
    ")\n",
    "plt.xlabel(\"Eigen-index\")\n",
    "plt.ylabel(\"Eigenvalue (log scale)\")\n",
    "plt.title(\"Spectral decay comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DM and EDMD eigenvalues on separate unit circles (including leading mode)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "# Common unit circle\n",
    "theta = np.linspace(0, 2 * np.pi, 400)\n",
    "circle_x = np.cos(theta)\n",
    "circle_y = np.sin(theta)\n",
    "\n",
    "# Left: DM spectrum (real eigenvalues), show first above_tol modes (includes leading one)\n",
    "ax_dm = axes[0]\n",
    "ax_dm.plot(circle_x, circle_y, \"k--\", linewidth=1.0, label=\"Unit circle\")\n",
    "lambda_ns_dm_plot = lambda_ns[:above_tol]\n",
    "ax_dm.scatter(lambda_ns_dm_plot, np.zeros_like(lambda_ns_dm_plot),\n",
    "               c=\"tab:blue\", s=40, alpha=0.7, label=\"DM eigenvalues\")\n",
    "ax_dm.axhline(0.0, color=\"gray\", linewidth=0.5)\n",
    "ax_dm.axvline(0.0, color=\"gray\", linewidth=0.5)\n",
    "ax_dm.set_xlabel(\"Real part\")\n",
    "ax_dm.set_ylabel(\"Imaginary part\")\n",
    "ax_dm.set_title(\"DM spectrum\")\n",
    "ax_dm.set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax_dm.legend()\n",
    "\n",
    "# Right: EDMD spectrum (possibly complex), show leading n_show_eigs modes (including index 0)\n",
    "ax_edmd = axes[1]\n",
    "ax_edmd.plot(circle_x, circle_y, \"k--\", linewidth=1.0, label=\"Unit circle\")\n",
    "n_show_edmd_circle = min(above_tol, eigvals_edmd.size)\n",
    "eigvals_edmd_plot = eigvals_edmd[:n_show_edmd_circle]\n",
    "ax_edmd.scatter(eigvals_edmd_plot.real, eigvals_edmd_plot.imag,\n",
    "                 c=\"tab:orange\", s=40, alpha=0.7, label=\"EDMD eigenvalues\")\n",
    "ax_edmd.axhline(0.0, color=\"gray\", linewidth=0.5)\n",
    "ax_edmd.axvline(0.0, color=\"gray\", linewidth=0.5)\n",
    "ax_edmd.set_xlabel(\"Real part\")\n",
    "ax_edmd.set_ylabel(\"Imaginary part\")\n",
    "ax_edmd.set_title(\"EDMD spectrum\")\n",
    "ax_edmd.set_aspect(\"equal\", adjustable=\"box\")\n",
    "ax_edmd.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b719d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect leading eigenvalues for DM and EDMD around the truncation\n",
    "n_print = 10\n",
    "print(\"=== Diffusion Maps (DM) eigenvalues ===\")\n",
    "print(\"all lambda_ns[:n_print]:\", np.round(lambda_ns[:n_print], 6))\n",
    "print()\n",
    "print(\"=== EDMD eigenvalues ===\")\n",
    "print(\"eigvals_edmd (real parts, first n_print):\", np.round(eigvals_edmd[:n_print].real, 6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5d782",
   "metadata": {},
   "source": [
    "## KSWGD transports with shared latents\n",
    "Both diffusion-map (DM) and EDMD spectra feed Wasserstein dynamics below. Each transport reuses the same standardized targets `X_tar`, so differences stem solely from their generator spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213eff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_particles = 64\n",
    "num_iters = 500\n",
    "step_size = 0.1\n",
    "rng_seed = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KSWGD driven by the diffusion-map spectrum\n",
    "m_particles_dm = m_particles\n",
    "num_iters_dm = num_iters\n",
    "step_size_dm = step_size\n",
    "latent_dim = X_tar.shape[1]\n",
    "rng_dm = rng_seed\n",
    "\n",
    "grad_fn = grad_ker1_gpu if use_gpu_kswgd else grad_ker1\n",
    "K_eval_fn = K_tar_eval_gpu if use_gpu_kswgd else K_tar_eval\n",
    "xp = cp if use_gpu_kswgd else np\n",
    "\n",
    "init_particles_dm = rng_dm.normal(0.0, 1.0, size=(m_particles_dm, latent_dim))\n",
    "if use_gpu_kswgd:\n",
    "    X_tar_dm_dev = cp.asarray(X_tar)\n",
    "    p_tar_dm_dev = cp.asarray(p_tar)\n",
    "    sq_tar_dm_dev = cp.asarray(sq_tar)\n",
    "    D_vec_dm_dev = cp.asarray(D_vec)\n",
    "    phi_trunc_dm_dev = cp.asarray(phi_trunc)\n",
    "    lambda_ns_s_ns_dm_dev = cp.asarray(lambda_ns_s_ns)\n",
    "    x_hist_dm = cp.zeros((m_particles_dm, latent_dim, num_iters_dm), dtype=cp.float64)\n",
    "    x_hist_dm[:, :, 0] = cp.asarray(init_particles_dm, dtype=cp.float64)\n",
    "else:\n",
    "    X_tar_dm_dev = X_tar\n",
    "    p_tar_dm_dev = p_tar\n",
    "    sq_tar_dm_dev = sq_tar\n",
    "    D_vec_dm_dev = D_vec\n",
    "    phi_trunc_dm_dev = phi_trunc\n",
    "    lambda_ns_s_ns_dm_dev = lambda_ns_s_ns\n",
    "    x_hist_dm = np.zeros((m_particles_dm, latent_dim, num_iters_dm), dtype=np.float64)\n",
    "    x_hist_dm[:, :, 0] = init_particles_dm\n",
    "\n",
    "kswgd_loop_dm = trange(num_iters_dm - 1, desc=\"DMPS\", unit=\"step\")\n",
    "for t in kswgd_loop_dm:\n",
    "    grad_matrix = grad_fn(x_hist_dm[:, :, t], X_tar_dm_dev, p_tar_dm_dev, sq_tar_dm_dev, D_vec_dm_dev, eps_kswgd)\n",
    "    cross_matrix = K_eval_fn(X_tar_dm_dev, x_hist_dm[:, :, t], p_tar_dm_dev, sq_tar_dm_dev, D_vec_dm_dev, eps_kswgd)\n",
    "    tmp = phi_trunc_dm_dev.T @ cross_matrix\n",
    "    tmp = lambda_ns_s_ns_dm_dev[:, None] * tmp\n",
    "    kswgd_push = phi_trunc_dm_dev @ tmp\n",
    "    for dim in range(latent_dim):\n",
    "        sum_term = grad_matrix[:, :, dim] @ kswgd_push\n",
    "        x_hist_dm[:, dim, t + 1] = x_hist_dm[:, dim, t] - (step_size_dm / m_particles_dm) * xp.sum(sum_term, axis=1)\n",
    "    if (t + 1) % 25 == 0 or (t + 1) == num_iters_dm - 1:\n",
    "        step_norm = x_hist_dm[:, :, t + 1] - x_hist_dm[:, :, t]\n",
    "        if use_gpu_kswgd:\n",
    "            mean_disp = float(cp.mean(cp.linalg.norm(step_norm, axis=1)).get())\n",
    "        else:\n",
    "            mean_disp = float(np.mean(np.linalg.norm(step_norm, axis=1)))\n",
    "        kswgd_loop_dm.set_postfix({\"mean_step\": f\"{mean_disp:.3e}\"})\n",
    "\n",
    "if use_gpu_kswgd:\n",
    "    Z_new_dm_std = cp.asnumpy(x_hist_dm[:, :, -1])\n",
    "else:\n",
    "    Z_new_dm_std = x_hist_dm[:, :, -1]\n",
    "\n",
    "Z_new_kswgd_dm = Z_new_dm_std * Z_dm_std + Z_dm_mean\n",
    "print(\"DMPS latent samples shape:\", Z_new_kswgd_dm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebe111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run KSWGD using the EDMD dictionary spectrum\n",
    "m_particles_edmd = m_particles\n",
    "num_iters_edmd = num_iters\n",
    "step_size_edmd = step_size\n",
    "rng_edmd = rng_seed\n",
    "\n",
    "grad_fn = grad_ker1_gpu if use_gpu_kswgd else grad_ker1\n",
    "K_eval_fn = K_tar_eval_gpu if use_gpu_kswgd else K_tar_eval\n",
    "xp = cp if use_gpu_kswgd else np\n",
    "\n",
    "init_particles_edmd = rng_edmd.normal(0.0, 1.0, size=(m_particles_edmd, latent_dim))\n",
    "if use_gpu_kswgd:\n",
    "    X_tar_edmd_dev = cp.asarray(X_tar)\n",
    "    p_tar_edmd_dev = cp.asarray(p_tar)\n",
    "    sq_tar_edmd_dev = cp.asarray(sq_tar)\n",
    "    D_vec_edmd_dev = cp.asarray(D_vec)\n",
    "    phi_trunc_edmd_dev = cp.asarray(phi_trunc_edmd)\n",
    "    lambda_ns_s_ns_edmd_dev = cp.asarray(lambda_ns_s_ns_edmd)\n",
    "    x_hist_edmd = cp.zeros((m_particles_edmd, latent_dim, num_iters_edmd), dtype=cp.float64)\n",
    "    x_hist_edmd[:, :, 0] = cp.asarray(init_particles_edmd, dtype=cp.float64)\n",
    "else:\n",
    "    X_tar_edmd_dev = X_tar\n",
    "    p_tar_edmd_dev = p_tar\n",
    "    sq_tar_edmd_dev = sq_tar\n",
    "    D_vec_edmd_dev = D_vec\n",
    "    phi_trunc_edmd_dev = phi_trunc_edmd\n",
    "    lambda_ns_s_ns_edmd_dev = lambda_ns_s_ns_edmd\n",
    "    x_hist_edmd = np.zeros((m_particles_edmd, latent_dim, num_iters_edmd), dtype=np.float64)\n",
    "    x_hist_edmd[:, :, 0] = init_particles_edmd\n",
    "\n",
    "kswgd_loop_edmd = trange(num_iters_edmd - 1, desc=\"EDMD + KSWGD\", unit=\"step\")\n",
    "for t in kswgd_loop_edmd:\n",
    "    grad_matrix = grad_fn(x_hist_edmd[:, :, t], X_tar_edmd_dev, p_tar_edmd_dev, sq_tar_edmd_dev, D_vec_edmd_dev, eps_kswgd)\n",
    "    cross_matrix = K_eval_fn(X_tar_edmd_dev, x_hist_edmd[:, :, t], p_tar_edmd_dev, sq_tar_edmd_dev, D_vec_edmd_dev, eps_kswgd)\n",
    "    tmp = phi_trunc_edmd_dev.T @ cross_matrix\n",
    "    tmp = lambda_ns_s_ns_edmd_dev[:, None] * tmp\n",
    "    kswgd_push = phi_trunc_edmd_dev @ tmp\n",
    "    for dim in range(latent_dim):\n",
    "        sum_term = grad_matrix[:, :, dim] @ kswgd_push\n",
    "        x_hist_edmd[:, dim, t + 1] = x_hist_edmd[:, dim, t] - (step_size_edmd / m_particles_edmd) * xp.sum(sum_term, axis=1)\n",
    "    if (t + 1) % 25 == 0 or (t + 1) == num_iters_edmd - 1:\n",
    "        step_norm = x_hist_edmd[:, :, t + 1] - x_hist_edmd[:, :, t]\n",
    "        if use_gpu_kswgd:\n",
    "            mean_disp = float(cp.mean(cp.linalg.norm(step_norm, axis=1)).get())\n",
    "        else:\n",
    "            mean_disp = float(np.mean(np.linalg.norm(step_norm, axis=1)))\n",
    "        kswgd_loop_edmd.set_postfix({\"mean_step\": f\"{mean_disp:.3e}\"})\n",
    "\n",
    "if use_gpu_kswgd:\n",
    "    Z_new_edmd_std = cp.asnumpy(x_hist_edmd[:, :, -1])\n",
    "else:\n",
    "    Z_new_edmd_std = x_hist_edmd[:, :, -1]\n",
    "\n",
    "Z_new_kswgd_edmd = Z_new_edmd_std * Z_dm_std + Z_dm_mean\n",
    "print(\"EDMD-KSWGD latent samples shape:\", Z_new_kswgd_edmd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4c14f",
   "metadata": {},
   "source": [
    "## Decode and visualize transports\n",
    "After both transports converge, decode the latent samples with the shared autoencoder decoder and display each batch for visual comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785050d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode DMPS latent vectors\n",
    "autoencoder.eval()\n",
    "Z_new_dm_tensor = torch.from_numpy(Z_new_kswgd_dm).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    dm_images = autoencoder.decoder(Z_new_dm_tensor)\n",
    "\n",
    "dm_images_cpu = dm_images.cpu().numpy()\n",
    "print(\"DMPS images shape:\", dm_images_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize digits generated via DMPS\n",
    "# ============ PARAMETERS TO MAKE STROKES THINNER ============\n",
    "# threshold: pixels below this value become black (0.0-0.5, higher = thinner)\n",
    "# gamma: power adjustment (>1 makes strokes thinner, <1 makes them thicker)\n",
    "THRESHOLD = 0.2  # try 0.2-0.5\n",
    "GAMMA = 1.0      # try 1.0-3.0\n",
    "# =============================================================\n",
    "\n",
    "n_rows_dm = 4\n",
    "n_cols_dm = 16\n",
    "n_show_dm = n_rows_dm * n_cols_dm\n",
    "fig, axes = plt.subplots(n_rows_dm, n_cols_dm, figsize=(2 * n_cols_dm, 2 * n_rows_dm))\n",
    "\n",
    "for i in range(n_show_dm):\n",
    "    ax = axes[i // n_cols_dm, i % n_cols_dm]\n",
    "    img = dm_images_cpu[i, 0]\n",
    "    # Apply threshold and gamma to make strokes thinner\n",
    "    img = np.clip((img - THRESHOLD) / (1.0 - THRESHOLD), 0, 1) ** GAMMA\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Generated MNIST images (DMPS)\", fontsize=40)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8750daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode EDMD-KSWGD latent vectors\n",
    "autoencoder.eval()\n",
    "Z_new_edmd_tensor = torch.from_numpy(Z_new_kswgd_edmd).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    edmd_images = autoencoder.decoder(Z_new_edmd_tensor)\n",
    "\n",
    "edmd_images_cpu = edmd_images.cpu().numpy()\n",
    "print(\"EDMD-KSWGD images shape:\", edmd_images_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5873eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize digits generated via EDMD + KSWGD\n",
    "# ============ PARAMETERS TO MAKE STROKES THINNER ============\n",
    "# threshold: pixels below this value become black (0.0-0.5, higher = thinner)\n",
    "# gamma: power adjustment (>1 makes strokes thinner, <1 makes them thicker)\n",
    "THRESHOLD = 0.2  # try 0.2-0.5\n",
    "GAMMA = 1.0      # try 1.0-3.0\n",
    "# =============================================================\n",
    "\n",
    "n_rows_edmd = 8\n",
    "n_cols_edmd = 8\n",
    "n_show_edmd = n_rows_edmd * n_cols_edmd\n",
    "fig, axes = plt.subplots(n_rows_edmd, n_cols_edmd, figsize=(2 * n_cols_edmd, 2 * n_rows_edmd))\n",
    "\n",
    "for i in range(n_show_edmd):\n",
    "    ax = axes[i // n_cols_edmd, i % n_cols_edmd]\n",
    "    img = edmd_images_cpu[i, 0]\n",
    "    # Apply threshold and gamma to make strokes thinner\n",
    "    img = np.clip((img - THRESHOLD) / (1.0 - THRESHOLD), 0, 1) ** GAMMA\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Generated MNIST images (KSWGD)\", fontsize=40)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over different KSWGD parameters and visualize generated images\n",
    "# Parameters to sweep: m_particles, num_iters, step_size, rng_seed\n",
    "# Uses Cartesian product to generate all combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# ============ PARAMETERS TO MAKE STROKES THINNER ============\n",
    "# threshold: pixels below this value become black (0.0-0.5, higher = thinner)\n",
    "# gamma: power adjustment (>1 makes strokes thinner, <1 makes them thicker)\n",
    "THRESHOLD = 0.2  # try 0.2-0.5\n",
    "GAMMA = 1.0      # try 1.0-3.0\n",
    "# =============================================================\n",
    "\n",
    "# Define parameter lists for the loop (will generate all combinations)\n",
    "rng_seed_list = [1,2,3,4,5]\n",
    "m_particles_list = [64]\n",
    "step_size_list = [0.01,0.05,0.1]\n",
    "num_iters_list = [500]\n",
    "\n",
    "# Generate all combinations using Cartesian product\n",
    "# Order: rng_seed (outermost) -> m_particles -> step_size -> num_iters (innermost, varies fastest)\n",
    "param_combinations = list(product(rng_seed_list, m_particles_list, step_size_list, num_iters_list))\n",
    "n_configs = len(param_combinations)\n",
    "\n",
    "print(f\"Total configurations: {n_configs}\")\n",
    "print(\"Loop order: rng_seed (outer) -> m_particles -> step_size -> num_iters (inner)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for config_idx, (rng_seed_loop, m_particles_loop, step_size_loop, num_iters_loop) in enumerate(param_combinations):\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Config {config_idx + 1}/{n_configs}\")\n",
    "    print(f\"  rng_seed={rng_seed_loop}, m_particles={m_particles_loop}, \"\n",
    "          f\"step_size={step_size_loop}, num_iters={num_iters_loop}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Initialize RNG and particles\n",
    "    rng_loop = np.random.default_rng(rng_seed_loop)\n",
    "    init_particles_loop = rng_loop.normal(0.0, 1.0, size=(m_particles_loop, latent_dim))\n",
    "    \n",
    "    # Setup for EDMD-based KSWGD\n",
    "    grad_fn = grad_ker1_gpu if use_gpu_kswgd else grad_ker1\n",
    "    K_eval_fn = K_tar_eval_gpu if use_gpu_kswgd else K_tar_eval\n",
    "    xp = cp if use_gpu_kswgd else np\n",
    "    \n",
    "    if use_gpu_kswgd:\n",
    "        X_tar_loop_dev = cp.asarray(X_tar)\n",
    "        p_tar_loop_dev = cp.asarray(p_tar)\n",
    "        sq_tar_loop_dev = cp.asarray(sq_tar)\n",
    "        D_vec_loop_dev = cp.asarray(D_vec)\n",
    "        phi_trunc_loop_dev = cp.asarray(phi_trunc_edmd)\n",
    "        lambda_ns_s_ns_loop_dev = cp.asarray(lambda_ns_s_ns_edmd)\n",
    "        x_hist_loop = cp.zeros((m_particles_loop, latent_dim, num_iters_loop), dtype=cp.float64)\n",
    "        x_hist_loop[:, :, 0] = cp.asarray(init_particles_loop, dtype=cp.float64)\n",
    "    else:\n",
    "        X_tar_loop_dev = X_tar\n",
    "        p_tar_loop_dev = p_tar\n",
    "        sq_tar_loop_dev = sq_tar\n",
    "        D_vec_loop_dev = D_vec\n",
    "        phi_trunc_loop_dev = phi_trunc_edmd\n",
    "        lambda_ns_s_ns_loop_dev = lambda_ns_s_ns_edmd\n",
    "        x_hist_loop = np.zeros((m_particles_loop, latent_dim, num_iters_loop), dtype=np.float64)\n",
    "        x_hist_loop[:, :, 0] = init_particles_loop\n",
    "    \n",
    "    # Run KSWGD iterations\n",
    "    kswgd_loop = trange(num_iters_loop - 1, desc=f\"KSWGD Config {config_idx + 1}\", unit=\"step\")\n",
    "    for t in kswgd_loop:\n",
    "        grad_matrix = grad_fn(x_hist_loop[:, :, t], X_tar_loop_dev, p_tar_loop_dev, \n",
    "                              sq_tar_loop_dev, D_vec_loop_dev, eps_kswgd)\n",
    "        cross_matrix = K_eval_fn(X_tar_loop_dev, x_hist_loop[:, :, t], p_tar_loop_dev, \n",
    "                                  sq_tar_loop_dev, D_vec_loop_dev, eps_kswgd)\n",
    "        tmp = phi_trunc_loop_dev.T @ cross_matrix\n",
    "        tmp = lambda_ns_s_ns_loop_dev[:, None] * tmp\n",
    "        kswgd_push = phi_trunc_loop_dev @ tmp\n",
    "        for dim in range(latent_dim):\n",
    "            sum_term = grad_matrix[:, :, dim] @ kswgd_push\n",
    "            x_hist_loop[:, dim, t + 1] = x_hist_loop[:, dim, t] - (step_size_loop / m_particles_loop) * xp.sum(sum_term, axis=1)\n",
    "        if (t + 1) % 50 == 0 or (t + 1) == num_iters_loop - 1:\n",
    "            step_norm = x_hist_loop[:, :, t + 1] - x_hist_loop[:, :, t]\n",
    "            if use_gpu_kswgd:\n",
    "                mean_disp = float(cp.mean(cp.linalg.norm(step_norm, axis=1)).get())\n",
    "            else:\n",
    "                mean_disp = float(np.mean(np.linalg.norm(step_norm, axis=1)))\n",
    "            kswgd_loop.set_postfix({\"mean_step\": f\"{mean_disp:.3e}\"})\n",
    "    \n",
    "    # Extract final latent samples and de-standardize\n",
    "    if use_gpu_kswgd:\n",
    "        Z_new_loop_std = cp.asnumpy(x_hist_loop[:, :, -1])\n",
    "    else:\n",
    "        Z_new_loop_std = x_hist_loop[:, :, -1]\n",
    "    \n",
    "    Z_new_loop = Z_new_loop_std * Z_dm_std + Z_dm_mean\n",
    "    \n",
    "    # Decode latent vectors to images\n",
    "    autoencoder.eval()\n",
    "    Z_new_loop_tensor = torch.from_numpy(Z_new_loop).float().to(device)\n",
    "    with torch.no_grad():\n",
    "        loop_images = autoencoder.decoder(Z_new_loop_tensor)\n",
    "    loop_images_cpu = loop_images.cpu().numpy()\n",
    "    \n",
    "    # Visualize generated images (fixed 16 columns, rows = m_particles / 16)\n",
    "    n_cols_loop = 16\n",
    "    n_rows_loop = m_particles_loop // n_cols_loop\n",
    "    n_show_loop = n_rows_loop * n_cols_loop\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows_loop, n_cols_loop, figsize=(2 * n_cols_loop, 2 * n_rows_loop))\n",
    "    \n",
    "    for i in range(n_show_loop):\n",
    "        ax = axes[i // n_cols_loop, i % n_cols_loop]\n",
    "        img = loop_images_cpu[i, 0]\n",
    "        # Apply threshold and gamma to make strokes thinner\n",
    "        img = np.clip((img - THRESHOLD) / (1.0 - THRESHOLD), 0, 1) ** GAMMA\n",
    "        ax.imshow(img, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    # Set title with larger font size\n",
    "    title_str = (f\"EDMD + KSWGD | seed={rng_seed_loop}, particles={m_particles_loop}, \"\n",
    "                 f\"step size={step_size_loop}\")\n",
    "    # title_str = (f\"EDMD + KSWGD\")\n",
    "    plt.suptitle(title_str, fontsize=40, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])  # Leave space for the title\n",
    "    plt.show()\n",
    "    \n",
    "    # Print parameter summary after the figure\n",
    "    print(f\"\\n[Parameter Summary]\")\n",
    "    print(f\"  - Random seed: {rng_seed_loop}\")\n",
    "    print(f\"  - Number of particles: {m_particles_loop}\")\n",
    "    print(f\"  - Step size: {step_size_loop}\")\n",
    "    print(f\"  - Number of iterations: {num_iters_loop}\")\n",
    "    # print(f\"  - Generated images shape: {loop_images_cpu.shape}\")\n",
    "    # print(f\"  - Latent dimension: {latent_dim}\")\n",
    "    # print(f\"  - KSWGD epsilon: {eps_kswgd:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22616a23",
   "metadata": {},
   "source": [
    "# Technical Documentation: Computational Details & Parameter Summary\n",
    "\n",
    "---\n",
    "\n",
    "## 1. CNN Autoencoder\n",
    "\n",
    "### 1.1 Network Architecture\n",
    "\n",
    "#### Encoder (CNNEncoder)\n",
    "| Layer | Type | Input Size | Output Size | Parameters |\n",
    "|-------|------|------------|-------------|------------|\n",
    "| 1 | Conv2d | 1x28x28 | 32x28x28 | kernel=3, stride=1, padding=1 |\n",
    "| 2 | BatchNorm2d | 32x28x28 | 32x28x28 | - |\n",
    "| 3 | ReLU | - | - | - |\n",
    "| 4 | Conv2d | 32x28x28 | 64x14x14 | kernel=3, stride=2, padding=1 |\n",
    "| 5 | BatchNorm2d | 64x14x14 | 64x14x14 | - |\n",
    "| 6 | ReLU | - | - | - |\n",
    "| 7 | Conv2d | 64x14x14 | 128x7x7 | kernel=3, stride=2, padding=1 |\n",
    "| 8 | BatchNorm2d | 128x7x7 | 128x7x7 | - |\n",
    "| 9 | ReLU | - | - | - |\n",
    "| 10 | Flatten | 128x7x7 | 6272 | - |\n",
    "| 11 | Linear | 6272 | 256 | - |\n",
    "| 12 | ReLU | - | - | - |\n",
    "| 13 | Linear | 256 | **6** | latent_dim=6 |\n",
    "\n",
    "#### Decoder (CNNDecoder)\n",
    "| Layer | Type | Input Size | Output Size | Parameters |\n",
    "|-------|------|------------|-------------|------------|\n",
    "| 1 | Linear | 6 | 256 | - |\n",
    "| 2 | ReLU | - | - | - |\n",
    "| 3 | Linear | 256 | 6272 | - |\n",
    "| 4 | ReLU | - | - | - |\n",
    "| 5 | Reshape | 6272 | 128x7x7 | - |\n",
    "| 6 | ConvTranspose2d | 128x7x7 | 64x14x14 | kernel=3, stride=2, padding=1, output_padding=1 |\n",
    "| 7 | BatchNorm2d | 64x14x14 | 64x14x14 | - |\n",
    "| 8 | ReLU | - | - | - |\n",
    "| 9 | ConvTranspose2d | 64x14x14 | 32x28x28 | kernel=3, stride=2, padding=1, output_padding=1 |\n",
    "| 10 | BatchNorm2d | 32x28x28 | 32x28x28 | - |\n",
    "| 11 | ReLU | - | - | - |\n",
    "| 12 | Conv2d | 32x28x28 | 1x28x28 | kernel=3, stride=1, padding=1 |\n",
    "| 13 | Sigmoid | - | - | Output range [0,1] |\n",
    "\n",
    "### 1.2 Training Parameters\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `latent_dim` | 6 | Latent space dimension |\n",
    "| `batch_size` | 128 | Batch size |\n",
    "| `num_epochs` | 60 | Number of training epochs |\n",
    "| `learning_rate` | 1e-3 | Learning rate |\n",
    "| `criterion` | MSELoss | Mean squared error loss |\n",
    "| `optimizer` | Adam | Adam optimizer |\n",
    "\n",
    "### 1.3 Dataset\n",
    "- **Training set**: 60,000 MNIST images\n",
    "- **Test set**: 10,000 MNIST images\n",
    "- **Preprocessing**: `transforms.ToTensor()` normalizes pixel values to [0, 1]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Diffusion Maps\n",
    "\n",
    "### 2.1 Parameter Settings\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `max_dm_samples` | 20,000 | Maximum samples for DM |\n",
    "| `m` | 15 | Number of eigenvectors computed |\n",
    "| `t_diffusion` | 1 | Diffusion time scale |\n",
    "\n",
    "### 2.2 Core Computational Pipeline\n",
    "\n",
    "1. **Data Standardization**:\n",
    "$$Z_{dm} = \\frac{Z_{raw} - \\mu}{\\sigma}$$\n",
    "\n",
    "2. **Gaussian Kernel Matrix**:\n",
    "$$K_{ij} = \\exp\\left(-\\frac{\\|z_i - z_j\\|^2}{2\\epsilon}\\right)$$\n",
    "\n",
    "3. **Bandwidth Selection** (Median Heuristic):\n",
    "$$\\epsilon = \\frac{\\text{median}(d_{ij}^2)}{2 \\ln(N)}$$\n",
    "\n",
    "4. **Markov Transition Matrix**:\n",
    "$$P_{ij} = \\frac{K_{ij}}{\\sum_j K_{ij}}$$\n",
    "\n",
    "5. **Eigenvalue Decomposition**: Compute the leading $m$ eigenpairs of $P^T$\n",
    "\n",
    "6. **Diffusion Coordinates**:\n",
    "$$\\psi_k = \\phi_k \\cdot \\lambda_k^t$$\n",
    "\n",
    "### 2.3 Visualization Parameters\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `n_gmm_components_2d` | 10 | 2D GMM components (outlier filtering) |\n",
    "| `outlier_percentile` | 15 | Remove bottom 15% outliers |\n",
    "| `SPREAD_FACTOR` | 1.0 | 3D visualization cluster separation factor |\n",
    "| `n_gmm_components` | 10 | 3D GMM components |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. KSWGD (Lagrangian Approach to Wasserstein Gradient Descent)\n",
    "\n",
    "### 3.1 Kernel Construction\n",
    "\n",
    "1. **KSWGD Bandwidth**:\n",
    "$$\\epsilon_{kswgd} = \\max\\left(\\frac{\\text{median}(d^2)}{2\\ln(N+1)}, 10^{-6}\\right)$$\n",
    "\n",
    "2. **Normalized Kernel**:\n",
    "$$p_x = \\sqrt{\\sum_j K_{ij}}$$\n",
    "$$\\tilde{K}_{ij} = \\frac{K_{ij}}{p_{x,i} \\cdot p_{x,j}}$$\n",
    "\n",
    "3. **Symmetric Random Walk Kernel**:\n",
    "$$K_{rw} = \\frac{1}{2}\\left(\\frac{\\tilde{K}}{D} + \\frac{\\tilde{K}}{D^T}\\right)$$\n",
    "\n",
    "where $D_j = \\sum_i \\tilde{K}_{ij}$\n",
    "\n",
    "### 3.2 Spectral Weight Computation\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `tol` | 1e-6 | Eigenvalue truncation threshold |\n",
    "| `reg` | 1e-3 | Regularization parameter |\n",
    "\n",
    "Formulas:\n",
    "$$\\lambda' = \\lambda_{ns} - 1$$\n",
    "$$\\lambda^{-1}[k] = \\frac{\\epsilon}{\\lambda'[k]}, \\quad k \\geq 1$$\n",
    "$$\\lambda_{ns,inv} = \\frac{\\epsilon}{\\lambda_{ns} + \\text{reg}}$$\n",
    "$$\\lambda_{ns,s,ns} = \\lambda_{ns,inv} \\cdot \\lambda^{-1} \\cdot \\lambda_{ns,inv}$$\n",
    "\n",
    "### 3.3 Particle Transport Parameters\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `m_particles` | 64 | Number of particles |\n",
    "| `num_iters` | 500 | KSWGD iterations |\n",
    "| `step_size` | 0.1 | Step size |\n",
    "| `rng_seed` | 1 | Random seed |\n",
    "\n",
    "### 3.4 KSWGD Update Formula\n",
    "\n",
    "$$x^{(t+1)} = x^{(t)} - \\frac{\\eta}{m} \\sum_j \\nabla_x K(x^{(t)}, X_{tar}) \\cdot \\Phi \\Lambda \\Phi^T K(X_{tar}, x^{(t)})$$\n",
    "\n",
    "where:\n",
    "- $\\eta$: step size (`step_size`)\n",
    "- $m$: number of particles (`m_particles`)\n",
    "- $\\Phi$: truncated eigenvector matrix\n",
    "- $\\Lambda$: diagonal spectral weight matrix\n",
    "\n",
    "---\n",
    "\n",
    "## 4. EDMD (Extended Dynamic Mode Decomposition)\n",
    "\n",
    "### 4.1 KDE Drift Estimation\n",
    "\n",
    "1. **Bandwidth Computation**:\n",
    "$$h = \\sqrt{\\text{median}(d^2)}$$\n",
    "\n",
    "2. **Weight Matrix**:\n",
    "$$W_{ij} = \\exp\\left(-\\frac{\\|x_i - x_j\\|^2}{2h^2}\\right)$$\n",
    "\n",
    "3. **KDE Score Function** (Drift Term):\n",
    "$$\\text{score}(x) = \\frac{\\sum_j W_{ij} x_j / \\sum_j W_{ij} - x}{h^2}$$\n",
    "\n",
    "### 4.2 Langevin Dynamics\n",
    "$$X_{next} = X + \\Delta t \\cdot \\text{score}(X) + \\sqrt{2\\Delta t} \\cdot \\xi$$\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `dt_edmd` | 0.1 | Langevin time step |\n",
    "| $\\xi$ | $\\mathcal{N}(0,1)$ | Standard Gaussian noise |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Dictionary Learning - Detailed Theory\n",
    "\n",
    "### 5.1 Mathematical Background\n",
    "\n",
    "The goal of dictionary learning is to find an **overcomplete dictionary** $\\mathbf{D} \\in \\mathbb{R}^{d \\times K}$ ($K > d$), such that data $\\mathbf{X}$ can be approximately represented by sparse codes $\\mathbf{A}$:\n",
    "\n",
    "$$\\mathbf{X} \\approx \\mathbf{D} \\mathbf{A}$$\n",
    "\n",
    "### 5.2 Optimization Objective\n",
    "\n",
    "Dictionary learning solves the following optimization problem:\n",
    "\n",
    "$$\\min_{\\mathbf{D}, \\mathbf{A}} \\frac{1}{2} \\|\\mathbf{X} - \\mathbf{D}\\mathbf{A}\\|_F^2 + \\alpha \\|\\mathbf{A}\\|_1$$\n",
    "\n",
    "where:\n",
    "- $\\|\\cdot\\|_F$: Frobenius norm\n",
    "- $\\|\\mathbf{A}\\|_1 = \\sum_{ij} |A_{ij}|$: L1 norm (promotes sparsity)\n",
    "- $\\alpha$: Sparsity regularization coefficient\n",
    "\n",
    "### 5.3 Constraints\n",
    "\n",
    "Dictionary atoms are typically constrained to unit norm:\n",
    "$$\\|\\mathbf{d}_k\\|_2 = 1, \\quad \\forall k = 1, \\ldots, K$$\n",
    "\n",
    "### 5.4 Alternating Optimization Algorithm\n",
    "\n",
    "Dictionary learning typically uses **alternating minimization**:\n",
    "\n",
    "**Step 1: Sparse Coding** (Fix $\\mathbf{D}$, optimize $\\mathbf{A}$)\n",
    "\n",
    "For each sample $\\mathbf{x}_i$, solve the LASSO problem:\n",
    "$$\\mathbf{a}_i = \\arg\\min_{\\mathbf{a}} \\frac{1}{2}\\|\\mathbf{x}_i - \\mathbf{D}\\mathbf{a}\\|_2^2 + \\alpha \\|\\mathbf{a}\\|_1$$\n",
    "\n",
    "Common algorithms:\n",
    "- **LARS (Least Angle Regression)**: Method used in this code\n",
    "- OMP (Orthogonal Matching Pursuit)\n",
    "- Coordinate Descent\n",
    "\n",
    "**Step 2: Dictionary Update** (Fix $\\mathbf{A}$, optimize $\\mathbf{D}$)\n",
    "$$\\mathbf{D} = \\arg\\min_{\\mathbf{D}} \\|\\mathbf{X} - \\mathbf{D}\\mathbf{A}\\|_F^2$$\n",
    "\n",
    "Analytical solution: $\\mathbf{D} = \\mathbf{X}\\mathbf{A}^T(\\mathbf{A}\\mathbf{A}^T)^{-1}$, then column normalization\n",
    "\n",
    "### 5.5 Mini-Batch Dictionary Learning\n",
    "\n",
    "`MiniBatchDictionaryLearning` uses an **online learning** strategy:\n",
    "\n",
    "1. Randomly sample a mini-batch\n",
    "2. Perform sparse coding on the mini-batch\n",
    "3. Incrementally update dictionary using **block coordinate descent**\n",
    "\n",
    "This enables the algorithm to handle large-scale datasets.\n",
    "\n",
    "### 5.6 Parameters in Code\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `n_dict_components` | 100 | Number of dictionary atoms $K$ |\n",
    "| `dict_alpha` | 1e-3 | Sparsity regularization coefficient $\\alpha$ |\n",
    "| `dict_batch` | 256 | Mini-batch size |\n",
    "| `dict_max_iter` | 500 | Maximum iterations |\n",
    "| `dict_random_state` | 42 | Random seed |\n",
    "| `fit_algorithm` | \"lars\" | LARS algorithm for sparse coding |\n",
    "\n",
    "### 5.7 Output Dimensions\n",
    "\n",
    "- **Dictionary atoms**: `dict_model.components_` shape is `(100, 6)`\n",
    "- **Sparse codes**: $\\Phi_X, \\Phi_Y$ shape is $(N, 101)$, including constant term\n",
    "\n",
    "---\n",
    "\n",
    "## 6. EDMD Koopman Operator\n",
    "\n",
    "### 6.1 Theoretical Background\n",
    "\n",
    "The **Koopman operator** is a linear operator acting on the space of observable functions, even when the underlying dynamical system is nonlinear.\n",
    "\n",
    "For a dynamical system $x_{t+1} = f(x_t)$, the Koopman operator $\\mathcal{K}$ is defined as:\n",
    "$$(\\mathcal{K}g)(x) = g(f(x))$$\n",
    "\n",
    "### 6.2 EDMD Approximation\n",
    "\n",
    "EDMD approximates the Koopman operator using dictionary functions $\\{\\psi_k\\}$:\n",
    "\n",
    "$$\\mathbf{G} = \\frac{1}{N} \\Phi_X^T \\Phi_X + \\text{reg} \\cdot \\mathbf{I}$$\n",
    "$$\\mathbf{A} = \\frac{1}{N} \\Phi_X^T \\Phi_Y$$\n",
    "\n",
    "Koopman matrix approximation: $\\mathbf{K} = \\mathbf{G}^{-1}\\mathbf{A}$\n",
    "\n",
    "Or equivalently, solve the generalized eigenvalue problem:\n",
    "$$\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{G} \\mathbf{v}$$\n",
    "\n",
    "### 6.3 Parameter Settings\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `reg_edmd` | 1e-3 | Tikhonov regularization |\n",
    "| `mode_skip_edmd` | 1 | Skip constant mode |\n",
    "| `eig_threshold_edmd` | 1e-6 | Eigenvalue truncation threshold |\n",
    "\n",
    "### 6.4 Generator Spectrum\n",
    "\n",
    "Recover continuous-time generator from discrete Koopman eigenvalues:\n",
    "$$\\lambda_{gen} = \\frac{\\lambda_{ns} - 1}{\\Delta t}$$\n",
    "\n",
    "KSWGD weights:\n",
    "$$\\lambda_{gen,inv}[k] = \\frac{1}{\\lambda_{gen}[k]}, \\quad |\\lambda_{gen}[k]| > 10^{-6}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Parameter Sweep Experiment\n",
    "\n",
    "The last cell performs systematic parameter sweeping:\n",
    "\n",
    "### 7.1 Sweep Parameters\n",
    "| Parameter | Sweep Values |\n",
    "|-----------|--------------|\n",
    "| `rng_seed_list` | [1, 2, 3, 4, 5] |\n",
    "| `m_particles_list` | [64] |\n",
    "| `step_size_list` | [0.01, 0.05, 0.1] |\n",
    "| `num_iters_list` | [500] |\n",
    "\n",
    "### 7.2 Total Configurations\n",
    "$$5 \\times 1 \\times 3 \\times 1 = 15 \\text{ configurations}$$\n",
    "\n",
    "### 7.3 Image Post-processing\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `THRESHOLD` | 0.2 | Background threshold |\n",
    "| `GAMMA` | 1.0 | Gamma correction |\n",
    "\n",
    "Post-processing formula:\n",
    "$$\\text{img}_{out} = \\left(\\frac{\\max(\\text{img} - T, 0)}{1 - T}\\right)^\\gamma$$\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Algorithm Pipeline Summary\n",
    "\n",
    "```\n",
    "MNIST Images (28x28)\n",
    "        |\n",
    "        v\n",
    "CNN Autoencoder (latent_dim=6)\n",
    "        |\n",
    "        v\n",
    "Latent Space Z in R^(N x 6)\n",
    "    /                \\\n",
    "   v                  v\n",
    "Diffusion Maps     EDMD Pipeline\n",
    "- Gaussian kernel  - KDE drift estimation\n",
    "- Markov matrix    - Langevin evolution\n",
    "- Eigendecomposition\n",
    "- Diffusion coords - Dictionary learning (100 atoms)\n",
    "                   - Koopman operator\n",
    "    \\                /\n",
    "     v              v\n",
    "KSWGD Particle Transport\n",
    "- 64 particles, 500 iterations, step size 0.1\n",
    "- Initialize from N(0, I), transport to target\n",
    "        |\n",
    "        v\n",
    "Decoder Generates Images\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Key Formula Summary\n",
    "\n",
    "| Name | Formula |\n",
    "|------|---------|\n",
    "| Gaussian Kernel | $K_{ij} = \\exp(-\\|x_i-x_j\\|^2/2\\epsilon)$ |\n",
    "| Median Bandwidth | $\\epsilon = \\text{median}(d^2)/2\\ln N$ |\n",
    "| Markov Matrix | $P_{ij} = K_{ij}/\\sum_j K_{ij}$ |\n",
    "| KDE Score | $s(x) = (\\sum_j W_{ij}x_j/\\sum_j W_{ij} - x)/h^2$ |\n",
    "| Langevin | $x' = x + \\Delta t \\cdot s(x) + \\sqrt{2\\Delta t}\\xi$ |\n",
    "| Dictionary Learning | $\\min_{D,A} \\|X-DA\\|_F^2 + \\alpha\\|A\\|_1$ |\n",
    "| EDMD | $Av = \\lambda Gv$ |\n",
    "| KSWGD Update | $x^{(t+1)} = x^{(t)} - \\eta/m \\cdot \\nabla K \\cdot \\Phi\\Lambda\\Phi^T K$ |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
